<<<<<<< HEAD
[{"content":"The Deeper, The Harder 第一个实验属于热身，只需要我们去调用系统提供的接口，称之为系统调用(System Calls)。而这个实验就要揭开操作系统的黑盒，看看系统调用的原理并写几个新的系统调用。\n配环境：基于qemu的gdb调试 第一题出了几个填空题，目的是为了学会用gdb调试kernel。因为是基于qemu接的gdb，需要在两个终借用网络端口进行远程调试。具体操作为：\n执行make qemu-gdb。最后会输出一个端口号，like： 1 2 3 # make qemu-gdb *** Now run \u0026#39;gdb\u0026#39; in another window. qemu-system-riscv64 -machine virt -bios none -kernel kernel/kernel -m 128M -smp 3 -nographic -global virtio-mmio.force-legacy=false -drive file=fs.img,if=none,format=raw,id=x0 -device virtio-blk-device,drive=x0,bus=virtio-mmio-bus.0 -S -gdb tcp::25000 开一个新的终端，执行gdb-multiarch。然后执行： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 (gdb) target remote localhost:25000 Remote debugging using localhost:25000 warning: Architecture rejected target-supplied description warning: No executable has been specified and target does not support determining executable automatically. Try using the \u0026#34;file\u0026#34; command. Truncated register 37 in remote \u0026#39;g\u0026#39; packet (gdb) set architecture riscv:rv64 # 实验手册没提到架构，不指定架构会崩屎 The target architecture is assumed to be riscv (gdb) file kernel/kernel Reading symbols from kernel/kernel... (gdb) b syscall Breakpoint 1 at 0x8000203c: file kernel/syscall.c, line 133. (gdb) c Continuing. [Switching to Thread 1.3] Thread 3 hit Breakpoint 1, syscall () at kernel/syscall.c:133 133 { 实际上，gdb也会提示我们，项目根目录里有一个.gdbinit配置文件，只需要在家目录的.gdbinit中引入：\n1 add-auto-load-safe-path /xv6-labs-2023/.gdbinit 即可不用每次都输入上述操作。\n并且作为CTFer，当然不能满足于原生gdb了，所以我直接——\npeda，启动！！ 这一启动不要紧，遇到一堆关于riscv的bug。\n首先是启动 gdb-multiarch 时需要确保export LC_CTYPE=C.UTF-8，因为docker基础镜像是极简版系统，对字符集支持不友好。\n然后peda能正常调试，但是不能展示那四个面板，这就意义不大了。所以我直接——\npwndbg，启动！！ 然后就直接：\n1 2 0x0000000000001000 in ?? () Exception occurred: context: (\u0026lt;class \u0026#39;NotImplementedError\u0026#39;\u0026gt;) 原来是代码没写完，那真的没事了。所以我直接——\ngef，启动！！ 万幸这次能显示面板了。看了眼github，还得是gef更新的勤快。\npeda, pwndbg, gef都是CTF中pwn方向常用的gdb的增强插件，但他们不能同时使用。\nLab2 SysCall 终于搞好环境，虽然看起来是无用的折腾，但是为后面更复杂的调试打下了坚实的基础（你最好是）。\n填空题 填空题没法打分，目的是帮助我们后续进行内核报错的调试\nQ: 查看backtrace输出，哪个函数调用 syscall 了？\nA: 由题可知显然易证。 Q: p-\u0026gt;trapframe-\u0026gt;a7 的值是多少，这个值代表什么？（提示：查看 user/initcode.S，这是 xv6 启动的第一个用户程序。）\nA: gef直接打印出来了，但也可以使用p *p.trapframe查看。结合源代码可知，a7是系统调用的索引。当前要执行的系统调用是sys_exec Q: CPU 之前处于什么模式？\nA: 课本让我们查看sstatus寄存器，p/t $sstatus，得到的结果是0x22。其含义需要翻阅riscv手册，相关内容文档给出了链接。（The RISC-V Instruction Set Manual Volume II: Privileged Architecture） 在第90页，可知第八位的SPP为0则表示trap来自于用户模式。 Q: 瞎几把改下指针让内核崩溃（比如num = * (int *) 0）。记录内核发生 panic 的汇编指令。哪个寄存器对应于变量 num？\nA: spec寄存器表示崩溃指令的地址。def直接查看。也可以查看kernel/kernel.asm Q: 为什么内核会崩溃？\nA: scause寄存器表示崩溃根因。具体内容在手册71页的表4.2。我们的崩溃的scause为0xd，查表得“13 Load page fault”，表明0不能被映射到内核地址空间。 Q: 内核崩溃时运行的二进制文件的名称是什么？它的进程 pid 是什么？\nA: p *p riscv的中文参考资料：https://blog.csdn.net/zzy980511/article/details/130642258\ntracing trace(1 \u0026lt;\u0026lt; SYS_call)系统调用输入一个掩码，表示系统调用号。当执行指定的系统调用时打印点东西，包括pid，第系统调用名和返回值：\u0026lt;pid\u0026gt;:syscall \u0026lt;syscall\u0026gt; -\u0026gt; \u0026lt;ret\u0026gt;\n首先梳理一下系统调用的调用链：\n用户侧 UPROGS += $U/_trace: 用户态的user/trace.c是系统调用int trace(int)的测试程序，实验已经给出。 user/user.h 需要增加int trace(int)的声明 user/usys.pl 用于生成usys.S，里面是系统调用的stub。stub是从用户态到内核态的桥梁。 1 2 3 4 5 6 7 8 9 10 11 12 # Generate usys.S, the stubs for syscalls. print \u0026#34;#include \\\u0026#34;kernel/syscall.h\\\u0026#34;\\n\u0026#34;; sub entry { my $name = shift; print \u0026#34;.global $name\\n\u0026#34;; print \u0026#34;${name}:\\n\u0026#34;; print \u0026#34; li a7, SYS_${name}\\n\u0026#34;; print \u0026#34; ecall\\n\u0026#34;; # 进入内核态 print \u0026#34; ret\\n\u0026#34;; } entry(\u0026#34;trace\u0026#34;); # ... 内核侧 kernel/syscall.h 定义系统调用的索引 kernel/syscall.c 所有系统调用的通用接口，根据传入的索引进行转发。 kernel/sysproc.c 系统调用的具体实现 1 2 3 4 5 6 7 8 uint64 sys_trace(void) { int mask; argint(0, \u0026amp;mask); myproc()-\u0026gt;tracemask |= mask; return 0; } 修改内核代码 至此走完了一个系统调用的完整调用链。但对trace来说，还需要修改内核代码实现我们需要的功能：\nkernel/proc.h: struct proc用于定义一个进程。pid是本来就有的字段，我们需要增加trace掩码字段。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 struct proc { struct spinlock lock; // p-\u0026gt;lock must be held when using these: enum procstate state; // Process state void *chan; // If non-zero, sleeping on chan int killed; // If non-zero, have been killed int xstate; // Exit status to be returned to parent\u0026#39;s wait int pid; // Process ID // wait_lock must be held when using this: struct proc *parent; // Parent process // these are private to the process, so p-\u0026gt;lock need not be held. uint64 kstack; // Virtual address of kernel stack uint64 sz; // Size of process memory (bytes) pagetable_t pagetable; // User page table struct trapframe *trapframe; // data page for trampoline.S struct context context; // swtch() here to run process struct file *ofile[NOFILE]; // Open files struct inode *cwd; // Current directory char name[16]; // Process name (debugging) uint64 tracemask; // tracemask uint64 arg; // Extra: int arg }; kernel/proc.c 这里实现trace掩码的初始化和fork克隆 1 2 3 4 5 6 7 8 9 10 11 12 static struct proc* allocproc(void) { // ... p-\u0026gt;tracemask = 0; } int fork(void) { // ... np-\u0026gt;tracemask = p-\u0026gt;tracemask; } kernel/syscall.c:syscall() 这里实现打印输出部分 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 void syscall(void) { int num; struct proc *p = myproc(); num = p-\u0026gt;trapframe-\u0026gt;a7; if(num \u0026gt; 0 \u0026amp;\u0026amp; num \u0026lt; NELEM(syscalls) \u0026amp;\u0026amp; syscalls[num]) { // Use num to lookup the system call function for num, call it, // and store its return value in p-\u0026gt;trapframe-\u0026gt;a0 p-\u0026gt;trapframe-\u0026gt;a0 = syscalls[num](); if (p-\u0026gt;tracemask \u0026amp; (1 \u0026lt;\u0026lt; num)) { // \u0026lt;\u0026lt; 判断是否需要trace这个系统调用 printf(\u0026#34;%d: syscall %s -\u0026gt; %d\\n\u0026#34;, p-\u0026gt;pid, syscall_name[num], p-\u0026gt;trapframe-\u0026gt;a0); // syscall_name整一个字符串数组即可，注意第0个元素置空 } } else { printf(\u0026#34;%d %s: unknown sys call %d\\n\u0026#34;, p-\u0026gt;pid, p-\u0026gt;name, num); p-\u0026gt;trapframe-\u0026gt;a0 = -1; } } Extra：打印参数 kernel/syscall.c中还实现了获取系统调用参数的辅助函数：argint(int n, int *ip)、argstr(int n, char *buf, int max)等。本质上就是读通用寄存器。\n如果直接在trace输出时再去读寄存器，由于此时系统调用已经结束，无法获取参数。为了将参数传回syscall()入口，需要继续为proc结构体添加一个字段。同时hook获取参数的函数：\n1 2 3 4 5 6 7 // Fetch the nth 32-bit system call argument. void argint(int n, int *ip) { *ip = argraw(n); myproc()-\u0026gt;arg = *ip; } 这里只展示了提取一个int，至于更复杂的参数也只是增加处理逻辑而已。\nsysinfo sysinfo 系统调用收集运行时系统信息。实验给出了数据结构定义：\n1 2 3 4 struct sysinfo { uint64 freemem; // amount of free memory (bytes) uint64 nproc; // number of process }; 完善调用链的操作大同小异。我们重点关注两个字段的获取：\nfree memory bytes 实验指引我们查看kernel/kalloc.c：\n1 2 3 4 5 6 7 8 struct run { struct run *next; }; struct { struct spinlock lock; struct run *freelist; } kmem; 可以看到这个简陋的动态内存管理机制使用了单链表来存储可用内存。于是空余字节的数量就是单链表进行求和\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // kernel/kalloc.c uint64 kfreemem(void) { struct run *r; uint64 free = 0; acquire(\u0026amp;kmem.lock); // 模仿kalloc函数进行上锁 r = kmem.freelist; while (r) { free += PGSIZE; // PGSIZE固定4096字节 r = r-\u0026gt;next; } release(\u0026amp;kmem.lock); return free; } 至此功能已经完成了，但是很奇怪打分脚本是如何评分的。查看user/sysintotest.c可以发现使用了sbrk系统调用。这个函数的作用是增加或减少进程的堆大小。于是计算空闲内存的逻辑是：用sbrk填满所有内存，计算增加的页数量。\nnumber of process 进程管理的逻辑位于kernel/proc.c：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // initialize the proc table. void procinit(void) { struct proc *p; initlock(\u0026amp;pid_lock, \u0026#34;nextpid\u0026#34;); initlock(\u0026amp;wait_lock, \u0026#34;wait_lock\u0026#34;); for(p = proc; p \u0026lt; \u0026amp;proc[NPROC]; p++) { initlock(\u0026amp;p-\u0026gt;lock, \u0026#34;proc\u0026#34;); p-\u0026gt;state = UNUSED; p-\u0026gt;kstack = KSTACK((int) (p - proc)); } } proc[NPROC]数组维护所有进程的proc结构体。进程状态在proc结构体中由一个枚举标记：\n1 2 // kernel/proc.h enum procstate { UNUSED, USED, SLEEPING, RUNNABLE, RUNNING, ZOMBIE }; 于是计算进程数量就是对列表中状态不是UNUSED的进程进行求和；\n1 2 3 4 5 6 7 8 uint64 count_proc(void) { struct proc *p; uint64 count = 0; for(p = proc; p \u0026lt; \u0026amp;proc[NPROC]; p++) if(p-\u0026gt;state != UNUSED) count += 1; return count; } 最后注意在kenel/defs.h中加入这两个函数的声明。\nExtra：load average load average的计算公式基本上就是：\n运行和等待的进程数/cpu内核数 关于进程数已经实现了，只需要统计SED, SLEEPING, RUNNABLE, RUNNING这些状态的进程即可。\n关于内核数量，kenel/param.h中的NCPU已经指定了最大处理器逻辑核数量。\n计算输出即可。而现代linux系统计算load average一般还要记录3分钟，5分钟，15分钟的数值。vx6对时间的支持并不友好，此题再议。\n打个分⑧ ","date":"2023-12-10T00:00:00Z","image":"https://lonelyuan.github.io/p/xv6-syscall/gef_hu90ecd56e3ba7374c29b43604edbf6baf_169165_120x120_fill_box_smart1_3.png","permalink":"https://lonelyuan.github.io/p/xv6-syscall/","title":"XV6 Lab - SystemCalls"},{"content":"《CSAPP排第一，6.828排第二》 课程简介：MIT 6.S081: Operating System Engineering - CS自学指南 (csdiy.wiki) MIT的课程体系一直在发展，为避免混淆这里简单梳理一下： 6.828：6.828 / Fall 2018 (mit.edu) 截至2018年，6.828课程的实验使用的是基于 x86 的 JOS 6.S081：6.S081 / Fall 2019 (mit.edu) 2019年新增6.S081（操作系统导论）作为6.828的附属课程。与此同时实验部分首次升级为基于 RISC-V 的 xv6 随后在2020年两门课分离。6.S081作为本科生课程继续发挥导论的作用。而6.828作为面向研究生的研讨课研究更前沿的课题。 6.1810：6.1810 / Fall 2023 (mit.edu) 2022年，课程号更新为 6.5810（原 6.828）和 6.1810（原 6.S081） 配环境：基于Docker的实验环境搭建 官网文档十分详细：\nLab: Xv6 and Unix utilities (mit.edu) 在本系列实验中，每个实验只关注操作系统的某个部分，因此不同实验用git管理：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 root@55724e7ba091:/xv6-labs-2023# git branch -r origin/HEAD -\u0026gt; origin/util origin/cow origin/debugging-demo origin/fs origin/lock origin/mmap origin/net origin/pgtbl origin/riscv origin/syscall origin/thread origin/traps origin/util 于是要切换到某个实验只需git switch -c \u0026lt;branch\u0026gt;切换分支即可。当然要注意保存当前branch的结果。\n最后给出我的dockerfile：\n1 2 3 4 5 6 FROM ubuntu:20.04 ENV DEBIAN_FRONTEND=noninteractive RUN sed -i \u0026#39;s/archive.ubuntu.com/mirrors.ustc.edu.cn/g\u0026#39; /etc/apt/sources.list RUN apt-get update RUN apt-get install -y git build-essential gdb-multiarch qemu-system-misc gcc-riscv64-linux-gnu binutils-riscv64-linux-gnu RUN git clone git://g.csail.mit.edu/xv6-labs-2023 \u0026amp;\u0026amp; cd xv6-labs-2023 XV6，启动！ QEMU（Quick Emulator）是一个开源的虚拟化和模拟器工具，它可以模拟多个硬件架构，包括x86、ARM、MIPS等。QEMU支持在主机系统上模拟虚拟机，并提供了一种灵活的方式来进行虚拟化开发和测试。——from GPT\n环境配好后，运行make qemu即可进入xv6系统。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 xv6 kernel is booting hart 1 starting hart 2 starting init: starting sh $ ls . 1 1 1024 .. 1 1 1024 README 2 2 2305 xargstest.sh 2 3 93 cat 2 4 32312 echo 2 5 31184 forktest 2 6 15296 grep 2 7 35664 init 2 8 31984 kill 2 9 31192 ln 2 10 31104 ls 2 11 34224 mkdir 2 12 31232 rm 2 13 31208 sh 2 14 53464 stressfs 2 15 32080 usertests 2 16 180664 grind 2 17 47288 wc 2 18 33312 zombie 2 19 30760 console 3 20 0 可以发现这里的可执行文对应着项目文件夹里user目录下的源代码。也就是说目前我们处于用户态。But how it works？\n由于执行的是make指令，当然要去阅读Makefile了：\n1 2 3 4 5 6 7 QEMUOPTS = -machine virt -bios none -kernel $K/kernel -m 128M -smp $(CPUS) -nographic QEMUOPTS += -global virtio-mmio.force-legacy=false QEMUOPTS += -drive file=fs.img,if=none,format=raw,id=x0 QEMUOPTS += -device virtio-blk-device,drive=x0,bus=virtio-mmio-bus.0 qemu: $K/kernel fs.img $(QEMU) $(QEMUOPTS) 这里真正启动了qemu程序，系统的内核、文件系统都在QEMUOPTS中指定。而我们的用户态程序都位于fs.img内：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 UPROGS=\\ $U/_cat\\ $U/_echo\\ $U/_forktest\\ $U/_grep\\ $U/_init\\ $U/_kill\\ $U/_ln\\ $U/_ls\\ $U/_mkdir\\ $U/_rm\\ $U/_sh\\ $U/_stressfs\\ $U/_usertests\\ $U/_grind\\ $U/_wc\\ $U/_zombie\\ fs.img: mkfs/mkfs README $(UEXTRA) $(UPROGS) mkfs/mkfs fs.img README $(UEXTRA) $(UPROGS) 这里让mkfs程序将文件系统构建成img格式的镜像。用户态程序都包含在UPROGS变量中。那么这些下划线开头的可执行文件又是谁编译的呢：\n1 2 3 4 _%: %.o $(ULIB) $(LD) $(LDFLAGS) -T $U/user.ld -o $@ $^ $(OBJDUMP) -S $@ \u0026gt; $*.asm $(OBJDUMP) -t $@ | sed \u0026#39;1,/SYMBOL TABLE/d; s/ .* / /; /^$$/d\u0026#39; \u0026gt; $*.sym 这里涉及到Makefile的一个通用技巧：-o $@ $^中的$@表示当前目标也，即_%，$^表示当前的依赖，即%.o $(ULIB)。于是我们知道这一步执行的是链接操作，那么编译又是谁干的呢？\n伟大的gpt老师告诉我们，makefile中存在这样的隐含规则，他会自动为.o文件寻找.c来编译：\n1 2 %.o: %.c $(CC) -c $(CFLAGS) $\u0026lt; -o $@ 终于捋顺了。虽然我们对操作系统内核的认识还很黑箱，但这些说的道理足以完成第一个实验了。\nLab1 Utils 第一个实验要求完成编写几个用户态函数，首先要明确一点，我们是在一个全新的操作系统，已经没有libc可用了！我们能够使用的只有XV6提供的系统调用，其定义都在user/user.h中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 struct stat; // system calls int fork(void); int exit(int) __attribute__((noreturn)); int wait(int*); int pipe(int*); int write(int, const void*, int); int read(int, void*, int); int close(int); int kill(int); int exec(const char*, char**); int open(const char*, int); int mknod(const char*, short, short); int unlink(const char*); int fstat(int fd, struct stat*); int link(const char*, const char*); int mkdir(const char*); int chdir(const char*); int dup(int); int getpid(void); char* sbrk(int); int sleep(int); int uptime(void); // ulib.c int stat(const char*, struct stat*); char* strcpy(char*, const char*); void *memmove(void*, const void*, int); char* strchr(const char*, char c); int strcmp(const char*, const char*); void fprintf(int, const char*, ...); void printf(const char*, ...); char* gets(char*, int max); uint strlen(const char*); void* memset(void*, int, uint); void* malloc(uint); void free(void*); int atoi(const char*); int memcmp(const void *, const void *, uint); void *memcpy(void *, const void *, uint); sleep sleep i命令要求进程暂停一定时间。输入一个整数，表示时间量，其单位则是系统定义的tick。\n天下代码一大抄，我们观察到kill指令的输入和sleep差不多，都是整数，只不过kill可以接受多个输入。而kill和sleep都有系统调用的定义，因此直接抄过来：\n1 2 3 4 5 6 7 8 9 10 11 #include \u0026#34;kernel/types.h\u0026#34; #include \u0026#34;user/user.h\u0026#34; int main(int argc, char **argv){ if(argc != 2){ fprintf(2, \u0026#34;usage: sleep tick\\n\u0026#34;); exit(1); } int ret = sleep(atoi(argv[1])); exit(ret); } 完成代码编写后按规则讲sleep加入UPROGS参数，最后执行评分脚本：\n1 2 3 4 5 6 root@55724e7ba091:/xv6-labs-2023# ./grade-lab-util sleep make: \u0026#39;kernel/kernel\u0026#39; is up to date. == Test sleep, no arguments == sleep, no arguments: OK (1.4s) == Test sleep, returns == sleep, returns: OK (0.9s) == Test sleep, makes syscall == sleep, makes syscall: OK (1.0s) (Old xv6.out.sleep failure log removed) Extra: uptime 实验文档中的最后给出了一些隐藏关，第一关要求实现uptime，也是掉接口，比sleep更简单：\n1 2 3 4 5 6 7 #include \u0026#34;kernel/types.h\u0026#34; #include \u0026#34;user/user.h\u0026#34; int main(int argc, char **argv){ fprintf(2, \u0026#34;uptime: %d\\n\u0026#34;, uptime()); exit(0); } pingpong pingpong命令将创建两个进程，并通过管道在两个进程间通信一个字节。官方文档对这个命令的实现描述的很清楚了：\nUse pipe to create a pipe. Use fork to create a child. Use read to read from a pipe, and write to write to a pipe. Use getpid to find the process ID of the calling process. 需要注意int pipe(int fd[2])仅支持单向通信，输入是两个fd分别表示读/写。因此读和写需要两个pipe。pipe返回fd之后，再执行fork即可让父子两个进程共享相同的pipe。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #include \u0026#34;kernel/types.h\u0026#34; #include \u0026#34;user/user.h\u0026#34; int main(int argc, char *argv[]) { int pid, p1[2], p2[2]; char buf[] = {\u0026#39;?\u0026#39;}; pipe(p1); pipe(p2); int ret = fork(); if (ret == 0) { // 返回0表示子进程 pid = getpid(); read(p1[0], buf, 1); printf(\u0026#34;%d: received ping\\n\u0026#34;, pid); write(p2[1], buf, 1); exit(0); } else { pid = getpid(); write(p1[1], buf, 1); read(p2[0], buf, 1); printf(\u0026#34;%d: received pong\\n\u0026#34;, pid); exit(0); } } primes 在上一个程序的基础上，primes希望使用多进程机制实现素数筛。具体流程为：\n每个进程通过管道从其左邻居读取数据，并通过另一个管道写入其右邻居。 每个进程代表一个素数，并判断传来的数是否是自己的倍数。当遇到新的素数时，创建新的子进程。 因此，针对第一步，每个进程都保持两个管道，一个临时变量，不断进行”读→判断→写“的循环。\n1 2 3 4 5 6 7 8 9 int me = 0, tmp = 0; int read_pipe[2], write_pipe[2]; while (1) { read(read_pipe[0], \u0026amp;tmp, 4); // 从左边读 if (tmp % me != 0) { try_fork(); write(write_pipe[1], \u0026amp;tmp, 4); // 往右边写 } } 针对第二步，当且仅当不被任何一个进程的数整除的时候进行fork。也就是当输入的数流动到最后/最新的进程的时候。因此需要一个状态变量判断自己是否是最新进程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 int me = 0, tmp = 0, forked=0; int read_pipe[2], write_pipe[2]; while (1) { read(read_pipe[0], \u0026amp;tmp, 4); if (tmp % me != 0) { if (!forked) { pipe(write_pipe); // 初始化管道 forked = 1; if (fork() == 0) { // 子进程重新进行初始化 read_pipe[0] = write_pipe[0]; // 读写管道交换 forked = 0; me = 0; } } write(write_pipe[1], \u0026amp;tmp, 4); } } 最后，主函数应该向管道中写入35个数，并且完成关闭多余的fd，终止条件等操作：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 #include \u0026#34;kernel/types.h\u0026#34; #include \u0026#34;user/user.h\u0026#34; int main(int argc, char *argv[]) { int me = 0, tmp = 0, forked=0; int read_pipe[2], write_pipe[2]; pipe(read_pipe); for (int i = 2; i \u0026lt;= 35; i++) write(read_pipe[1], \u0026amp;i, 4); // 初始先往read_pipe里写满 close(read_pipe[1]); while (1) { if(read(read_pipe[0], \u0026amp;tmp, 4)){ if (me == 0) { me = tmp; printf(\u0026#34;prime %d\\n\u0026#34;, me); } if (tmp % me != 0) { if (!forked) { pipe(write_pipe); forked = 1; if (fork() == 0) { close(write_pipe[1]); // 子进程的write_pipe尚未开发 close(read_pipe[0]); read_pipe[0] = write_pipe[0]; forked = 0; me = 0; } else close(write_pipe[0]); } if (forked) write(write_pipe[1], \u0026amp;tmp, 4); } } else { // 所有数都读完了，等待子进程退出 close(read_pipe[0]); if (forked) { close(write_pipe[1]); int child_pid; wait(\u0026amp;child_pid); } exit(0); } } } find find指令要求在特定名称的目录树中查找文件。程序大部分可以借鉴ls的实现，只需要在输出的时候执行字符串比较，并且实现递归查找。不过首先要了解文件系统的接口：\n1 2 3 4 5 6 7 8 9 10 11 12 13 // kernel/fs.h struct dirent { // Directory is a file containing a sequence of dirent structures. ushort inum; char name[DIRSIZ]; }; // kernel/stat.h struct stat { // 文件状态结构体 int dev; // File system\u0026#39;s disk device uint ino; // Inode number short type; // Type of file short nlink; // Number of links to file uint64 size; // Size of file in bytes }; 于是遍历目录的操作通常为：\n1 2 3 4 5 6 7 fd = open(path, O_RDONLY)) \u0026lt; 0); fstat(fd, \u0026amp;st); switch(st.type){ case T_DIVICE: ... case T_FILE: ... case T_DIR: ... } 于是在T_DIR分支内实现递归，在T_FILE分支内查找字符串即可：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 switch(st.type){ case T_FILE: if(match(path, pattern)\u0026gt;=0) printf(\u0026#34;%s\\n\u0026#34;, path); break; case T_DIR: strcpy(buf, path); p = buf+strlen(buf); *p++ = \u0026#39;/\u0026#39;; while(read(fd, \u0026amp;de, sizeof(de)) == sizeof(de)){ if (de.inum == 0 || trcmp(de.name, \u0026#34;.\u0026#34;) == 0 || strcmp(de.name, \u0026#34;..\u0026#34;) == 0) continue; memmove(p, de.name, DIRSIZ); p[DIRSIZ] = 0; if(stat(buf, \u0026amp;st) \u0026lt; 0){ printf(\u0026#34;find: cannot stat %s\\n\u0026#34;, buf); continue; } find(buf, pattern); } break; } 而match函数随便写一个字符串匹配或者KMP算法即可。\nExtra：find支持正则 给了grep.c，直接调接口\nxargs xargs command命令的参数同样是shell指令，它读取stdout作为参数指令的参数。简单来说，xargs把左边指令的输出放到最右边当作输入。但在我们的实现中，还有诸多细节：\nstdout中每一行作为一个参数，也就是需要以\\n分割。然而这里xv6并没有方便的库函数读取一行输入，需要自己实现readline() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 int readline(char* buf) { char ch, line[MAXARG] = {0}; int bytesRead = 0; while (read(0, \u0026amp;ch, 1)) { // Read a char from stdout if (ch != \u0026#39;\\n\u0026#39;) { line[bytesRead++] = ch; if (bytesRead + 1 \u0026gt;= MAXARG) { printf(\u0026#34;xargs: line too long\\n\u0026#34;); return -1; } } else { // End of line if (bytesRead \u0026gt; 0) { line[bytesRead] = \u0026#39;\\0\u0026#39;; return 1; } } } return -1; } 执行子命令使用fork+exec+wait 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 int main(int argc, char *argv[]) { char buf[buf_size + 1] = {0}; char *xargv[MAXARG] = {0}; for (int i = 1; i \u0026lt; argc; i++) // 去掉xargs xargv[i - 1] = argv[i]; while (1) { int read_bytes = readline(buf); if (read_bytes \u0026lt;= 0) break; char xbuf[buf_size + 1] = {0}; memcpy(xbuf, buf, strlen(buf)); xargv[argc - 1] = xbuf; if (fork() == 0) { // in child if (exec(argv[1], xargv) \u0026lt; 0) { fprintf(2, \u0026#34;xargs: exec fails with -1\\n\u0026#34;); exit(1); } } else { int pid; wait(\u0026amp;pid); } } Extra：还说🔪的事 在当前实现里，每exec一个shell都会打印一个$，导致运行test脚本时的输出实际上是：\n1 2 3 4 5 sh \u0026lt; xargstest.sh $ $ $ $ $ $ hello hello hello $ $ 为了消除烦人的$，我们需要修改shell源码，让其判断是否从文件中打开。相关逻辑位于：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // user/sh.c:134 int getcmd(char *buf, int nbuf){ write(2, \u0026#34;$ \u0026#34;, 2); // 加入判断逻辑 memset(buf, 0, nbuf); gets(buf, nbuf); if(buf[0] == 0) // EOF return -1; return 0; } int main(void){ static char buf[100]; int fd; // Ensure that three file descriptors are open. while((fd = open(\u0026#34;console\u0026#34;, O_RDWR)) \u0026gt;= 0){ if(fd \u0026gt;= 3){ close(fd); break; } } // Read and run input commands. while(getcmd(buf, sizeof(buf)) \u0026gt;= 0){ if(buf[0] == \u0026#39;c\u0026#39; \u0026amp;\u0026amp; buf[1] == \u0026#39;d\u0026#39; \u0026amp;\u0026amp; buf[2] == \u0026#39; \u0026#39;){ // Chdir must be called by the parent, not the child. buf[strlen(buf)-1] = 0; // chop \\n if(chdir(buf+3) \u0026lt; 0) fprintf(2, \u0026#34;cannot cd %s\\n\u0026#34;, buf+3); continue; } if(fork1() == 0) runcmd(parsecmd(buf)); wait(0); } exit(0); } 只需要加入一个状态变量判断是否经过fork即可。\nExtra：sh user/sh.c作为shell功能很受限，可以为其添加更多常用功能，如：\n支持wait 支持; 支持子shell：(，) 支持tab自动补全 支持history 详情请参考《CSAPP-shellLab》，👴懒得写了\n打个分⑧： ","date":"2023-12-01T00:00:00Z","image":"https://lonelyuan.github.io/p/xv6-util/util-grade_hu29693ed85ff5987b48267af9c379c744_33770_120x120_fill_box_smart1_3.png","permalink":"https://lonelyuan.github.io/p/xv6-util/","title":"XV6 Lab - Utilities"},{"content":"挂梯子每个人都玩过，但你知道梯子的原理吗。最后一个lab，实现一个HTTP代理服务器。本实验难度相对前面两个lab有所下降，但综合性比较强，涉及教材最后三章的所有内容以及malloc和cache两个lab。\n项目结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 . |-- csapp.c /* |-- csapp.h * 这三个文件是项目主体，可以随意修改 |-- proxy.c */ |-- driver.sh # 测评脚本 |-- free-port.sh /* |-- nop-server.py * 工具脚本 |-- port-for-user.pl */ `-- tiny |-- cgi-bin/ # 动态程序 |-- static/ # 静态文件 |-- csapp.c /* |-- csapp.h * 课本中提到的tiny实现，建议详细阅读 `-- tiny.c */ csapp.c csapp.c和csapp.h是课本后三章提到的函数代码实例，包括以下几组函数实现：\n进程控制：Fork(),Execve(),Wait(),Kill(),Sleep(),Pause()\u0026hellip; 信号控制：Signal(),Sigprocmask(),Sig***set() I/O操作：Open(),Read(),Write(),Lseek(),Close()\u0026hellip; Signal-safe I/O Standard I/O Robust I/O 目录操作：Opendir(),Readdir(),Closedir() 动态内存分配：Malloc(),Realloc(),Calloc(),Free() 内存映射：Mmap(),Nunmap() Socket接口：Socket(),Bind(),Listen(),Accept(),Connect() 网络信息：Getaddrinfo(),Gethostbyname(),Inet_ntop()\u0026hellip; 可重入接口：Open_clientfd(),Open_listenfd() Pthreads多线程：create(),join(),cancel(),detach(),exit(),self(),once() POSIX信号量：Sem_init(),P(),V() 这也太多了8。实际上这些都是系统函数的封装，我们并不需要用到所有函数。可以看到，本实验将后三章讲述的内容全部抛出，让我们自己思考并选用这些工具来完成目标。当然，也可以随意修改这些封装或者直接使用系统接口。\ntiny.c 此外，tiny目录下也有相同的csapp.c和csapp.h，而tiny.c是课本上提到的简易web服务器实现，于是我们可以将其作为proxy的初始代码框架。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 int main(int argc, char **argv){ int listenfd, connfd; char hostname[MAXLINE], port[MAXLINE]; socklen_t clientlen; struct sockaddr_storage clientaddr; listenfd = Open_listenfd(argv[1]); while (1) { clientlen = sizeof(clientaddr); connfd = Accept(listenfd, (SA *)\u0026amp;clientaddr, \u0026amp;clientlen); Getnameinfo((SA *) \u0026amp;clientaddr, clientlen, hostname, MAXLINE, port, MAXLINE, 0); printf(\u0026#34;Accepted from (%s, %s)\\n\u0026#34;, hostname, port); doit(connfd); Close(connfd); } } Socket接口是一切网络程序的底层，有关socket模型请随便搜索那一张流程图并熟记于心（或者参考👴的文章）。这里简单总结一下要点：\n地址标记主机，端口标记进程。 客户端执行Connect()，服务器执行Bind(),Listen(),Accept()。 unix系统中一切皆文件，打开的文件通过文件描述符fd标记。 网络连接也是一种特殊的文件，即Socket()也返回一个fd。 于是对该fd使用传统I/O函数即可进行通信内容的读写。本质上就是读写Socket提供的缓冲区 于是服务器需要维护listenfd,connfd两个fd分别代表监听端口和客户端端口。 而服务器是一个需要长久运行的程序，因此他的核心进程往往运行着一个死循环，也称为主事件循环。 在循环中服务器不断接受着客户端的请求，于是connfd在循环中不断地创建和销毁，而listenfd保持不变。 而具体到单个请求的处理，tiny将其交给了doit()函数。其功能分为以下几步：\n从缓冲区中读取HTTP报文 tiny只针对GET请求做出响应 读第一行，判断HTTP方法 读取处理剩余的HTTP首部 判断请求的是静态文件还是动态程序（cgi-bin） 静态请求，读取文件内容 动态请求，调用cgi程序 此外，面对错误情况要返回相应的状态码，而服务器进程不能结束。 得分点 BasicCorrectness: 40 （基本代理） Concurrency: 15 （并发性） Cache: 15 （使用缓存） Part1: Basic Proxy proxy在client面前扮演服务器，在server面前扮演客户端。也就是说在proxy中需要同时实现这两个功能，而tiny已经有了服务器端的实现，故而只需要考虑客户端的实现即可。\n1 2 3 4 5 ┌──────┐ (2) ┌─────┐ (1) ┌──────┐ │ │◄──────┤ │◄───────┤ │ │Server│ (3) │Proxy│ (4) │Client│ │ ├──────►│ ├───────►│ │ └──────┘ └─────┘ └──────┘ 具体来说，只需要修改doit函数。首先建立最简单的模型：\n1 2 3 4 5 6 7 8 9 10 11 12 13 // v0.1: score 16/40 void doit(int cfd){ char request[MAXLINE], host[16],port[5], response[MAXLINE]; /* (1) client -\u0026gt; proxy */ read_req(cfd, request, host, port); /* (2) proxy -\u0026gt; server */ int sfd = Open_clientfd(host, port); Rio_writen(sfd, request, strlen(request)); /* (3) server -\u0026gt; proxy */ read_res(sfd, response); /* (4) proxy -\u0026gt; client */ Rio_writen(cfd, response, strlen(response)); } read_req()和read_res()封装了从Rio缓冲区读取报文的细节。下面详细介绍：\n在client面前扮演server 对于请求报文，首先需要解析出地址和端口以便找到目的服务器，其次需要注意curl --proxy的第一行发包：\n1 GET http://localhost:81/ HTTP/1.1 这里路径变成了服务器的完整地址，直接丢给tiny是会报404的。因此，👴直接对第一行提取host,port,path。（注意分清sscanf()和sprintf()）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 void read_req(int fd, char* message, char* host, char* port, char* path){ rio_t rio; Rio_readinitb(\u0026amp;rio, fd); memset(message, 0, strlen(message)); char buf[MAXBUF], host_port_path[MAXLINE],host_port[MAXLINE], path_line[MAXLINE]; // Receive: \u0026#34;GET http://host:port/path HTTP/1.1\u0026#34; Rio_readlineb(\u0026amp;rio, buf, MAXLINE); sscanf(buf, \u0026#34;GET %s HTTP/1.1\\n\u0026#34;, host_port_path); sscanf(host_port_path, \u0026#34;http://%[^/]%s\u0026#34;, host_port, path); if(sscanf(host_port, \u0026#34;%[^:]:%s\u0026#34;, host, port) == 1) port = \u0026#34;80\u0026#34;; // Send: \u0026#34;GET /path HTTP/1.1\u0026#34; sprintf(path_line, \u0026#34;GET %s HTTP/1.1\\n\u0026#34;, path); strcat(message, path_line); while(strcmp(buf, \u0026#34;\\r\\n\u0026#34;)) { Rio_readlineb(\u0026amp;rio, buf, MAXLINE); strcat(message, buf); } } 在server面前扮演client 对于响应报文，则需要考虑包体长度问题。代码中设置了MAXBUF常量为8192，在测评脚本中有几个样例是远超过这个数字的。因此需要考虑流式传输，一边接受一边发送。于是doit()也需要进行修改\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // v0.2: score 40/40 void doit(int cfd){ char request[MAXLINE], host[16],port[5], res_buf[MAXBUF]; /* (1) client -\u0026gt; proxy */ read_req(cfd, request, host, port); /* (2) proxy -\u0026gt; server */ int sfd = Open_clientfd(host, port); Rio_writen(sfd, request, strlen(request)); /* (3) server -\u0026gt; proxy */ int n; while ((n = Rio_readn(sfd, res_buf, sizeof res_buf)) \u0026gt; 0) /* (4) proxy -\u0026gt; client */ Rio_writen(cfd, res_buf, n * sizeof(char)); } Part2: Concurrency 在并发性测试中，测评脚本会调用nop-server.py，其核心逻辑如下：\n1 2 3 4 5 serversocket.listen(5) while 1: channel, details = serversocket.accept() while 1: continue 可以看到，nop-server在接受请求之后会进入死循环，也就是说连接被永远阻塞了。这要求proxy能够同时接受多个连接。Pthread库的多线程接口较为简单，只需要将主事件循环中插入Pthread_create()，而doit()则被封装进线程的入口函数中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 // v0.3 55/70 int main(){ // ... while (1) { // ... Pthread_create(\u0026amp;tid, NULL, thread, connfd); } } void thread(int fd){ Pthread_detach(pthread_self()); // 设置为可分离状态，自动回收资源 doit(fd); Close(fd); } Part3: Cache 在缓存测试中，测评脚本会在执行过一定的请求之后杀死tiny服务器，要求服务器对之前的请求进行保存。结合上一步的多线程，这里便存在着并发读写的问题。\n而缓存的实现细节有非常多可说的部分，这里首先抽象出接口：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // v0.4 70/70 void doit(int cfd) { char request[MAXLINE], host[MAXLINE],port[MAXLINE], path[MAXLINE], response[MAXLINE]; /* (1) client -\u0026gt; proxy */ read_req(cfd, request, host, port, path); /* (1.1) proxy -\u0026gt; cache */ char *value = read_cache(\u0026amp;cache, \u0026amp;path); if (value != NULL) { /* (1.2) cache -\u0026gt; client */ Rio_writen(cfd, value, strlen(value)); return; } /* (2) proxy -\u0026gt; server */ int n, sfd = Open_clientfd(host, port); Rio_writen(sfd, request, strlen(request)); /* (3) server -\u0026gt; proxy */ char buf[MAXBUF], res[MAX_CACHE_SIZE]; while ((n = Rio_readn(sfd, buf, sizeof buf)) \u0026gt; 0) { /* (4) proxy -\u0026gt; client */ Rio_writen(cfd, buf, n * sizeof(char)); strncat(res, buf, n * sizeof(char)); } /* (4.1) proxy -\u0026gt; cache */ write_cache(\u0026amp;cache, \u0026amp;path, res); Close(sfd); } 具体到缓存设计这里可以自由发挥。如果面向评测脚本编程，只需要缓存容量为3，连缓存删除的策略都不用实现就可以满分。不过考试就考这个LRU、OPT啥的，还是得理解一下。\n下面是👴让gpt写的基于循环链表的LRU策略的缓存系统：\n数据结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 typedef struct CacheEntry { char* key; char* value; struct CacheEntry* next; struct CacheEntry* prev; } CacheEntry; typedef struct { int size; int capacity; CacheEntry* head; CacheEntry* tail; pthread_mutex_t lock; } Cache; 初始化 1 2 3 4 5 6 7 Cache* createCache(int capacity) { Cache* cache = (Cache*)malloc(sizeof(Cache)); cache-\u0026gt;size = 0; cache-\u0026gt;capacity = capacity; pthread_mutex_init(\u0026amp;cache-\u0026gt;lock, NULL); return cache; } 读缓存 1 2 3 4 5 6 7 8 9 10 11 12 13 14 char* read_cache(Cache* cache, const char* key) { pthread_mutex_lock(\u0026amp;cache-\u0026gt;lock); // 查找是否存在相同的 key CacheEntry* current = cache-\u0026gt;head; while (current != NULL) { if (strcmp(current-\u0026gt;key, key) == 0) { pthread_mutex_unlock(\u0026amp;cache-\u0026gt;lock); return current-\u0026gt;value; } current = current-\u0026gt;next; } pthread_mutex_unlock(\u0026amp;cache-\u0026gt;lock); return NULL; } 写缓存 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 void write_cache(Cache* cache, const char* key, const char* value) { // 初始化Entry CacheEntry* entry = (CacheEntry*)malloc(sizeof(CacheEntry)); entry-\u0026gt;key = strdup(key); entry-\u0026gt;value = strdup(value); entry-\u0026gt;next = NULL; entry-\u0026gt;prev = NULL; pthread_mutex_lock(\u0026amp;cache-\u0026gt;lock); // 查找是否已存在相同的 key CacheEntry* current = cache-\u0026gt;head; while (current != NULL) { if (strcmp(current-\u0026gt;key, key) == 0) {// 更新值 free(current-\u0026gt;value); current-\u0026gt;value = strdup(value); pthread_mutex_unlock(\u0026amp;cache-\u0026gt;lock); return; } current = current-\u0026gt;next; } // 插入新节点到链表头部 entry-\u0026gt;next = cache-\u0026gt;head; if (cache-\u0026gt;head != NULL) { cache-\u0026gt;head-\u0026gt;prev = entry; } else { cache-\u0026gt;tail = entry; } cache-\u0026gt;head = entry; // 如果超过容量限制，删除尾部节点 if (cache-\u0026gt;size == cache-\u0026gt;capacity) { CacheEntry* tail = cache-\u0026gt;tail; cache-\u0026gt;tail = tail-\u0026gt;prev; cache-\u0026gt;tail-\u0026gt;next = NULL; free(tail-\u0026gt;key); free(tail-\u0026gt;value); free(tail); } else { cache-\u0026gt;size++; } pthread_mutex_unlock(\u0026amp;cache-\u0026gt;lock); } 评价：最后一个实验满分的要求还是很低的。由于c语言编程实在繁琐，👴这个实验追求的是满分前提下的代码极简主义。\n结束了吗 实际上，生产级代理服务器需要考虑的远比本实验复杂几个数量级，在此提出几个思路以抛砖引玉：\n完备的协议支持： tiny仅支持GET方法，且不支持请求头，这实际上是被称为HTTP 0.9的一个历史版本。而目前最广泛使用的HTTP 1.1，为了实现对它的兼容，需要实现以下特性： 增加HEAD、POST方法，支持头域（HTTP 1.0中被引入） 支持Keep-Alive头，满足http请求重用tcp连接 支持Transfer-Encoding: chunked头，实现分块传输编码，满足大文件请求的需求 支持Accept-Ranges头，实现字节范围请求 支持请求流水线等其他特性 虽然实现HTTP协议是服务器的任务，但是对代理服务器的稳健性提出了更高的要求。 另外，本实验实现的proxy基本上是明文http代理。然而在实际应用中https才是更常用的协议。为此代理需要实现对TLS的支持。 更高的性能 我们完全可以自己修改评分脚本，把对缓存的考察上点强度。为了满足更高的性能，需要更高效的数据结构，如： 使用信号量代替互斥锁，使用读者写者模型 使用哈希表，红黑树等高级数据结构，提高查询速度 从更实际的开发的角度，不必将目光局限于c语言。有大量的其他语言生态的高性能库供我们挑选。 加密传输 保密性也是一个重要需求。更常见的代理架构是客户端和服务器都运行着代理服务器进程，在本地代理和远程代理之间运行着私有的加密通信协议。(Shadowsocks(R), VMess/VLess, Trojan\u0026hellip;) 路由规则 本地代理统管着所有出网流量，但客户端不希望所有请求都经过代理。为此需要为不同目标的流量设计不同的路由规则。 另一方面，客户端还希望管理多个代理服务器(clash) VPN和代理服务器原理不同，VPN是如何实现路由的？ 猫鼠游戏 想象你是局域网管理员，你观察到网络中某些IP的大部分流量都集中至一个外部IP的特定高位端口，你能否判断这些IP存在异常行为？ 你观察到某些IP的流量不再通往高位端口了，反而都是通往443端口的https流量，该外部IP运行着一个简单的网站，如何判断？ 详情自行搜索相关论文。关键词：GFW ","date":"2023-10-05T00:00:03Z","permalink":"https://lonelyuan.github.io/p/csapp-proxylab/","title":"CSAPP - Proxylab"},{"content":" 本系列是学习《Fuzzing101 with LibAFL》系列博客（后文统称：原博客）的笔记分享，在学习介绍 LibAFL 用法的同时总结 Rust 知识点。\n前置知识： fuzz基本概念、AFL基本使用 本篇要点：\nLibAFL Forkserver模式: Sugar API AFL tools：afl-cmin、optmin、afl-tmin、afl-cov 字段固定 Rust Builder clap Execise-3 source \u0026amp; corpus 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # tcpdump wget https://github.com/the-tcpdump-group/tcpdump/archive/refs/tags/tcpdump-4.9.1.tar.gz tar -xzvf tcpdump-4.9.1.tar.gz mv tcpdump-tcpdump-4.9.1 tcpdump rm tcpdump-4.9.1.tar.gz # tcpdump的依赖pcap wget https://github.com/the-tcpdump-group/libpcap/archive/refs/tags/libpcap-1.8.0.tar.gz tar -xzvf libpcap-1.8.0.tar.gz mv libpcap-libpcap-1.8.0/ libpcap rm libpcap-1.8.0.tar.gz # 用scapy生成corpus ## 原文使用poetry,直接pip也可 pip install scapy python create-bootp.py # 本篇没用到qemu，但依然需要这个依赖 apt-get install -y ninja-build Makefile.toml 还是熟悉的配方，还是熟悉的cargo make build。还是不熟悉的bug。。。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 [tasks.build] dependencies = [ \u0026#34;build-cargo\u0026#34;, \u0026#34;copy-project-to-build\u0026#34;, \u0026#34;build-libpcap\u0026#34;, \u0026#34;build-tcpdump\u0026#34;, ] [tasks.build-cargo] command = \u0026#34;cargo\u0026#34; args = [\u0026#34;build\u0026#34;, \u0026#34;--release\u0026#34;] [tasks.copy-project-to-build] script = \u0026#34;\u0026#34;\u0026#34; mkdir -p build/ cp ../target/release/exercise-3 build/ sudo setcap cap_sys_admin+epi build/exercise-3 \u0026#34;\u0026#34;\u0026#34; [tasks.build-libpcap] env = { \u0026#34;CC\u0026#34; = \u0026#34;afl-clang-lto\u0026#34;, \u0026#34;LLVM_CONFIG\u0026#34; = \u0026#34;llvm-config-15\u0026#34;, \u0026#34;AFL_MAP_SIZE\u0026#34; = \u0026#34;86217\u0026#34;, \u0026#34;AFL_USE_ASAN\u0026#34; = \u0026#34;1\u0026#34; } cwd = \u0026#34;libpcap\u0026#34; script = \u0026#34;\u0026#34;\u0026#34; ./configure --enable-shared=no --prefix=\u0026#34;${CARGO_MAKE_WORKING_DIRECTORY}/../build/\u0026#34; make make install \u0026#34;\u0026#34;\u0026#34; [tasks.build-tcpdump] cwd = \u0026#34;tcpdump\u0026#34; script = \u0026#34;\u0026#34;\u0026#34; ./configure --prefix=\u0026#34;${CARGO_MAKE_WORKING_DIRECTORY}/../build/\u0026#34; make make install sudo setcap cap_sys_admin+epi ../build/sbin/tcpdump mkdir -p ../solutions \u0026#34;\u0026#34;\u0026#34; [tasks.build-tcpdump.env] \u0026#34;CC\u0026#34; = \u0026#34;afl-clang-lto\u0026#34; \u0026#34;LLVM_CONFIG\u0026#34; = \u0026#34;llvm-config-15\u0026#34; \u0026#34;AFL_USE_ASAN\u0026#34; = \u0026#34;1\u0026#34; \u0026#34;AFL_MAP_SIZE\u0026#34; = \u0026#34;86217\u0026#34; \u0026#34;CFLAGS\u0026#34; = \u0026#34;-I${CARGO_MAKE_WORKING_DIRECTORY}/../build/include/\u0026#34; \u0026#34;LDFLAGS\u0026#34; = \u0026#34;-L${CARGO_MAKE_WORKING_DIRECTORY}/../build/lib/\u0026#34; 补充：Linux中的Capability机制 只有root和普通进程的权限管理不够灵活，普通进程要么什么都不能做，要么sudo什么都能做。于是将root特权分割成诸多能力Capability。\n进程拥有三组能力集：\ncap_effective：可用能力集 cap_inheritable：可继承能力集 cap_permitted：最大能力集 可执行文件也有三组能力集，与进程对应：\ncap_effective： cap_allowed：可继承的能力集 cap_forced：必须拥有才能执行的能力集 均可简记为eip。setcap是配置Capability的工具，其操作类似chmod。\nDebug: build-libpcap 啥叫 -ldw 1 2 = note: /usr/bin/ld: cannot find -ldw: No such file or directory collect2: error: ld returned 1 exit status -ldw代表libdw.so，apt安装即可 我afl-clang-lto呢 1 2 3 configure:2853: afl-clang-lto --version \u0026gt;\u0026amp;5 ./configure: line 2855: afl-clang-lto: command not found configure:2864: $? = 127 让CC指向AFLpulsplus里面的afl-clang-lto。切记要绝对路径 你根本不在bpf/net 1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ make --debug Reading makefiles... Updating makefiles.... Updating goal targets.... File \u0026#39;all\u0026#39; does not exist. File \u0026#39;libpcap.a\u0026#39; does not exist. Prerequisite \u0026#39;grammar.c\u0026#39; is newer than target \u0026#39;grammar.h\u0026#39;. Must remake target \u0026#39;grammar.h\u0026#39;. Successfully remade target file \u0026#39;grammar.h\u0026#39;. File \u0026#39;bpf_filter.o\u0026#39; does not exist. File \u0026#39;bpf_filter.c\u0026#39; does not exist. File \u0026#39;bpf/net/bpf_filter.c\u0026#39; does not exist. Must remake target \u0026#39;bpf/net/bpf_filter.c\u0026#39;. make: *** No rule to make target \u0026#39;bpf/net/bpf_filter.c\u0026#39;, needed by \u0026#39;bpf_filter.c\u0026#39;. Stop. 好熟悉的bug，👴模糊的记得之前捣鼓别的fuzzer的时候好像也遇到过，但是👴清楚的记得当时我没解决。\n于是，👴开始排查是否有依赖缺失，sudo apt-get install libpcap-dev，没用。总不能是 WSL 内核就少点东西吧，我都WSL2了。\n又回头看了看源码，发现 libpcap 的 Github 上有一份bpf_filter.c，而作者给的fuzzing-101-solution里面没有。👴直接上libpacp仓库复制，没用。\n再看看 fuzzing-101 仓库，他用的是 libpacp1.80 版本，👴去翻仓库的标签，果然1.8版本有bpf/net/bpf_filter.c。破案了。👴直接进行一个issue的提。\n后面一步没报错。偶剋~\n1 2 3 4 5 6 7 8 $ ./build/sbin/tcpdump --h tcpdump version 4.9.1 libpcap version 1.8.0 OpenSSL 3.0.2 15 Mar 2022 Compiled with AddressSanitizer/CLang. $ ./build/sbin/tcpdump -r corpus/bootp-testcase.pcap reading from file corpus/bootp-testcase.pcap, link-type IPV4 (Raw IPv4) 15:11:03.147545 IP localhost.bootps \u0026gt; 127.1.1.1.bootpc: BOOTP/DHCP, Request from 00:00:00:00:00:00 (oui Ethernet), length 236 fuzzer 1 2 3 4 5 6 7 8 9 10 11 12 13 14 fn main() { let parsed_opts = parser::parse_args(); let cores = Cores::from_cmdline(\u0026amp;parsed_opts.cores).expect(\u0026#34;Failed to parse cores\u0026#34;); ForkserverBytesCoverageSugar::\u0026lt;86217\u0026gt;::builder() .input_dirs(\u0026amp;[parsed_opts.input]) .output_dir(parsed_opts.output) .cores(\u0026amp;cores) .program(parsed_opts.target) .debug_output(parsed_opts.debug) .arguments(\u0026amp;parsed_opts.args) .build() .run() } Sugar API to simplify the life of the naive user of LibAFL\nLibAFL贴心的为我这种 naive user 准备了一条龙服务，提供了 Sugar API 将前两篇的样板代码进一步简化。好的，fuzzer写完了。\nRust 基础之 Builder parser.rs 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #[derive(Parser, Debug)] pub struct FuzzerOptions { #[clap(short, long, default_value = \u0026#34;solutions\u0026#34;)] pub output: PathBuf, #[clap(short, long, default_value = \u0026#34;corpus\u0026#34;, multiple_values = true)] pub input: PathBuf, #[clap(short, long)] pub cores: String, #[clap(short, long, required = true, takes_value = true)] pub target: String, #[clap(short, long)] pub debug: bool, #[clap( short, long, allow_hyphen_values = true, multiple_values = true, takes_value = true )] pub args: Vec\u0026lt;String\u0026gt;, } pub fn parse_args() -\u0026gt; FuzzerOptions { FuzzerOptions::parse() } 这里使用了 clap 库来解析命令行参数，转换为数据结构FuzzerOptions。\nRust 基础之 注解 跑🏃‍ 直接跑是很dumb的，迟迟跑不出结果。这里先抄个答案\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 $ ./build/sbin/tcpdump -r corpus/bootp_asan.pcap -v [2:27:14] reading from file corpus/bootp_asan.pcap, link-type EN10MB (Ethernet) 08:00:00.000000 IP (tos 0x0, ttl 252, id 40207, offset 0, flags [+, DF, rsvd], proto UDP (17), length 60951, bad cksum ff (-\u0026gt;8336)!) ================================================================= ==23730==ERROR: AddressSanitizer: heap-buffer-overflow on address 0x6060000000b4 at pc 0x56339a3e4010 bp 0x7fffaf70f850 sp 0x7fffaf70f848 READ of size 2 at 0x6060000000b4 thread T0 #0 0x56339a3e400f in bootp_print /home/czy/fuzzing-101-solutions/exercise-3/tcpdump/./print-bootp.c:325:2 #1 0x56339a46960a in ip_print_demux /home/czy/fuzzing-101-solutions/exercise-3/tcpdump/./print-ip.c:387:3 #2 0x56339a47008b in ip_print /home/czy/fuzzing-101-solutions/exercise-3/tcpdump/./print-ip.c:658:3 #3 0x56339a4207c2 in ethertype_print /home/czy/fuzzing-101-solutions/exercise-3/tcpdump/./print-ether.c:333:10 #4 0x56339a41e731 in ether_print /home/czy/fuzzing-101-solutions/exercise-3/tcpdump/./print-ether.c:236:7 #5 0x56339a36bff1 in pretty_print_packet /home/czy/fuzzing-101-solutions/exercise-3/tcpdump/./print.c:339:18 #6 0x56339a36bff1 in print_packet /home/czy/fuzzing-101-solutions/exercise-3/tcpdump/./tcpdump.c:2506:2 #7 0x56339a74458a in pcap_offline_read /home/czy/fuzzing-101-solutions/exercise-3/libpcap/./savefile.c:507:4 #8 0x56339a362050 in pcap_loop /home/czy/fuzzing-101-solutions/exercise-3/libpcap/./pcap.c:875:8 #9 0x56339a362050 in main /home/czy/fuzzing-101-solutions/exercise-3/tcpdump/./tcpdump.c:2009:12 答案是管用的，但是直接丢进 Libafl 却没有crash。\n优化 目前的fuzzer原作者跑了一晚上啥也没跑出来，由此引入一些优化方法。\n语料库压缩：optmin optmin 是 afl-tmin 的优化版。将语料库中触发重复路径的部分最小化，有助于fuzzer减少重复尝试。这里的语料库在/solutions/queue，也就是AFL执行过若干轮后的。\n1 2 3 4 5 6 7 # build cd AFLplusplus/utils/optimin ./build_optimin.sh mv optimin ../../../exercise-3 # run cp -r solutions/queue/* queue_for_cmin AFL_MAP_SIZE=86217 ASAN_OPTIONS=abort_on_error=1 ./optimin -f -i queue_for_cmin -o cminnified ./build/sbin/tcpdump -vr @@ 样例压缩：afl-tmin 另一方面，tmin对单个输入进行压缩，减小文件大小也有助于提高效率。\n1 2 3 4 5 6 7 # build cd AFLplusplus/ make afl-tmin mv afl-tmin ../exercise-3 # run cp -r solutions/queue/* queue_for_cmin AFL_MAP_SIZE=86217 ASAN_OPTIONS=abort_on_error=1 ./optimin -f -i queue_for_cmin -o cminnified ./build/sbin/tcpdump -vr @@ 覆盖率观察：afl-cov 然而这种常规优化还是没能有突破，原作者决定观察一下那些代码还没有被覆盖。安装覆盖率工具afl-cov相对比较繁琐：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 export HOME=/fuzzing-101-solutions/exercise-3/ cd $home # 安装afl-cov sudo apt install lcov git clone https://github.com/vanhauser-thc/afl-cov.git # 移动源代码 mkdir exercise-3-gcov exercise-3-gcov/build cp -r exercise-3/libpcap exercise-3-gcov cp -r exercise-3/tcpdump exercise-3-gcov cp -r exercise-3/solutions exercise-3-gcov # 清理lock文件 cd exercise-3-gcov/solutions/queue find * -empty -delete # lcov 需要文件名仅为6位 ## 原博客用的python脚本，👴直接请教 new bing for i in *; do mv -v \u0026#34;$i\u0026#34; \u0026#34;${i: -6}\u0026#34; done # 编译带 cov 的 libpcap cd $home/exercise-3-gcov/libpcap make clean /opt/afl-cov/afl-cov-build.sh -c ./configure --prefix=$(pwd)/../build; make make install # 编译带 cov 的 tcpdump cd $home/exercise-3-gcov/tcpdump make clean CFLAGS=-I$(pwd)/../build/include/ LDFLAGS=-L$(pwd)/../build/lib/ /opt/afl-cov/afl-cov-build.sh -c ./configure --prefix=$(pwd)/../build ; make make install sudo setcap cap_sys_admin+epi ../build/sbin/tcpdump # 执行 /opt/afl-cov/afl-cov.sh -c solutions \u0026#34;./build/sbin/tcpdump -vr @@\u0026#34; 观察到根本运行不到目标CVE所在的文件。\n固定输入 最后原作者决定改 Libafl 源码，在变异之前往里塞固定了的 BOOTY 头。但是👴的 LibAFL 源代码和原博客中有些微区别，虽然版本号一样：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ///libafl/src/executors/forkserver.rs:438 if self.executor.uses_shmem_testcase() { let shmem = unsafe { self.executor.shmem_mut().as_mut().unwrap_unchecked() }; let target_bytes = input.target_bytes(); let size = target_bytes.as_slice().len(); let size_in_bytes = size.to_ne_bytes(); // The first four bytes tells the size of the shmem. shmem.as_mut_slice()[..4].copy_from_slice(\u0026amp;size_in_bytes[..4]); shmem.as_mut_slice()[SHMEM_FUZZ_HDR_SIZE..(SHMEM_FUZZ_HDR_SIZE + size)] .copy_from_slice(target_bytes.as_slice()); } else { self.executor .input_file_mut() .write_buf(input.target_bytes().as_slice())?; } 不过还是找到了对应的位置，向write_buf()插入固定的头部即可。\n👴觉得这样不够优雅，于是寻思能否进行一个类重写。\n【To be continue】\n","date":"2023-08-02T02:00:36+08:00","permalink":"https://lonelyuan.github.io/p/libafl-fuzzing101-3/","title":"libAFL速通Fuzzing101 (3)"},{"content":" 本系列是学习《Fuzzing101 with LibAFL》系列博客（后文统称：原博客）的笔记分享，在学习介绍 LibAFL 用法的同时总结 Rust 知识点。\n前置知识： fuzz基本概念、AFL基本使用 本篇要点：\nLibAFL Inprocess模式 Harness 编译器wrapper LLPM，多核并行 漏洞分类：AFLTriage Rust 函数、闭包 match 模式识别 Option、Result Execise-1.5 Execise-1 中编写的fuzzer十分甚至九分的简陋，距离实际应用还相差甚远。原博客在1.5集中列举了三种优化方法：\n使用afl-clang-lto 代替 afl-clang-fast—— fast 1.1x afl-clang-lto(link time optimization): 实现无碰撞插桩 使用 共享内存 干掉 文件I/O —— fast 3x patch源代码，加入__AFL_FUZZ_INIT();宏 使用InProcessExecutor 换掉 ForkserverExecutor—— fast 10x patch源代码，编写harness function和compiler wraper 由于 Execise-1 的目标xpdf是命令行程序，不是库，故需要做一定修改使其支持静态链接。其操作较为繁琐，涉及make迁移到cmake等，建议有需求时自行研究。\n而 Execise-2 的目标libexif本身是一个库，不如借助 Execise-2 学习harness。\n所以什么是harness？ Harness v. 控制并利用；（把动物）拴在一起（或拴到某物上）；给（马）套上挽具；连接，串联 n. （马的）挽具，马具；系带，吊带；日常工作\n在面对一个库时，并没有现成的入口点，因此需要写一个函数来调用它，这个函数就是 harness。此时，harness成为了与fuzzer直接交互的目标。 也就是说，fuzzer是横冲直撞的野马，target是一望无际的草原，harness则是指引方向的缰绳。\n使用harness时，fuzzer的所有工作将在一个进程中完成，即InProcess。这对性能有以下好处：\n可以直接通过harness的编写促使fuzzer探索我们感兴趣的部分 与fork-server不同，进程内执行免去了进程管理的负担，这一点显著提升了性能 单进程模式天然支持多核，（一个fuzzer实例一个cpu核心）对现代多核处理器友好 那么代价是什么？由于harness将在一个进程中被反复执行，harness应满足以下要求：\n不能有内存泄漏，否则将会对fuzzer本身造成破坏。 不要执行exit()。这会结束当前进程，应该发送abort以供fuzzer重启 避免高算法复杂度，避免大量内存占用，避免日志输出等拖慢速度的行为 是不是摩拳擦掌了呢？让我们重新加入战斗吧！\nExecise-2 libexif source \u0026amp; corpus 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # libexif的依赖 apt-get install autopoint libtool gettext libpopt-dev # 下载源码 wget https://github.com/libexif/libexif/archive/refs/tags/libexif-0_6_14-release.tar.gz tar -xf libexif-0_6_14-release.tar.gz mv libexif-libexif-0_6_14-release libexif # 准备corpus mkdir corpus solutions cd corpus git clone --no-checkout --filter=blob:none https://github.com/libexif/libexif.git cd libexif ## 只留图片 git checkout master -- test/testdata mv test/testdata/*.jpg ../ cd .. rm -rvf libexif Cargo.toml 在InProcess模式中，需要编译器把fuzzer，target，harness全部链接到一起。故以库的形式创建项目：\ncargo new --lib exercise-2 同时，本篇也用到了Libafl的全部组件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # execise-2/Cargo.toml [package] name = \u0026#34;exercise-2\u0026#34; version = \u0026#34;0.1.0\u0026#34; edition = \u0026#34;2021\u0026#34; [dependencies] libafl = { version = \u0026#34;0.10.1\u0026#34; } # libafl core libafl_cc = { version = \u0026#34;0.10.1\u0026#34; } # compiler wrapper libafl_targets = { version = \u0026#34;0.10.1\u0026#34;, features = [ \u0026#34;libfuzzer\u0026#34;, \u0026#34;sancov_pcguard_hitcounts\u0026#34;, \u0026#34;sancov_cmplog\u0026#34;, ] } # common code for targets instrumentation [lib] name = \u0026#34;exercisetwo\u0026#34; crate-type = [\u0026#34;staticlib\u0026#34;] # 生成 libexercisetwo.a cargo-make 使用build.rs能够增加自动化程度，但用rust写shell依旧略显繁琐。于是原博客引入了 cargo-make 工具，在cargo原本的Cargo.toml基础上加入了Makefile.toml，用以自定义配置，构建自动化工作流。 类似于Makefile，又有点像docker-compose.yml。\n安装：cargo install --force cargo-make 如下所示，既可以执行cargo make build一句话跑通全部，也可单独执行cargo make build-libexif，十分灵活。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # execise-2/Makefile.toml [tasks.build] dependencies = [\u0026#34;clean\u0026#34;, \u0026#34;build-compilers\u0026#34;, \u0026#34;copy-project-to-build\u0026#34;, \u0026#34;build-libexif\u0026#34;, \u0026#34;build-fuzzer\u0026#34;] [tasks.build-compilers] command = \u0026#34;cargo\u0026#34; args = [\u0026#34;build\u0026#34;, \u0026#34;--release\u0026#34;] [tasks.copy-project-to-build] script = \u0026#34;\u0026#34;\u0026#34; mkdir -p build/ cp ${CARGO_MAKE_WORKING_DIRECTORY}/../target/release/ex2_compiler build/ cp ${CARGO_MAKE_WORKING_DIRECTORY}/../target/release/libexercisetwo.a build/ \u0026#34;\u0026#34;\u0026#34; [tasks.build-fuzzer] cwd = \u0026#34;build\u0026#34; command = \u0026#34;./ex2_compiler\u0026#34; args = [\u0026#34;-I\u0026#34;, \u0026#34;../libexif/libexif\u0026#34;, \u0026#34;-I\u0026#34;, \u0026#34;../libexif\u0026#34;, \u0026#34;-o\u0026#34;, \u0026#34;fuzzer\u0026#34;, \u0026#34;../harness.c\u0026#34;, \u0026#34;lib/libexif.a\u0026#34;] # -Idir 增加dir为头文件的搜索路径 [tasks.build-libexif] cwd = \u0026#34;libexif\u0026#34; env = { \u0026#34;CC\u0026#34; = \u0026#34;/fuzzing101/exercise-2/build/ex2_compiler\u0026#34;, \u0026#34;LLVM_CONFIG\u0026#34; = \u0026#34;llvm-config-15\u0026#34;} script = \u0026#34;\u0026#34;\u0026#34; autoreconf -fi ./configure --enable-shared=no --prefix=\u0026#34;${CARGO_MAKE_WORKING_DIRECTORY}/../build/\u0026#34; make -i make install -i \u0026#34;\u0026#34;\u0026#34; 看起来清爽多了（此时👴还没有意识到问题的严重性）。\n补充：Linux开发工具链 ./configure 配置: 根据Makefile.in模板和系统信息生成Makefile make 编译：根据Makefile将源代码编译成可执行文件 make install 安装：将可执行文件复制到正确的地方\nautoreconf：属于 autotools 工具链，也是生成makefile的自动化工具。后逐渐被cmake取代。（现在流行的是Ant？） harness \u0026amp; compiler harness.c harness的核心，也就是被fuzzer调用的位置，是LLVMFuzzerTestOneInput()函数。 其输入是一个字节数组和其尺寸。主流fuzzer都接受这个函数声明，或许是因为他们后端都用的LLVM的Libfuzzer吧。\n在Libexif的test目录下有test-fuzzer-persistent.c，是一个适用于AFL持久模式的harness。稍加改造即可：\n删除 AFL 宏 删除任何打印/日志语句 将 main() 重命名为 LLVMFuzzerTestOneInput() 修复其他版本问题 compiler.rs 显然，这部分并没有让我们写一个编译器，而是一个套壳，一层包装(wrapper)。 这里将target与fuzzer静态链接在一起，并加入-fsanitize=address参数以使用ASAN。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // exercise-2/src/bin/ex2_compiler.rs pub fn main() { let cwd = env::current_dir().unwrap(); let args: Vec\u0026lt;String\u0026gt; = env::args().collect(); let mut cc = ClangWrapper::new(); if let Some(code) = cc .cpp(false) .silence(true) .parse_args(\u0026amp;args) .expect(\u0026#34;Failed to parse the command line\u0026#34;) .link_staticlib(\u0026amp;cwd, \u0026#34;exercisetwo\u0026#34;) .add_arg(\u0026#34;-fsanitize-coverage=trace-pc-guard\u0026#34;) .add_arg(\u0026#34;-fsanitize=address\u0026#34;) .run() .expect(\u0026#34;Failed to run the wrapped compiler\u0026#34;) { std::process::exit(code); } } 开始编写fuzzer之前，根据项目的文件结构梳理一下编译逻辑：\nbuild-compilers: 生成自己的编译器：编译时链接fuzzer库。 build-libexif：用自己的编译器编译target build-fuzzer：用自己的编译器编译harness，并链接target库 1 2 3 4 5 6 7 8 9 10 |-- Cargo.toml |-- Makefile.toml |-- corpus |-- harness.c |-- libexif |-- solutions `-- src |-- bin | `-- ex2_compiler.rs `-- lib.rs Libafl: Inprocess模式 组件：Observer \u0026amp; Feedback 由于我们使用的不再是afl-clang-fast，而是使用自己的编译器wrapper。故__AFL_SHM_ID已经不好使了。好在libafl_targets提供了EDGES_MAP：std_edges_map_observer。\n1 2 let edges_observer = HitcountsMapObserver::new(unsafe{std_edges_map_observer(\u0026#34;edges\u0026#34;)}); 此外，简单的超时反馈也改为了真正的崩溃反馈：CrashFeedback。\n1 2 let mut objective = feedback_and_fast!(CrashFeedback::new(), MaxMapFeedback::new(\u0026amp;edges_observer)); 组件：Monitor \u0026amp; EventManager \u0026amp; Status EventManager 在 Inprocess 模式中才真正发挥功用。对于多实例环境，通信问题必须解决。LibAFL设计了一套低级消息传递协议(LLMP)，使用C-S架构，第一个执行的fuzzer作为代理(Broker)，后续执行的均作为客户端(Client)。Client负责不断执行，将信息汇总与Broker综合展示。\n此外， Inprocess 模式还必须设定进程的重启，setup_restarting_mgr_std第一次执行中返回(None, LlmpRestartingEventManager)，后续则返回上一个进程留下的状态，以此实现状态的永续。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 let monitor = MultiMonitor::new(|s| { println!(\u0026#34;{}\u0026#34;, s); }); // MultiMonitor: 同时支持Broker模式或Client模式 let (state, mut mgr) = match setup_restarting_mgr_std(monitor, 1337, EventConfig::AlwaysUnique){ Ok(res) =\u0026gt; res, Err(err) =\u0026gt; match err { Error::ShuttingDown =\u0026gt; { return Ok(()); } _ =\u0026gt; { panic!(\u0026#34;Failed to setup the restarting manager: {}\u0026#34;, err); } }, }; let mut state = state.unwrap_or_else(|| { StdState::new( StdRand::with_seed(current_nanos()), input_corpus, solutions_corpus, \u0026amp;mut feedback, \u0026amp;mut objective, ).unwrap() }); Rust 基础之函数返回值、模式匹配与错误处理 本例中的mgr是一个经典的match用法，用match处理函数的返回值。下面把概念和符号捋一遍：\n函数 Rust 的函数体由一系列语句组成，最后由表达式结尾。必须严格分别表达式和语句。因为表达式代表一个返回值，而语句不返回。\n1 2 3 4 fn FUNC(PARAM: TYPE, PARAM: TYPE, ...) -\u0026gt; RETURN_TYPE { STATEMANT; EXPRESSION } ;: 标识一条语句。表达式没有分号。 !: 标识发散函数(diverge function)，没有返回值。如println!(\u0026quot;{}\u0026quot;, s)，panic!() panic!(): 线程恐慌。单线程程序即报错退出。 (): 空元组，不占用内存。无返回值时的返回值。 模式匹配 match相当于switch的加强版：\n1 2 3 4 5 match VALUE { PATTERN =\u0026gt; EXPRESSION, PATTERN =\u0026gt; EXPRESSION, ... } _: 表示剩余情况的PATTERN。 exhaustive特性：变量的所有可能性必须全部被覆盖。 错误处理 函数返回值常用两类泛型枚举进行包装：\n1 2 3 4 5 6 7 8 pub enum Option\u0026lt;T\u0026gt; { // 可选值 None, // 可以没有值。适用于许多情况：初始值，可选参数，错误(不会panic!) Some(T), // 必须有值 } enum Result\u0026lt;T, E\u0026gt; { // 返回值 Ok(T), Err(E), // Err可以不panic! } Rust对Result实现了许多方便的方法，详情请参阅文档。\nunwrap()：解包Result，才能获取值 对None执行则panic! ?：语法糖，将Err对象传播出来，进一步使代码简洁。 1 2 3 4 5 let result = match FUNC() { Err(e) =\u0026gt; return Err(e), Ok(f) =\u0026gt; f, }; let result = FUNC()?; //等价写法 参考文档：\nhttps://rustwiki.org/zh-CN/std/option/index.html https://rustwiki.org/zh-CN/std/result/index.html 组件：Harness \u0026amp; Executor 在fuzzer侧，LLVMFuzzerTestOneInput()对应libfuzzer_test_one_input()函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 let mut harness = |input: \u0026amp;BytesInput| { let target = input.target_bytes(); let buffer = target.as_slice(); libfuzzer_test_one_input(buffer); ExitKind::Ok }; let in_proc_executor = InProcessExecutor::new( \u0026amp;mut harness, tuple_list!(edges_observer, time_observer), \u0026amp;mut fuzzer, \u0026amp;mut state, \u0026amp;mut mgr, ).unwrap(); fuzzer写完了，善！\nRust 基础之闭包 闭包(closure)，一般语言的闭包就是 lambda 表达式或匿名函数，在Rust中还要加上捕获外部环境中的变量的能力。\n闭包捕获变量的方式分为三类：按顺序捕获\nFn：表示捕获方式为通过不可变引用（\u0026amp;T）的闭包 FnMut：表示捕获方式为通过可变引用（\u0026amp;mut T）的闭包 FnOnce：表示捕获方式为通过值（T）的闭包 实际上，闭包就是这三种Trait的语法糖。关于Trait目前大致理解成某种规定泛型对象的行为的东西。如上面的三类函数，不同程度上约束了泛型。深度内容留待后文学习。\n究竟何为“捕获”？Rust是没有垃圾回收的语言，取而代之的是生命周期。引用时，会自动分析变量生命周期，以决定使用哪个Trait。\n还可以使用关键字move强制转移所有权到闭包中\n参考文档：https://rustwiki.org/zh-CN/rust-by-example/fn/closures/capture.html\n跑🏃‍ 使用ASAN很快就发现了崩溃：\n1 2 3 4 5 6 7 8 [AFL++ ae703a5ce157] /fuzzing101/exercise-2 # taskset -c 4 ./build/fuzzer [Broker #0] (GLOBAL) run time: 0h-0m-57s, clients: 0, corpus: 0, objectives: 0, executions: 0, exec/sec: 0.000 (CLIENT) corpus: 0, objectives: 0, executions: 0, exec/sec: 0.000 -------------8\u0026lt;------------- [Stats #3] (GLOBAL) run time: 0h-1m-0s, clients: 4, corpus: 3, objectives: 0, executions: 6, exec/sec: 0.000 (CLIENT) corpus: 3, objectives: 0, executions: 6, exec/sec: 0.000, edges: 9/10 (90%) [Testcase #3] (GLOBAL) run time: 0h-1m-0s, clients: 4, corpus: 4, objectives: 0, executions: 8, exec/sec: 0.000 (CLIENT) corpus: 4, objectives: 0, executions: 8, exec/sec: 0.000, edges: 9/10 (90%) Debug：我log去哪了 但结果并不让人满意，起因是cargo make build执行并未成功，上述结果是手动编译得到。报错如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [cargo-make] INFO - Running Task: build-libexif -------------8\u0026lt;------------- checking for a BSD-compatible install... /usr/bin/install -c checking whether build environment is sane... yes checking for a race-free mkdir -p... /usr/bin/mkdir -p checking for gawk... no checking for mawk... mawk checking whether make sets $(MAKE)... yes checking whether make supports nested variables... yes checking for POSIX sh $() command substitution... yes checking for gcc... /fuzzing101/exercise-2/build/ex2_compiler checking whether the C compiler works... no configure: error: in `/fuzzing101/exercise-2/libexif\u0026#39;: configure: error: C compiler cannot create executables See `config.log\u0026#39; for more details [cargo-make] ERROR - Error while executing command, exit code: 77 [cargo-make] WARN - Build Failed. 它提示我，我的编译器不大好使。但是较为离谱的是手动执行编译却没问题。 那么我们看看config.log吧，然后就有个问题，config.log到底藏哪了。\n👴：你根本不在工作目录，你躲哪去了 cargo make: 我不到啊\n这个幽灵问题折磨了我许久，直到我意识到Makefile.toml里面的clean选项。。。\n1 2 3 4 5 ... rest of stderr output deleted ... configure:3778: $? = 0 configure:3767: /fuzzing101/exercise-2/build/ex2_compiler -V \u0026gt;\u0026amp;5 clang: error: unsupported option \u0026#39;-V -g\u0026#39; clang: error: no such file or directory: \u0026#39;/fuzzing101/exercise-2/libexif/libexercisetwo.a\u0026#39; 虽然还是不理解为什么，但是照猫画虎把libexercisetwo.a放入就编译成功了。\nDebug：内存爆了！ 尽管很快跑出crash，但fuzzer经常崩溃退出，导致并没有crash保存。报错如下：\n1 2 3 4 thread \u0026#39;\u0026lt;unnamed\u0026gt;\u0026#39; panicked at \u0026#39;Fuzzer-respawner: Storing state in crashed fuzzer instance did not work, no point to spawn the next client! This can happen if the child calls `exit()`, in that case make sure it uses `abort()`, if it got killed unrecoverable (OOM), or if there is a bug in the fuzzer itself. (Child exited with: 9)\u0026#39;, /root/.cargo/registry/src/index.crates.io-6f17d22bba15001f/libafl-0.10.1/src/events/llmp.rs:1071:21 note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace fatal runtime error: failed to initiate panic, error 5 Aborted 报错告诉我们可能有以下原因：\nchild calls exit()：我跑的确实是ASAN_OPTIONS=abort_on_error=1 taskset -c 6 ./build/fuzzer fuzzer有bug：我可以不相信我自己，但我不能不相信 Rust。 OOM：内存溢出。观察下任务管理器，可以发现fuzzer执行后内存占用迅速飙升，在达到90%后fuzzer稳定崩溃退出。 那么基本确认是内存溢出的问题。👴的16G属实不堪大用，这下不得不买内存条了。\n那么基本确认问题无解了吗？👴开始怀疑问题出在Docker上。于是👴回到宿主机 WSL2 上重新配环境。还是在执行cp build/libexercisetwo.a libexif之后成功编译。\n这次能够稳定运行一段时间了，并且成功获得objective。👴就是个睿智。\n👴宣布实验2完成。\n成果落地 好吧还有最后一步。在诸多crash中可能有大量假阳性，大量重复漏洞，为了获得最终的CVE编号，还需要费时费力的辨别。AFLTriage 就是解决这个问题的自动化工具，它使用 GDB 并行的执行漏洞分类、 ASAN 解析和 crash 去重等工作。\nAFLTriage 的工作流程十分简单：将crash依次丢进target执行，并解读执行报告。 因此，首先要为harness添加一个main函数，使其调用一次LLVMFuzzerTestOneInput()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // harness.c #ifdef TRIAGE_TESTER int main(int argc, char* argv[]) { struct stat st; char *filename = argv[1]; stat(filename, \u0026amp;st); FILE *fd = fopen(filename, \u0026#34;rb\u0026#34;); char *buffer = (char *)malloc(sizeof(char) * (st.st_size)); fread(buffer, sizeof(char), st.st_size, fd); LLVMFuzzerTestOneInput(buffer, st.st_size); free(buffer); fclose(fd); } #endif 这里通过#ifdef宏指令和build选项对应，执行cargo make build-triager即可进入分类流程。\n1 2 3 4 [tasks.build-triager] cwd = \u0026#34;build\u0026#34; command = \u0026#34;./ex2_compiler\u0026#34; args = [\u0026#34;-D\u0026#34;, \u0026#34;TRIAGE_TESTER\u0026#34;, \u0026#34;-I\u0026#34;, \u0026#34;../libexif/libexif\u0026#34;, \u0026#34;-I\u0026#34;, \u0026#34;../libexif\u0026#34;, \u0026#34;-o\u0026#34;, \u0026#34;triager\u0026#34;, \u0026#34;../harness.c\u0026#34;, \u0026#34;lib/libexif.a\u0026#34;] 最后执行AFLTriage：../AFLTriage/target/release/afltriage -i ./solutions/ -o ./reports/ ./build/triager @@\n得到3个report：\n1 2 3 afltriage_ASAN_heap-buffer-overflow_READ_exif_entry_get_value_f8a5a368646cf8484298dd0549da6e12.txt afltriage_ASAN_unknown-crash_WRITE_exif_mnote_data_olympus_save_1e4a69a1a4d7585d8ae1e143a3b5eb94.txt afltriage_SIGSEGV___memmove_sse2_unaligned_erms_b1cfe4f5c38c4991e7c55dccdfb06372.txt 👴还有点怀疑ASAN的输出好像都是fuzzer里面的bug，但是阅读报告之后发现确实是target里面的。只是原博客的ASAN能够指出Target源代码的行号，👴的只能拿到二进制地址。\n1 2 3 4 5 6 7 8 9 10 11 12 Summary: ASAN detected heap-buffer-overflow in exif_entry_get_value after a READ leading to SIGABRT (si_signo=6) / SI_TKILL (si_code=-6) -------------8\u0026lt;------------- #10 0x0000555555695c85 in exif_entry_get_value (/home/czy/fuzzing-101-solutions/exercise-2/build/triager) 542: const exif_entry_get_value(e = (ExifEntry *)0x604000000350, val = (char *)\u0026lt;optimized out\u0026gt;, maxlen = (unsigned int)1999) { |||: |||: /* Local reference: ExifEntry * e = 0x604000000350; */ 682: */ 683: if (e-\u0026gt;size \u0026amp;\u0026amp; e-\u0026gt;data \u0026amp;\u0026amp; 684: (strspn ((char *)e-\u0026gt;data, \u0026#34; \u0026#34;) != strlen ((char *) e-\u0026gt;data))) |||: ---: } at exif-entry.c:684 只能说👴的环境还是有点毛病， WSL2 里面跑比 WSL2+Docker 里面跑，稳定运行时间长，但也不超过三分钟。👴只能手动断断续续的重新跑，这样fuzzer的状态其实是丢失了的。后面的实验还是别折腾我这个破本子了。\n而且跑出来的crash👴看着也不像预期要挖的那俩CVE。但是这些都不影响👴再次宣布实验2完成。\n","date":"2023-07-30T02:45:31+08:00","image":"https://lonelyuan.github.io/p/libafl%E9%80%9F%E9%80%9Afuzzing101-2/final_hu189931506a8648410d5552fb49660c91_955953_120x120_fill_box_smart1_3.png","permalink":"https://lonelyuan.github.io/p/libafl%E9%80%9F%E9%80%9Afuzzing101-2/","title":"libAFL速通Fuzzing101 (2)"},{"content":" 本系列是学习《Fuzzing101 with LibAFL》系列博客（后文统称：原博客）的笔记分享，在学习介绍 LibAFL 用法的同时总结 Rust 知识点。\n前置知识： fuzz基本概念、AFL基本使用 本篇要点：\nLibAFL 9大组件 Forkserver模式：简单组装 Rust Cargo 基本使用 变量所有权： 转移(move) 和 拷贝(copy) 引用(reference) 和 借用(borrowing) 是不是搞fuzz的都在搞rust Fuzzing101是大名鼎鼎的 Fuzzing 入门教程。👴之前搞过一点，故这次整点花活。看到有个叫epi052的大佬用 LibAFL 做 Fuzzing101，于是👴也跟着学一波rust。\nLibAFL是用 Rust 写的 Fuzzing 框架，主要贡献在于给出了一套 Fuzzer 的标准化定义，以此试图改善当今 Fuzzing 研究界成果倍出但互不兼容，经常重复造轮子的现象。\nLibAFL 隶属于 AFL++ 项目组，故需要先配置 AFL++ 。而 AFL++ 的官方 Docker 镜像就包含了 Rust 环境，所以使用 Docker 配 LibAFL 环境就只需一句话：\n1 2 docker pull aflplusplus/aflplusplus docker run -ti -v ./Fuzzing101:/fuzzing101 aflplusplus/aflplusplus Execise-1 xpdf 练习一主要是熟悉基本流程。使用AFL主要有以下步骤：\n目标编译插桩。如： 1 2 3 4 export LLVM_CONFIG=llvm-config-15 CC=afl-clang-fast CXX=afl-clang-fast++ ./configure --prefix=./install make make install 语料库准备 执行afl-fuzz Let\u0026rsquo;s see 如何用Rust完成上述步骤。\nRust 基础之cargo 在 Rust 中，可以用rustc编译单个文件，更常见的是使用包管理器cargo。\nCargo.toml 运行cargo new创建一个 package ，其中必有Cargo.toml，描述 package 如何构建。\n1 2 3 4 5 6 7 8 9 # execise-1/Cargo.toml [package] name = \u0026#34;exercise-1\u0026#34; version = \u0026#34;0.1.0\u0026#34; edition = \u0026#34;2021\u0026#34; build = \u0026#34;build.rs\u0026#34; [dependencies] libafl = \u0026#34;0.10.1\u0026#34; 本项目首先规定了构建脚本为build.rs，然后引入了 libafl 依赖。 运行cargo build时，Cargo 会自动处理依赖。(包括 crates.io 下载安装，我觉得这就是现代语言的一种自信)\nbuild.rs 构建脚本是为了方便 Rust 项目与第三方工具的集成。比如上文中目标编译的几条指令，就可以用 Rust std 库中的Command类来执行。\n1 2 3 4 5 6 // make clean; Command::new(\u0026#34;make\u0026#34;) .arg(\u0026#34;clean\u0026#34;) .current_dir(xpdf_dir.clone()) .status() .expect(\u0026#34;Couldn\u0026#39;t clean xpdf directory\u0026#34;); 使用构建脚本还有许多好处，可以利用 Cargo 采取更灵活的构建策略。构建脚本的输出可以被 Cargo 解释，只需打印以cargo: 开头的指令。如下面两行输出向 Cargo 表明仅在这两个文件发生改动时执行构建脚本。\n1 2 println!(\u0026#34;cargo:rerun-if-changed=build.rs\u0026#34;); println!(\u0026#34;cargo:rerun-if-changed=src/main.rs\u0026#34;); LibAFL 组装 上述还是甜点，下面进入正菜环节。 LibAFL 将 Fuzzer 定义为9个组件，分别是：\n摘自这篇博客。\nInput：程序的输入。 重点是格式，最常见的就是 byte array，也有AST等。 Corpus：输入和其附属元数据的存储。 存储有位于内存和位于硬盘两种，后者更广泛。输入也可分为有助于进化的 interesting testcase 和最终触发 crash 的 solution。 Scheduler：从 corpus 中选取 testcase 的调度策略。 最朴素的即先进先出或随机选择，也可引入优先级算法。 Stage：定义对 testcase 进行的操作（action）。 往往会进行多阶段的操作。如 AFL 中的 random havoc stage。 Observer：提供一次执行目标程序的信息。 常用的 coverage map 就是一种 observer。 Executor：用 fuzzer 的输入来执行目标程序。 不同 fuzzer 在这方面区别很大。 Feedback：将程序执行的结果分类以决定是否将其加入 corpus。 feedback 通常处理一个或多个 observer 报告的信息来判断 execution 是否 “interesting”，是否是满足条件的 solution，比如可观测的 crash。 Mutator：从一个或多个输入生成新的 testcase。 通常是最常改动的，不同 mutator 可以组合，往往还和特定的输入类型绑定。 Generator：凭空产生新的输入。 有随机生成的，也有 Nautilus 这种基于语法的。 除此之外，在 LibAFL 实现中还有若干重要组件：\nAPI文档 请 参阅\nState: 包含了运行时的所有元数据，包括 Corpus、RNG 等。 Bolts: 工具库，实现了诸如共享内存的支持。 Monitor: 向用户打印log之类。 Events: 组件之间通信 Fuzzer: 顶层组件，把一切组织起来 因原博客的讲解很详细，且提供了完整代码。故本文试图切换视角，从自顶向下的角度拆解代码：\n组件：Fuzzer 1 2 3 4 5 6 7 8 let monitor = SimpleMonitor::new(|s| println!(\u0026#34;{s}\u0026#34;)); let mut mgr = SimpleEventManager::new(monitor); let scheduler = IndexesLenTimeMinimizerScheduler::new(QueueScheduler::new()); let mutator = StdScheduledMutator::new(havoc_mutations()); let mut stages = tuple_list!(StdMutationalStage::new(mutator)); -------------8\u0026lt;------------- let mut fuzzer = StdFuzzer::new(scheduler, feedback, objective); fuzzer.fuzz_loop(\u0026amp;mut stages, \u0026amp;mut executor, \u0026amp;mut state, \u0026amp;mut mgr)?; 可以看到 StdFuzzer 串联起了全部组件。mgr、scheduler、mutator、stages 都是使用库自带的类，固省略之，下面详述复杂些的组件。\n组件：State 1 2 3 4 5 6 7 let mut state = StdState::new( StdRand::with_seed(current_nanos()), input_corpus, timeouts_corpus, \u0026amp;mut feedback, \u0026amp;mut objective, )?; 查阅文档可知StdState的成员含义，这些成员就是Fuzzer的全部状态了。一个可能的疑惑是为什么会有feedback、objective两种 Feedback，让我们继续向上检阅代码。\n1 2 3 4 5 6 7 8 9 10 pub fn new\u0026lt;F, O\u0026gt;( rand: R, corpus: C, solutions: SC, feedback: \u0026amp;mut F, objective: \u0026amp;mut O ) -\u0026gt; Result\u0026lt;Self, Error\u0026gt; where F: Feedback\u0026lt;Self\u0026gt;, O: Feedback\u0026lt;Self\u0026gt;, Rust 基础之所有权 所有权，是 Rust 特有的设计，在无GC的前提下实现内存安全与高性能。基本规则：\nRust 中每一个值都被一个变量所拥有，该变量被称为值的所有者 一个值同时只能被一个变量所拥有，或者说一个值只能拥有一个所有者 当所有者(变量)离开作用域范围时，这个值将被丢弃(drop) 基于这些原则，当一个值被另一个变量使用时，会发生所有权的转移，先前的变量便不能访问该值。\n1 2 3 let s1 = String::from(\u0026#34;hello\u0026#34;); let s2 = s1; println!(\u0026#34;{}, world!\u0026#34;, s1); // 报错！ 1 2 3 let s1 = String::from(\u0026#34;hello\u0026#34;); let s2 = s1.clone(); println!(\u0026#34;{}, world!\u0026#34;, s1); // 不报错 1 2 3 let x = 5; let y = x; println!(\u0026#34;x = {}, y = {}\u0026#34;, x, y); // 不报错 转移(move) 和 拷贝(copy) let s2 = s1;在 Rust 中被称为变量绑定，代表s1被移动到了s2。\n如果想要访问相同值，需要对变量进行拷贝。在上面的例子中，int类型没有拷贝也不报错，这是因为基本类型的大小是已知的，且分配在栈上，对他的拷贝比较简单，故 Rust 自动实现了拷贝。而String是复杂类型，必须显式的拷贝。\n引用(reference) 和 借用(borrowing) 将值在变量之间传来传去确实比较麻烦。 Rust实现了2种引用：\n\u0026amp;: 不可变引用，允许使用值但不获取所有权。可以有多个。 \u0026amp;mut: 可变引用。仅能存在一个。 可变引用与不可变引用不能同时存在。 获取变量的引用，就称为借用。显然，在离开作用域后所有权将被归还。引用的作用域从创建一直持续到它最后一次使用，而变量的作用域从创建持续到某一个花括号}。\n对引用有效性的检查是 Rust 解决数据竞争，悬垂指针等安全问题的重要机制。\n在本项目中，需要feedback和objective随着state更新而不断积累，因此使用可变引用。而其他成员和state相关，故直接将所有权移交给state。\n参考文档：https://course.rs/basic/ownership/ownership.html\n组件：Observer \u0026amp; Feedback 1 2 3 4 5 6 7 8 9 10 11 12 13 let time_observer = TimeObserver::new(\u0026#34;time\u0026#34;); let edges_observer = unsafe { HitcountsMapObserver::new(StdMapObserver::new(\u0026#34;shared_mem\u0026#34;, shmem_buf)) }; let mut feedback = feedback_or!( MaxMapFeedback::tracking(\u0026amp;edges_observer, true, false), TimeFeedback::with_observer(\u0026amp;time_observer) ); let mut objective = feedback_and_fast!( TimeoutFeedback::new(), MaxMapFeedback::new(\u0026amp;edges_observer) ); 如定义所言，Observer 仅提供信息，Feedback 将观察到的信息进行判断。 在本例中，首先定义的两个Observer分别提供了代码运行时间和便覆盖率的信息。 然后分布对他们进行了不同的反馈判断。feedback_or和feedback_and_fast是逻辑判断宏。因此可以解读他们的逻辑：\nfeedback的条件是覆盖了新的分支 或 “运行时间反馈”。故反馈的是有趣的样例(interesting testcase) 实际上，“运行时间反馈”永远不会真的反馈，需要配合其他反馈使用。这里仅作示例。 objective的条件是覆盖了新的分支 且 运行超时。故反馈的是能触发无限递归漏洞的样例，即我们想要的结果（solution） 组件：Executor 1 2 3 4 5 6 7 let fork_server = ForkserverExecutor::builder() .program(\u0026#34;./xpdf/install/bin/pdftotext\u0026#34;) .parse_afl_cmdline([\u0026#34;@@\u0026#34;]) .coverage_map_size(MAP_SIZE) .build(tuple_list!(time_observer, edges_observer))?; let timeout = Duration::from_secs(5); let mut executor = TimeoutForkserverExecutor::new(fork_server, timeout)?; 我们的 Executor 还是采用经典的 forkserver 架构，构建 Executor 时，首先加入了两个 Observer ，然后指定了超时时间，有助于增加fuzz吞吐量。\n跑🏃‍ 总之借助 LibAFL 的框架，写一个 Fuzzer 还是很清晰的。（或许若干年后的 Fuzzing 学习者就不用啃AFL的1000行源码了😭）\n最后跑出来一个死循环。👴宣布实验一完成。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 [AFL++ 798a8ebfa8a4] /fuzzing101/exercise-1 # ./xpdf/install/bin/pdftotext ./timeouts/c497979e26a808e9 Error: PDF file is damaged - attempting to reconstruct xref table... Error (2459): Dictionary key must be a name object Error (2465): Illegal character \u0026#39;\u0026gt;\u0026#39; Error (2468): Dictionary key must be a name object Error (2471): Dictionary key must be a name object Error (2486): Dictionary key must be a name object Error (2488): Illegal character \u0026lt;2f\u0026gt; in hex string Error (2489): Illegal character \u0026lt;78\u0026gt; in hex string Error (2490): Illegal character \u0026lt;6d\u0026gt; in hex string Error (2491): Illegal character \u0026lt;70\u0026gt; in hex string Error (2492): Illegal character \u0026lt;3a\u0026gt; in hex string Error (2493): Illegal character \u0026lt;4d\u0026gt; in hex string Error (2494): Illegal character \u0026lt;6f\u0026gt; in hex string Error (2496): Illegal character \u0026lt;69\u0026gt; in hex string Error (2498): Illegal character \u0026lt;79\u0026gt; in hex string Error (2501): Illegal character \u0026lt;74\u0026gt; in hex string Error (2503): Dictionary key must be a name object -------------8\u0026lt;------------- ","date":"2023-07-26T02:54:55+08:00","image":"https://lonelyuan.github.io/p/libafl%E9%80%9F%E9%80%9Afuzzing101-1/exe1_hu040a15c83346252047b5ebf7d9d42a76_312292_120x120_fill_box_smart1_3.png","permalink":"https://lonelyuan.github.io/p/libafl%E9%80%9F%E9%80%9Afuzzing101-1/","title":"libAFL速通Fuzzing101 (1)"},{"content":"这个《伊万·弗拉特里克的安全博客》啊，确实是个好博客。这篇《所以你想做安保工作?》啊，确实是篇好文章。那么我一个新世纪理工科战士，怎么开始写读后感了呢？老板的任务罢了。\n伊万老哥是谷歌的安全研究员，代表作有winafl等。能上大厂当研究员，已经是我对职业生涯的理想了。文章说，对大部分人来说，安全首先是一个爱好然后才是工作。诚然，没有纯粹的爱好是无法提供长时间坐冷板凳的自驱力的。但或许大部分人并没有对某一件事的狂热爱好，在褪去光鲜外表后，大部分人都是三分钟热度。人们常说“兴趣大于天赋”，或许浓厚的兴趣本身就是一种稀有的天赋。\nDon’t look now but getting started is more difficult now than it was 10 years ago\n安全研究的入门难度比十年前更高。而本文发布于2018年，那时我正值高考，国内CTF形势方兴未艾，现在网络上随处可见的入门知识，都是当时的热门考点。文章说CTF是很好的入门方式，可以减缓学习曲线的陡峭程度。而现在，又过去了半个十年，我也紧赶慢赶步入研究生阶段。这个结论能否适用于当下的入门者，恐怕难以下定论。（仅限于中国大陆）（只是因为作者没有去过其他国家，没有说中国大陆不好的意思）。\n当然我也不是输出负能量，面对越来越卷的市场，面对全球经济发展下行的环境，面对没有原始资本的自己，唯一能做的就是尽可能学习免费的知识和技能，静观其变。作者最后说，搞安全需要长时间坐电脑，并且\u0026quot;quite intellectually challenging\u0026quot;，经常\u0026quot;mentally exhausting\u0026quot;。此言诚然，要做好长时间得不到回报的觉悟，寻找和培养正反馈；同时也要加强锻炼，身体健康和精神健康两手抓。\n","date":"2023-07-07T20:29:12+08:00","permalink":"https://lonelyuan.github.io/p/%E6%89%80%E4%BB%A5%E4%BD%A0%E6%83%B3%E5%81%9A%E5%AE%89%E4%BF%9D%E5%B7%A5%E4%BD%9C%E8%AF%BB%E5%90%8E%E6%84%9F/","title":"《所以你想做安保工作?》读后感"},{"content":"历史篇 你们 CLI 确实比 GUI 有点素质 要论计算机人的典中典，还得是n年不更新只有寥寥几篇文章的 Hexo 博客。它代表着命令行初学者的兴奋，第一次配 node 环境成功后的喜悦，以及一个月之后的疑问：\n这点屁事我为什么不发秋秋空间/微博？ 只有我看我为什么不记 Onenote/Notion ？ 想要流量我为什么不发知乎/简书/西埃斯弟恩……？ 尽管从现在看仿佛是前朝遗老，个人博客依旧是不存在于中文互联网中的极少数高质量中文内容。它代表着 RSS ，代表着永远不用担心跑路和审查，是 geek 们的精神自留地。\n但是👴还是觉得发一篇博客敲好几条命令麻烦的要死。大概是👴不再年轻了，👴开始追求简单安逸，像挨了锤的牛一样。于是👴最终选用 Gridea ，一个博客客户端，可一键推送到 Github Page。这玩意有些不太趁手的地方，等👴闲来无事的时候搞一搞二次开发……\n然而，👴还没等到闲来无事的时候，发觉Gridea作者弃坑了。。。其客户端（electron害人不浅）编辑体验差，git更新老出毛病。作者现在只更新web端，托管到他的云服务下面。👴还是更相信github不会跑路，所以👴还是赶紧跑路吧。于是：\n你们 JS 确实比 Go 有点素质 于是👴最终选用 Hugo 做博客，因为与 Hexo 相比 Hugo 的运行速度和空间占用都十分轻量。最重要的是，作为 Go 开发的项目，可以直接下载可执行文件，不需要恼人的配环境环节。👴看中了 Stack 主题，但是这个主题用的人不少，有些千篇一律的尴尬。为此👴决定深耕换皮之道……\n原理篇 Hugo 项目结构 1 2 3 4 5 6 7 8 9 ├── archetypes # .md 模板 │ └── default.md ├── config.toml # 配置文件 ├── content # 在这写东西 ├── data # 更多配置文件 ├── layouts # .html 模板 ├── public # 渲染好的网站 ├── static # 静态文件，hugo会全部复制 └── themes # 博客主题 content 这里是 Hugo 的输入，存放.md格式的文章。使用hugo new命令时，会尝试从archetypes目录寻找对应的模板，模板通常仅包含front matter，定义了文章的元属性。语法如下：\nhugo new \u0026lt;SECTIONNAME\u0026gt;/\u0026lt;FILENAME\u0026gt;.\u0026lt;FORMAT\u0026gt;\ncontent中的子文件夹称为 sections ，它们是网站内容的基本分块。分块的目的是分配不同的处理方式，如post需要展示文章列表，page仅展示单独页面等。配置中的permalinks项就是以分块为单位分配URL。\npublic 这里是 Hugo 的输出，存放完整的 HTML 静态网页。使用hugo命令时，会尝试从layouts目录寻找对应的模板， HTML 模板均以 GO 模板语法编写。在写文章时也可使用模板来避免写 HTML 的繁杂，如 Hugo 提供的各种 shortcode 。\n以 Github Page 为例，部署时仅需将这个文件夹同步至 github.io 仓库即可。\nHugo 设计理念 【To be continued】翻译翻译官方文档\n开发篇 如何优雅的二次开发？ 观察theme的内容，会发现除了没有content目录之外和网站根目录结构完全一致。由此猜测，所谓theme也是一个 site，使用theme就是用其模板覆盖我们的网站。\n那么，直接修改theme目录里的内容自然可行，但如果需要升级主题，则会产生许多讨厌的merge问题。如何实现数据和配置的解耦？实际上，上述关于覆盖顺序的猜想并不准确，实际顺序是：本地模板→主题模板→默认模板。故而，在本地模板中添加相同路径下的同名模板文件，即可覆盖掉主题模板的配置。\n以 Stack 主题为例，其在许多位置都存在着诸如hugo-theme-stack\\assets\\scss\\custom.scss的空白文件，只需要在根目录新建\\assets\\scss\\custom.scss即可添加对 CSS 的改动。\n一般来说，仿照主题提供的demo网站即可满足一般的二次开发需求。关于模板查找顺序还有诸多细节，请参阅官方文档：Template lookup order。\narticle元信息：lastmod，wordcount Hugo 本身为每篇文章都统计了相关变量，但 Stack 主题没有展示。从F12定位到相关元素，其模板在：\\themes\\hugo-theme-stack\\layouts\\partials\\article\\components\\details.html\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026lt;footer class=\u0026#34;article-time\u0026#34;\u0026gt; {{ if $showDate }} \u0026lt;div\u0026gt; {{ partial \u0026#34;helper/icon\u0026#34; \u0026#34;date\u0026#34; }} \u0026lt;time class=\u0026#34;article-time--published\u0026#34;\u0026gt; {{- .Date.Format (\u0026#34;2006-1-1\u0026#34;) -}} \u0026amp;nbsp;published \u0026lt;/time\u0026gt; {{- if ne .Lastmod .Date -}} \u0026lt;time class=\u0026#34;article-time--published\u0026#34;\u0026gt; {{- .Lastmod.Format (\u0026#34;2006-1-1\u0026#34;) -}} \u0026amp;nbsp;last modified {{- end -}} \u0026lt;/time\u0026gt; \u0026lt;/div\u0026gt; {{ end }} {{ if $showReadingTime }} \u0026lt;div\u0026gt; {{ partial \u0026#34;helper/icon\u0026#34; \u0026#34;clock\u0026#34; }} \u0026lt;time class=\u0026#34;article-time--reading\u0026#34;\u0026gt; {{ T \u0026#34;article.readingTime\u0026#34; .ReadingTime }} \u0026lt;span class=\u0026#34;post-word-count\u0026#34;\u0026gt;, {{ .WordCount }} words\u0026lt;/span\u0026gt; \u0026lt;/time\u0026gt; \u0026lt;/div\u0026gt; {{ end }} 代码块：行号，突出行 hugo框架本身就支持：（为避免转解析加了空格）\n1 2 3 4 5 { {\u0026lt; highlight go-html-template \u0026#34;lineNos=inline, lineNoStart=42, hl_Lines=1\u0026#34; \u0026gt;}} {{ range .Pages }} \u0026lt;h2\u0026gt;\u0026lt;a href=\u0026#34;{{ .RelPermalink }}\u0026#34;\u0026gt;{{ .LinkTitle }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt; {{ end }} { {\u0026lt; /highlight \u0026gt;}} 预览：\n42{{ range .Pages }} 43 \u0026lt;h2\u0026gt;\u0026lt;a href=\u0026#34;{{ .RelPermalink }}\u0026#34;\u0026gt;{{ .LinkTitle }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt; 44{{ end }} 默认代码高亮是真够吧丑，赶紧改改css。\n配色，字体 【To be continued】\n标题跳转 这slack主题居然标签旁边没有跳转的小链接我也是没想到的。\n【To be continued】\n信息块 slack主题里也没有，那没事了。\n1 2 3 4 {{\\\u0026lt;note info \u0026gt;}} 书写表达的信息 支持 Markdown 语法 {{\\\u0026lt; /note \u0026gt;}} 【To be continued】\n版权块 【To be continued】\n富文本 【To be continued】\n导图 词云 你这静态网站不是很静态啊 评论系统 Stack主题支持的评论系统：\nhttps://stack.jimmycai.com/config/comments 👴作为白嫖怪，既然选择了Github Pages当然要选择同生态的方案。目前有两种方案：\nGitalk：基于issue，和仓库绑定 Giscus：基于GitHub Discussions gitalk对每个文章需要管理员新建issue才能评论实在8太好使。Giucus配置起来更方便：\n首先创建一个公开仓库(直接用page仓库也可，或许)，按官网说的打开Discussion功能，并安装Giscus app 然后把仓库路径填进官网，后面全默认或选第一个，就得到了一串配置信息。 把里面的配置加入hugo配置文件即可（删掉配置变量的data-前缀） 网站统计 教程一大把，搞定科学上网就没问题。\n然后你就会发现并没有人来访问。\n统计平台：\nhttps://analytics.google.com/ https://www.cloudflare.com/zh-cn/web-analytics/ 工作流篇 这一节介绍从撰写到部署踩坑过的工具/环境\nIDE：vscode天下第一 IDE最重要的是避免重复劳动，包括写作，多媒体管理，保存，部署等等。 由于vscode跟github现在都姓了微软了，他们简直亲如一家。\n具体来说，使用vscode写博客的姿势be like：\nGUI丝滑git同步 终端一键预览，发布（甚至可以写配置加一个绿色小三角） markdown支持：图片复制自动插入正文并复制到同路径下 还可以进一步丝滑的需求比如模板文件等\nvscode插件 Front Matter：这不CMS吗 这个插件乍一看挺厉害，实则一拖四。提供了一个类似CMS的界面，可以自动化配置一些些Front Matter，比如日期。但是用了一会其作用不说如虎添翼吧也可以算得上聊胜于无。\nobsdian 使用obsdian比vscode强的地方在于原生支持front matter丝滑管理。 另一个原因是，敲代码已经打开一个vscode图标了容易混淆。 但是在markdown渲染方面有些割裂。希望未来有合适插件出现。\nGithub Pages + Github Action 自动部署 https://gohugo.io/hosting-and-deployment/hosting-on-github/ 部署之后却发现总是带有项目名作为子路径（即xxx.github.io/xxx）。这就很让人不爽了。纵观全网的博客大多都带着这个尾巴，表示怀疑这些人究竟是不是一直这么用的。\nhugo官方给出的workflow中，最后一步是这样的\n1 2 3 4 5 6 7 8 9 10 11 # Deployment job deploy: environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} runs-on: ubuntu-latest needs: build steps: - name: Deploy to GitHub Pages id: deployment uses: actions/deploy-pages@v2 👴直接🐏url，但是${{ steps.deployment.outputs.page_url }}是个用来输出的东西，改它没用。应该是actions/deploy-pages@v2这个action本身的问题。\n于是👴参考了22年的几篇博客：\nhttps://client.sspai.com/post/73512#! 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 - name: Build with Hugo env: # ... run: | hugo \\ --minify \\ --baseURL \u0026#34;https://lonelyuan.github.io/\u0026#34; # fxxk $ ... - name: Deploy Web uses: peaceiris/actions-gh-pages@v3 with: PERSONAL_TOKEN: ${{ secrets.PERSONAL_TOKEN }} EXTERNAL_REPOSITORY: pseudoyu/pseudoyu.github.io PUBLISH_BRANCH: master PUBLISH_DIR: ./public commit_message: ${{ github.event.head_commit.message }} 这种方法涉及两个仓库，因此需要额外配置token。按照博客的方法替换成peaceiris/actions-gh-pages@v3后，可以成功在主域名更新了。\n虽然但是，目前的操作从写博客→hugo→git push变成了写博客→hugo server(总得预览一下吧)→git push，似乎并没有什么简化，，，虽然可以依靠编辑器的自动git commit的插件，但是👴还是不想每次保存都commit。\nGithub Action 收集 lastmodify 使用 Github 的 CI/CD 管线可以在更新时绑定到commit号，但是👴觉得没太大用。改一个字就更新lastmod过于粗粒度，遂还是采用手动展示👴想展示的日期。\n","date":"2021-11-07T14:19:11Z","permalink":"https://lonelyuan.github.io/p/%E9%97%B2%E6%9D%A5%E6%97%A0%E4%BA%8B%E5%80%92%E8%85%BE%E5%8D%9A%E5%AE%A2/","title":"闲来无事，倒腾博客"},{"content":"由于👴觉得👴学校的操作系统讲了个🔨，慕名而来学习上交的 MOSPI 课程。银杏书看完之后👴发现👴学校的OS确实讲了个🔨。我直接当场来一段圣经吟唱：\n那个额西电操作系统嗷，不会写教材可以不写，害特么在弄你那个管程，来我教你啊，看好了啊。首先 M.A.L.H. 原则，看懂了吗，然后开讲虚拟内存，哎我就不虚拟，我就讲那个空闲链表。哎，再扎个多线程，看到没，线程上下文切换了。我特么直接三段系统调度（短期，中期，长期），然后我直接~就一个多核调度，我就调度到IPC，进程现在已经可以通信了啊！别怪我没有教好你，进程通信了之后干什么，憋特么讲你那破几把处理机了。看好啊，讲出锁（嬉皮笑脸），讲出信号量直接就扔到互斥资源身上，就疯狂的进入他的临界区。然后我再一个，文件系统！加三段系统虚拟化（CPU虚拟化、内存虚拟化、IO虚拟化），全部吃满，完成强杀，你唛璧你懂个der，讲寄吧OS，我爱你。\n圣经原文：拖更云的鹰佐教学\n本系列为 ChCore lab 实验报告。 Lab源码：https://gitee.com/ipads-lab/chcore-lab MOSPI在线网站：https://ipads.se.sjtu.edu.cn/mospi/\n实验环境 需要docker和qemu，docker不赘述。linux下安装qemu： sudo apt-get install qemu-system-arm 安装完成之后查看版本号：\n1 2 3 $ qemu-system-aarch64 --version QEMU emulator version 4.2.0 Copyright (c) 2003-2019 Fabrice Bellard and the QEMU Project developers 5个实验在源码仓库分别以5个分支存在。 git clone -b即可。\n内核构建和调试：\n用docker交叉编译内核：make build 启动qemu：make qemu 这里遇到报错： Unable to init server: Could not connect: Connection refused gtk initialization failed 解决方法：修改 Makefile ，在QEMUOPTS参数后加-nographic 启动qemu：make qemu-gdb 将监听1234端口以供gdb远程调用 退出：ctrl+a，然后按x。 如果意外退出，要杀死进程：kill $(ps -ef | grep qemu | grep 1234 | awk '{print $2}') 在另一个终端启动gdb调试：make gdb 这里可能需要安装gdb-multiarch：sudo apt-get install gdb-multiarch 可以看到，本项目中 Makefile 主要是封装了一些命令。\nLab1 练习3-加载入口定义 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 root@lastyear:~/chcore-lab# readelf -S build/kernel.img There are 9 section headers, starting at offset 0x20cd8: Section Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align [ 0] NULL 0000000000000000 00000000 0000000000000000 0000000000000000 0 0 0 [ 1] init PROGBITS 0000000000080000 00010000 000000000000b5b0 0000000000000008 WAX 0 0 4096 [ 2] .text PROGBITS ffffff000008c000 0001c000 00000000000011dc 0000000000000000 AX 0 0 8 [ 3] .rodata PROGBITS ffffff0000090000 00020000 00000000000000f8 0000000000000001 AMS 0 0 8 [ 4] .bss NOBITS ffffff0000090100 000200f8 0000000000008000 0000000000000000 WA 0 0 16 [ 5] .comment PROGBITS 0000000000000000 000200f8 0000000000000032 0000000000000001 MS 0 0 1 [ 6] .symtab SYMTAB 0000000000000000 00020130 0000000000000858 0000000000000018 7 46 8 [ 7] .strtab STRTAB 0000000000000000 00020988 000000000000030f 0000000000000000 0 0 1 [ 8] .shstrtab STRTAB 0000000000000000 00020c97 000000000000003c 0000000000000000 0 0 1 看到init段的起始地址是0x80000，和readelf -h中的 Entry point address 一致，也和 GDB 刚进入时where的输出一致。\n1 2 3 0x0000000000080000 in ?? () (gdb) where #0 0x0000000000080000 in _start () 下面寻找_start的定义，在CMakeLists.txt中找到_start，\n1 2 3 4 5 6 7 set_property( TARGET kernel.img APPEND_STRING PROPERTY LINK_FLAGS \u0026#34;-T ${CMAKE_CURRENT_BINARY_DIR}/${link_script} -e _start\u0026#34; ) 这里为kernel.img指定了链接器脚本(-T)和入口函数(-e)。\n于是跟随link_script：\n1 2 set(link_script \u0026#34;linker.lds\u0026#34;) configure_file(\u0026#34;./scripts/linker-aarch64.lds.in\u0026#34; \u0026#34;linker.lds.S\u0026#34;) 进入脚本linker-aarch64.lds.in：\n1 2 3 4 5 6 7 8 9 10 #include \u0026#34;../boot/image.h\u0026#34; SECTIONS { . = TEXT_OFFSET; img_start = .; init : { ${init_object} } // ... 其中init段指定了加载init_object，它表示bootloader的所有目标文件集合。其定义回到CmakeLists.txt：\n1 2 3 4 5 6 7 set(init_object \u0026#34;${BINARY_KERNEL_IMG_PATH}/${BOOTLOADER_PATH}/start.S.o ${BINARY_KERNEL_IMG_PATH}/${BOOTLOADER_PATH}/mmu.c.o ${BINARY_KERNEL_IMG_PATH}/${BOOTLOADER_PATH}/tools.S.o ${BINARY_KERNEL_IMG_PATH}/${BOOTLOADER_PATH}/init_c.c.o ${BINARY_KERNEL_IMG_PATH}/${BOOTLOADER_PATH}/uart.c.o\u0026#34; ) 可发现/boot/start.S定义了_start。\n下面继续寻找地址，在链接器脚本引用了image.h，其中有TEXT_OFFSET的定义：\n1 2 3 4 5 6 7 #pragma once #define SZ_16K 0x4000 #define SZ_64K 0x10000 #define KERNEL_VADDR 0xffffff0000000000 #define TEXT_OFFSET 0x80000 一切终于串起来了：\nCMakeLists.txt：是CMake的脚本文件。 CMake 是跨平台的C/C++建构工具。 作用： 指定源文件集合init_object 定义链接器脚本link_script 指定入口函数_start并指定链接器脚本 最终生成kernel.img //最近看到的挺好的CMake教程：https://www.bilibili.com/video/BV1rR4y1E7n9 linker-aarch64.lds.in：lds是链接器脚本文件，负责控制输出的ELF文件的细节。 作用：指定了起始地址0x80000 练习3-多处理器挂起 start.S中注释的很明白了，通过检查mpidr_el1寄存器来判断 cpuid ，如果不是0则进入死循环。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 BEGIN_FUNC(_start) mrs x8, mpidr_el1 and x8, x8, #0xFF cbz x8, primary /* hang all secondary processors before we intorduce multi-processors */ secondary_hang: bl secondary_hang primary: /* Turn to el1 from other exception levels. */ bl arm64_elX_to_el1 /* Prepare stack pointer and jump to C. */ adr x0, boot_cpu_stack add x0, x0, #0x1000 mov sp, x0 bl init_c /* Should never be here */ b . END_FUNC(_start) 练习4-LMA和VMA 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 root@lastyear:~/chcore-lab# objdump -h build/kernel.img build/kernel.img: file format elf64-little Sections: Idx Name Size VMA LMA File off Algn 0 init 0000b5b0 0000000000080000 0000000000080000 00010000 2**12 CONTENTS, ALLOC, LOAD, CODE 1 .text 000011dc ffffff000008c000 000000000008c000 0001c000 2**3 CONTENTS, ALLOC, LOAD, READONLY, CODE 2 .rodata 000000f8 ffffff0000090000 0000000000090000 00020000 2**3 CONTENTS, ALLOC, LOAD, READONLY, DATA 3 .bss 00008000 ffffff0000090100 0000000000090100 000200f8 2**4 ALLOC 4 .comment 00000032 0000000000000000 0000000000000000 000200f8 2**0 CONTENTS, READONLY 可以发现只有init段的VMA和LMA相同。其赋值还是回到lds脚本：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 SECTIONS { . = TEXT_OFFSET; img_start = .; init : { //init段VMA==VMA ${init_object} } . = ALIGN(SZ_16K); // 对齐16k init_end = ABSOLUTE(.); // init段结束 // KERNEL_VADDR在image.h定义为0xffffff0000000000 .text KERNEL_VADDR + init_end : AT(init_end) { // AT指定LMA *(.text*) } // .text段：VMA = KERNEL_VADDR + init_end; LMA = init_end // 后面的段，全部按顺序对齐并递增，此时VMA和LMA已经不同，故后面的段也全都不同 . = ALIGN(SZ_64K); .data : { *(.data*) } . = ALIGN(SZ_64K); .rodata : { *(.rodata*) } _edata = . - KERNEL_VADDR; // 这些外部变量指的是LMA，则减去虚拟地址头 _bss_start = . - KERNEL_VADDR; .bss : { *(.bss*) } _bss_end = . - KERNEL_VADDR; . = ALIGN(SZ_64K); img_end = . - KERNEL_VADDR; } 回答问题：\n为什么LMA和VMA不同\nVMA是对应虚拟内存的地址，但在内核启动时还处于物理地址模式，VMA可能超出物理内存范围。所以只能先加载，再映射到虚拟地址。 为什么内核段的VMA要映射到高位，应该是一种惯例。 为什么bootloader不用VMA，因为他负责初始化页表，他不能用，也没有必要。 LMA到VMA在何时转换\n由上一问可知，页表初始化之后便可转换为VMA。 练习5-c语言进制转换 从后往前取余即可。\n练习6-函数栈 start.S中赋值了sp：\n1 2 3 4 /* Prepare stack pointer and jump to C. */ adr x0, boot_cpu_stack add x0, x0, #0x1000 mov sp, x0 /* sp = boot_cpu_stack + 0x1000 */ boot_cpu_stack在init.c\n1 2 #define INIT_STACK_SIZE 0x1000 char boot_cpu_stack[PLAT_CPU_NUMBER][INIT_STACK_SIZE] ALIGN(16); 由于PLAT_CPU_NUMBER被定义为4，故boot_cpu_stack大小为4*4096，可供四个CPU使用。sp初始化后指向第一个4069，也就是第一个cpu内核栈的最高位。初始化时，fp=sp。\n但这是bootloader的栈。后续进入内核后，会重新分配内核栈，参见head.S：\n1 2 3 4 5 6 7 8 BEGIN_FUNC(start_kernel) mov x3, #0 msr TPIDR_EL1, x3 ldr x2, =kernel_stack add x2, x2, KERNEL_STACK_SIZE mov sp, x2 bl main END_FUNC(start_kernel) 于是内核栈的定义在start_kernel函数。\n有关内核栈的位置，因为kernel_stack是全局数组，且未初始化，因而位于.bss。同时没有其他未初始化变量，因此首地址在.bss + KERNEL_STACK_SIZE。\n通过readelf得到.bss的VMA为0xffffff0000090100，KERNEL_STACK_SIZE为0x2000，进入gdb调试可以验证\n1 2 gef➤ x/g $sp 0xffffff0000092100 \u0026lt;kernel_stack+8192\u0026gt;: 0x0 练习7-调用惯例 先看stack_test函数。这里gdb安装了gef插件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 gef➤ b stack_test Breakpoint 1 at 0xffffff000008c020 gef➤ disas Dump of assembler code for function stack_test: =\u0026gt; 0xffffff000008c020 \u0026lt;+0\u0026gt;: stp x29, x30, [sp, #-32]! /* FP、LR 入栈 */ 0xffffff000008c024 \u0026lt;+4\u0026gt;: mov x29, sp 0xffffff000008c028 \u0026lt;+8\u0026gt;: str x19, [sp, #16] /* x 入栈 */ 0xffffff000008c02c \u0026lt;+12\u0026gt;: mov x19, x0 0xffffff000008c030 \u0026lt;+16\u0026gt;: mov x1, x0 0xffffff000008c034 \u0026lt;+20\u0026gt;: adrp x0, 0xffffff0000090000 # 计算偏移 0xffffff000008c038 \u0026lt;+24\u0026gt;: add x0, x0, #0x0 0xffffff000008c03c \u0026lt;+28\u0026gt;: bl 0xffffff000008c620 \u0026lt;printk\u0026gt; 0xffffff000008c040 \u0026lt;+32\u0026gt;: cmp x19, #0x0 0xffffff000008c044 \u0026lt;+36\u0026gt;: b.gt 0xffffff000008c068 \u0026lt;stack_test+72\u0026gt; # greater than /* 递归 */ 0xffffff000008c048 \u0026lt;+40\u0026gt;: bl 0xffffff000008c0dc \u0026lt;stack_backtrace\u0026gt; 0xffffff000008c04c \u0026lt;+44\u0026gt;: mov x1, x19 0xffffff000008c050 \u0026lt;+48\u0026gt;: adrp x0, 0xffffff0000090000 0xffffff000008c054 \u0026lt;+52\u0026gt;: add x0, x0, #0x20 0xffffff000008c058 \u0026lt;+56\u0026gt;: bl 0xffffff000008c620 \u0026lt;printk\u0026gt; 0xffffff000008c05c \u0026lt;+60\u0026gt;: ldr x19, [sp, #16] # x19 = sp + 16 /* x 出栈 */ 0xffffff000008c060 \u0026lt;+64\u0026gt;: ldp x29, x30, [sp], #32 # load pair /* FP、LR 出栈 */ 0xffffff000008c064 \u0026lt;+68\u0026gt;: ret 0xffffff000008c068 \u0026lt;+72\u0026gt;: sub x0, x19, #0x1 0xffffff000008c06c \u0026lt;+76\u0026gt;: bl 0xffffff000008c020 \u0026lt;stack_test\u0026gt; 0xffffff000008c070 \u0026lt;+80\u0026gt;: mov x1, x19 0xffffff000008c074 \u0026lt;+84\u0026gt;: adrp x0, 0xffffff0000090000 0xffffff000008c078 \u0026lt;+88\u0026gt;: add x0, x0, #0x20 0xffffff000008c07c \u0026lt;+92\u0026gt;: bl 0xffffff000008c620 \u0026lt;printk\u0026gt; 0xffffff000008c080 \u0026lt;+96\u0026gt;: ldr x19, [sp, #16] 0xffffff000008c084 \u0026lt;+100\u0026gt;: ldp x29, x30, [sp], #32 0xffffff000008c088 \u0026lt;+104\u0026gt;: ret End of assembler dump. 运行，观察栈的变化，这里省略部分输出：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 gef➤ c ───────────────────────────────────────── registers ──── $x0 : 0x0000000000000005 # 这一层函数的输入值 $x19 : 0x0000000000000000 # 上一层函数的返回值 $x29 : 0xffffff00000920f0 # FP $x30 : 0xffffff000008c0d4 → \u0026lt;main+72\u0026gt; # LR $sp : 0xffffff00000920f0 ───────────────────────────────────────────── stack ──── 0xffffff00000920f0│+0x0000: 0x0000000000000000 0xffffff00000920f8│+0x0008: 0xffffff000008c018 # 栈头，可能是栈初始化的数据结构 ──────────────────────────────────────────── trace ──── [#0] 0xffffff000008c020 → stack_test() [#1] 0xffffff000008c0d4 → main() ─────────────────────────────────────────────────────── gef➤ c ───────────────────────────────────────── registers ──── $x0 : 0x0000000000000004 $x19 : 0x0000000000000005 $x29 : 0xffffff00000920d0 $x30 : 0xffffff000008c070 #→ \u0026lt;stack_test+80\u0026gt; $sp : 0xffffff00000920d0 → 0xffffff00000920f0 ───────────────────────────────────────────── stack ──── 0xffffff00000920d0│+0x0000: 0xffffff00000920f0 ─┐ # FP 0xffffff00000920d8│+0x0008: 0xffffff000008c0d4 │ # LR 0xffffff00000920e0│+0x0010: 0x0000000000000000 │ 0xffffff00000920e8│+0x0018: 0x00000000ffffffc0 │ 0xffffff00000920f0│+0x0020: 0x0000000000000000 ◄┘ 0xffffff00000920f8│+0x0028: 0xffffff000008c018 ───────────────────────────────────────────── trace ──── [#0] 0xffffff000008c020 → stack_test() [#1] 0xffffff000008c070 → stack_test() [#2] 0xffffff000008c0d4 → main() ──────────────────────────────────────────────────────── gef➤ c ───────────────────────────────────────── registers ──── $x0 : 0x0000000000000003 $x19 : 0x0000000000000004 $x29 : 0xffffff00000920b0 → 0xffffff00000920d0 → 0xffffff00000920f0 $x30 : 0xffffff000008c070 $sp : 0xffffff00000920b0 → 0xffffff00000920d0 → 0xffffff00000920f0 ──────────────────────────────────────────── stack ──── 0xffffff00000920b0│+0x0000: 0xffffff00000920d0 ─┐ # [#1] 0xffffff00000920b8│+0x0008: 0xffffff000008c070 │ 0xffffff00000920c0│+0x0010: 0x0000000000000005 │ 0xffffff00000920c8│+0x0018: 0x00000000ffffffc0 │ 0xffffff00000920d0│+0x0020: 0xffffff00000920f0 ◄┘ # [#2] 0xffffff00000920d8│+0x0028: 0xffffff000008c0d4 │ 0xffffff00000920e0│+0x0010: 0x0000000000000000 │ 0xffffff00000920e8│+0x0018: 0x00000000ffffffc0 │ 0xffffff00000920f0│+0x0020: 0x0000000000000000 ◄┘ # [#3] 0xffffff00000920f8│+0x0028: 0xffffff000008c018 ─────────────────────────────────────────── trace ──── [#0] 0xffffff000008c020 → stack_test() [#1] 0xffffff000008c070 → stack_test() [#2] 0xffffff000008c070 → stack_test() [#3] 0xffffff000008c0d4 → main() ────────────────────────────────────────────────────── 可以看到每次递归调用压栈4个64位字，分别是：上一层FP，LR，参数x和0x00000000ffffffc0。最后一个64位字用途未知。\n练习9-backtrace 提供read_fp()接口，我们知道fp永远指向父函数的fp，故递归调用即可。\n1 2 3 4 5 u64* fp = (u64*) *((u64*)read_fp()); // 双层指针，因为第一层是本函数 while(fp != 0) { printk(\u0026#34;LR %lx FP %lx Args %d %d %d %d %d\\n\u0026#34;, *(fp + 1), fp, *(fp - 2), *(fp - 1), *(fp), *(fp + 1), *(fp + 2)); //为什么5个参数是fp-2到fp+2？样例只包括一个参数，只要出现fp+2就能测试通过 fp = (u64*) *fp; //下一层 } 满分通过，懒得贴图了。\n看到大佬写的，瞬间不想写了，寄。 https://www.cnblogs.com/kangyupl/p/chcore_lab1.html\n","date":"2021-10-29T17:03:14Z","permalink":"https://lonelyuan.github.io/p/mospi-chcore-lab-1/","title":"MOSPI-ChCore lab (1)"},{"content":"众所周知，计网被评为最困的计算机专业课，俗称计算机中的语文。👴看了《计算机网络－自顶向下方法》（后文简称CNTDA）之后，觉得翻译就像汤姆叔叔的烂苹果派一样糟糕，上帝啊，我发誓会狠狠踢他的屁股。建议带🔥去看英文原版。\n但是👴最近接触的许多实验还是很好玩的，于是本文试图通过全程动手实操学习计网。\n主要工具：\nwireshark是坠nb的网络封包分析软件。就是用来抓包的。 下载：https://www.wireshark.org/download.html 教程：https://www.javatpoint.com/wireshark\nscapy库是python的网络编程库，可以让你细致入微的操纵网络流量。就是用来发包的。 //不要和爬虫库scrapy混淆 scapy文档：https://scapy.readthedocs.io/en/latest/ 中文版：https://www.osgeo.cn/scapy/introduction.html //有些翻译错误\n计网基本概念 💣包(package) 等等，啥是“抓包”？啥是“发包”？啥是“包”？\n当然，包不仅仅是一个 CSGO 术语，在计算机网络中，包(package)有多个近义词，包括：报文/数据报(Datagram)，分组/封包(Packet)……根据语境不同而区分，但大致指的是同一件事情：即网络中真正流动着的东西，我们希望网络来传递的东西。只不过“包”是最通俗的叫法，那么抓包和发包就不难理解了。\n你还想问，包到底长什么样？众所周知，快递由包装和里面的东西组成，其实网络上的封包也差不多，也大致都有两部分：\n包头，学名首部(Header)——快递包装上的标签，写着目的地址，联系电话，快递号等信息 包体，学名载荷(Payload)——快递要运输的货物本身。某些语境下也喜欢称为报文。 当然，网络封包归根结底还是线性的比特序列，于是我们需要包头来识别这个封包的相关信息，就像看快递先看标签一样。\n另外，一个协议的封包也可以成为另一个协议的载荷，后面你会看到诸如pkt.payload.payload.payload.payload的套娃用法，要理解这种套娃，还需要知道分层思想。\n🍰分层(layering) CNTDA 中用邮政系统类比计算机网络，这是最常用的例子，这里我们用快递物流网来举例。随便打开你的网购记录，你会发现快递物流大概经过以下过程：\n客户发货：把货物和地址交给快递点 快递网点揽件：包装货物而变成包裹；包裹被送往最近的中转中心 中转中心运输：根据包裹目的地不同，分拣并装车运输给不同的中转中心；若收到本片区的包裹，卸车并分拣给不同的网点 快递网点派送：按包裹的地址，快递员送货上门 客户取件：拆箱，拿到货物，确认无误签收 你知道发一个快递要经历怎样的困难吗？你不知道，你只关心你自己。这里的重点是，客户不需要关心中转中心如何指挥重型货车或飞机，网点也只需要关心如何包装好客户的货物。快递网络明显的呈现出三层的分层架构，每一层之间只需要关心自己的工作，并和相邻的层交互。这就是应对复杂系统的组织方法——分层。\n课本上会提到OSI七层模型或者TCP/IP五层模型，这里的模型全称是协议分层模型，又来新词了，别急，后面还有：\n协议(Protocol)：同一层级内的交互规则。//横向 服务(Service)：不同层级间的交互规则。//纵向 每一层的工作，就是调用下层的接口，并为上层提供服务。接口(Interface)和服务的区别是，服务作为实体，由本层负责实现，暴露出接口供上层调用；而接口则是抽象的，本层并不知道下一层的可靠性。\n由此你能否看出分层思想的优越性？每一层只关注自己的实现，于是大问题被分解成了小问题。好比一个总工作量100的问题，不了解分层思想的你只能10+10+10+……=100；而分层思想提供了乘法法则，于是你可以通过10*10=100，只需要完成20工作量。//个中思想也体现了OOP中的解耦。\n上述类比中标注了一些对应关系：\n封包(Packaging)：包装，货物→包裹。信息在层次间传递的过程就是封包/解封的过程。 路由(Routing)：分拣。根据包裹上的标签，决定包装的去向。 可以看到，每一层都有自己的“货物”，比如中转中心的载荷是满载包裹的长途货车而不是单个包裹。报文在每一层都被封装并交给下一层，要想得到原始报文只能一层一层解开，操作模式类似栈。由此协议分层模型也被简称为协议栈(Protocol stack)。\n最后简单解释五层模型每一层的分工，自底向上顺序：\n物理层：对接物理介质，运输比特 提供基于比特的通信路径 链路层：将路径串联成链 提供基于链路的接入、交付、和传输服务 网络层：将链路编织成网 提供任意两主机之间的通信 运输层：将主机的通信分解为进程的通信 提供进程间的逻辑通信 应用层：实现用户需求 向用户提供透明可靠的网络服务 偶剋！你已经了解了分层思想，下面来设计互联网吧！（迫真）\n⌚️开始实验 有关计网的学习顺序自古就有自顶向下还是自底向上的分歧，余以为只要理解了分层思想，顺序便不算很重要。本系列实验将遵从浅入深出的原则，从应用层逐步深入到链路层再返回应用层，同时难度不断加大。\n实验来源：\n👴自己：0x10, 0x20 SEEDLab，雪城大学的信息安全课配套实验，网络安全部分。国内知名度不高所以值得一做。官方网站 CNTDA 实验：GIthub上抄的作业 实验代码仓库：lonelyuan/ComputerNetwork-exp (github.com)\n实验编号规则：0xabn\na：层级：1 - 应用层；2 - 传输层；3 - 网络层；4 - 链路层；5 - 物理层 b：难度：0 - ⭐；1 - ⭐⭐；2 - ⭐⭐⭐；3 - ⭐⭐⭐⭐；4 - ⭐⭐⭐⭐⭐； n：重复难度则再加一位编号 //【想看哪个没更新的可以催👴】\n0x10 应用层: Server | ⭐ Intro 目标：用scapy/socket做一个静态服务器。\n实际上，python3已经自带了一个简易http服务器：\n1 2 3 $ python3 -m http.server Serving HTTP on 0.0.0.0 port 8000 (http://0.0.0.0:8000/) ... 127.0.0.1 - - [10/Nov/2021 14:51:57] \u0026#34;GET / HTTP/1.1\u0026#34; 200 - 浏览器访问：localhost:8000，如果当前目录下有index.html文件，浏览器即可显示该html文档。\n该http服务器也是基于另一个python标准库socket编写的，本实验我们直接用socket实现一个更简单的http服务器。\n前置：\n术语：\nC/S架构(client-server)：互联网的基本模型。通信的双方通常分成两个角色：\n发起的一方称为客户端(C)，即前端。 接收的一方称为服务端(C)，即后端。为了保证随时接收请求，服务端需要持久监听某通信端口 URL：统一资源标识符。也就是互联网上的地址，网址。\n完整语法：[协议名]://[用户名]:[密码]@[服务器地址]:[服务器端口号]/[路径]?[查询字符串]#[片段] HTTP协议：应用层最普遍的文本协议之一。文本协议表示其所有内容都是可读的，其主要格式如下：\n1 2 3 4 5 GET / HTTP/1.1\\r\\n /* 一个状态行 */ Host: localhost\\r\\n /* 多个首部行 */ ... Connection: close\\r\\n\\r\\n /* 以两个CRLF(回车换行，编程时用\\r\\n表示)隔断 */ \u0026lt;html\u0026gt;... \u0026lt;/html\u0026gt; /* payload */ HTML：标记语言，用\u0026lt;\u0026gt;组织起网页的骨架。浏览器会把HTML源码渲染成好看的网页。\nsocket：逻辑通信的端点。\nsocket是逻辑通信的接口。上文提到网络层为运输层和应用层提供了点到点的逻辑通信服务，该服务的基本接口就是socket。 socket是通信端点的抽象。它将进程/应用和(主机host,端口port) 二元组绑定，于是通过 (host,port) 即可标记网络上的进程。 一个主机有一个地址和多个端口。地址和端口的关系，就像房子和窗户的关系。 socket由操作系统提供。本实验用到的是python对socket的封装，但不管换什么语言本质上都是系统调用。 //其翻译“套接字”非常具有误导性，建议直接用英文单词。 建议花5分钟通读《图解HTTP》前6章（或者《CNTDA》2.1-2.2节），以理解上述术语\nGuidelines Socket通信 要使用socket通信，通信双方都需要持有一个socket对象，其主要方法和生命周期如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 SERVER CLIENT socket() socket() │ │ ▼ │ bind((host,port)) │ │ │ ▼ │ listen(num) │ │ │ ▼ ▼ accept() connect((host,port)) │ │ ├──►send()──►recv()◄──┤ │ │ ├──►recv()◄──send()◄──┤ │ │ ▼ ▼ close() close() 于是我们可以建立起服务器代码的框架：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 import socket s = socket.socket() s.bind((\u0026#39;0.0.0.0\u0026#39;, 8000)) # 绑定地址和端口 s.listen(5) # 开始监听，num表示最大连接数量 while True: c, addr = s.accept() # c是客户端socket print(\u0026#39;[+] accepted:\u0026#39;, addr) req = c.recv(1024) print(\u0026#39;[+] recieved:\u0026#39;, req.decode(\u0026#39;utf-8\u0026#39;)) # 接收类型为字节对象bytes，要打印则应当编码为字符串 res = http_handler(req) # 解析请求，返回响应 c.send(res) c.close() It\u0026rsquo;s worth noting that，服务端socket并没有发送任何数据！accept()方法将返回一个客户端socket对象，由这个socket执行数据的收发。这样做的原因是为了实现多路复用，即让服务器支持多个连接同时通信。 于是我们可以看到，对每个TCP连接，都有一对socket存在于通信的两端。而服务端socket仅仅做了管理连接的工作，他们放在一个类里，是出于简化代码的考虑。（当然实现多路复用的方式不只有一种。 现在，你可以自己尝试编写socket客户端跟该服务器进行明文的通信。不过我们的目标是HTTP服务器，先复习一下HTTP协议格式，状态码，首部等知识吧。\nHTTP解析 如果编程能力尚可，你可以自己写HTTP类来把报文解析成对象。这里还是用现成的，scapy库提供的HTTPRequest和HTTPResponse类。\n1 2 3 4 5 6 7 8 9 10 11 12 13 from scapy.layers.http import * from scapy.all import * def http_handler(req_str): req = HTTPRequest() req.do_dissect(req_str) # 解析请求 print(\u0026#39;[+] req: \u0026#39;, req.summary()) # body = route(req.Path.decode()) # 路由函数 body = \u0026#34;\u0026lt;h1\u0026gt;Hello~~~\u0026lt;/h1\u0026gt;\u0026#34; res = HTTPResponse() res = HTTP() / res / body print(\u0026#39;[+] res: \u0026#39;, res.summary()) return raw(res) do_dissect()方法将字符串解析为对象\nHTTP()/res/body：scapy核心语法/，表示协议栈的堆叠，可以链式调用。\n这里的类型为：HTTP / HTTPResponse / Raw，之所以要这样三层表示，是因为HTTPResponse/HTTPRequest类仅仅是一个中间层，如果没有HTTP层，scapy会报warning。\nraw()方法返回封包的字节数组，可以看到在socket之上，我们先把报文转化为对象，解析之后再返回报文。\n观察封包的常用方法还有：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 In [2]: a = Ether()/IP(dst=\u0026#34;www.wsnd.com\u0026#34;)/TCP() In [3]: a Out[3]: \u0026lt;Ether type=IPv4 |\u0026lt;IP frag=0 proto=tcp dst=Net(\u0026#34;www.wsnd.com/32\u0026#34;) |\u0026lt;TCP |\u0026gt;\u0026gt;\u0026gt; In [4]: a.summary() Out[4]: \u0026#39;Ether / IP / TCP 0.0.0.0:ftp_data \u0026gt; Net(\u0026#34;www.wsnd.com/32\u0026#34;):http S\u0026#39; In [5]: a.show() ###[ Ethernet ]### dst = ff:ff:ff:ff:ff:ff src = 00:00:00:00:00:00 type = IPv4 ###[ IP ]### version = 4 ... proto = tcp chksum = None src = 0.0.0.0 dst = Net(\u0026#34;www.wsnd.com/32\u0026#34;) \\options \\ ###[ TCP ]### sport = ftp_data dport = http ... In [6]: ls(a) dst : DestMACField = \u0026#39;ff:ff:ff:ff:ff:ff\u0026#39; (\u0026#39;None\u0026#39;) src : SourceMACField = \u0026#39;00:00:00:00:00:00\u0026#39; (\u0026#39;None\u0026#39;) type : XShortEnumField = 2048 (\u0026#39;36864\u0026#39;) ... In [7]: raw(a) Out[7]: b\u0026#39;\\xff\\xff\\xff\\xff\\xff\\xff\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00E\\x00\\x00(\\x00\\x01\\x00\\x00@\\x06\\xc9\\xa8\\x00\\x00\\x00\\x00H\\ti\\x1e\\x00\\x14\\x00P\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00P\\x02 \\x00\\xdeW\\x00\\x00\u0026#39; In [8]: hexdump(a) 0000 FF FF FF FF FF FF 00 00 00 00 00 00 08 00 45 00 ..............E. 0010 00 28 00 01 00 00 40 06 C9 A8 00 00 00 00 48 09 .(....@.......H. 0020 69 1E 00 14 00 50 00 00 00 00 00 00 00 00 50 02 i....P........P. 0030 20 00 DE 57 00 00 ..W.. 现在运行服务器，用浏览器访问localhost:8000，你可以看到大大的“Hello”了！\nTask 下面的任务交给你，目标是尽量接近python自带http服务器的表现。\n为了实现静态服务器，你需要根据访问的路径返回对应的内容。为此，请完善route()函数：\n访问根路径/将返回index.html 使用os模块读取文件，注意文本文件和二进制文件（如图片）的处理 用HTTP响应码进行错误处理，比如404 NOT FOUND，302 REDIRECT 最后，在根目录(你在哪里运行你的服务器脚本，那里就是你的根目录)下放入任意文件，浏览器都可以访问其内容，如果不存在则会返回404。\nExpand 抓包观察访问你的网站和访问正常网站有什么区别。你会发现，本实验几乎没有讲解HTTP首部的细节，请自行了解诸如Content-Type:，Content-Length:，Transfer-Encoding:等首部，看看传输图片/压缩文件时的标准做法，以及在遇到大文件时如何实现分段运输。（尽管我们的实现很简陋，浏览器还是能正常工作，说明HTTP是相当健壮的协议） 你的服务器是否有安全问题？你可以访问根目录之外的文件吗？如： /../../../../etc/passwd（linux下） 服务器概念辨析：Web初学者容易对服务器概念感到迷惑。软件语境下，服务器指对外提供服务的程序，常用服务器如apache、nginx，tomcat等；硬件语境下则指运行着服务器软件的机器。 我们实现的是静态网站，你可能疑惑是不是还有动态网站。当然有，区分动态和静态并不是网页会不会自己动，而是服务器上的数据是否可以动态的改变，而我们的服务器只能被动的显示文件，客户端无法做出任何更改。现代web框架诸如Springboot，Django之类当然是动态网站框架。 实际上，计网并不关心应用层以上的东西，让我们向下看，探究socket背后的原理吧。\n0x20 传输层：Socket | ⭐ Intro 目标：用 scapy 实现TCP协议，以尽可能替换上一个实验使用的socket模块 // 你可能猜到了，下一个实验是不是要自己实现IP协议呀？恭喜你猜错了。 前置： 术语 TCP/UDP TCP报文格式 有限状态机 完成本实验仅涉及《CNTDA》3.4-3.5节，如果理解有困难，建议先完成Wireshark 实验：TCP观察 在上一个实验中，我们了解到socket是操作系统提供的系统调用，例如 Linux 中，创建socket对象返回的sock_fd本质上就是一个文件描述符，即建立连接后可以直接像文件一样读写，绑定端口后操作系统会保护该端口不被其他进程占用。而本实验关注运输层原理，所以绕过了操作系统，使用更底层的接口实现TCP。当然，是最简陋的一种实现。 Guidelines Socket实现原理 那么，socket里面到底有什么？首先，要保存地址端口等信息；其次，要有收发的两个缓冲区，这里可以用队列；然后，为了实现可靠运输，需要用到计时器来触发重传，需要变量标记滑动窗口；我们还用自动机思想来管理连接状态。Socket底层模型如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 ┌─────Socket──────┐ ┌─────┐ │ ────────────┐ │ ┌────┐ │ ├──┼─► SendQ ├──┼─►│ │ │ │ │ ────────────┘ │ │ │ │ App │ │ Buffers │ │ IP │ │ │ │ ┌──────────── │ │ │ │ │◄─┼──┤ RecvQ ◄─┼──┤ │ └─────┘ │ └──────────── │ └────┘ ├────Variables────┤ │ Status │ │ Timer │ │ SendBase │ │ NextSeq │ └─────────────────┘ 这里就需要面向对象上场了\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 class Socket: def __init__(): self.SendQ = Queue() self.RecvQ = Queue() self.Status = Status.CLOSED self.Timer = Timer() self.SendBase = 0 self.NextSeq = 0 # SERVER def bind(addr): self.addr = addr pass def listen(num): pass def accept(): #return c, addr pass # CLIENT def connect(addr): pass # BOTH def recv(length): #return data pass def send(data): pass def close(): pass 下面逐个实现socket接口。\n定制TCP报文\n连接管理\n了解了三次握手，就可以实现connect函数了\nTask 多路复用 目前的实现只能支持一个TCP连接，请实现listen(num)函数，调用时创建 num 对读写缓冲区，响应的为\n完善TCP功能： RTT 可靠运输 流量控制 阻塞控制 拓展UDP到你的socket Expand 0x30 网络层: 路由追踪 | ⭐ Intro 术语：\nIP层：IP协议，ICMP协议，路由协议 路由追踪：请求某地址经过了那些路由器？ Guidelines scapy实现了路由追踪函数，你可以钻研一下源码（很短），下面写一个自己的traceroute。\nTask 下面用Ipython演示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 In [1]: from scapy.all import * In [2]: target=\u0026#34;www.amazon.com\u0026#34; In [3]: ans, unans = sr(IP(dst=target,ttl=(1,30))/TCP(flags=0x2)) Begin emission: Finished sending 30 packets. .*****..**********..........................................................................^C Received 92 packets, got 15 answers, remaining 15 packets In [4]: for snd, rcv in ans: ...: print(snd.ttl, rcv.src, isinstance(rcv.payload, TCP)) ...: 1 11.206.119.46 False 2 11.110.80.173 False 3 10.102.15.74 False 4 11.73.2.241 False 5 124.160.189.101 False 6 219.158.97.2 False 7 219.158.34.190 False 8 69.192.14.38 True 9 219.158.24.134 False 10 219.158.10.30 False 11 69.192.14.38 True 12 69.192.14.38 True 13 69.192.14.38 True 14 69.192.14.38 True 下面讲解核心代码：\nans,unans=sr(IP(dst=target,ttl=(1,30),id=RandShort())/TCP(flags=0x2))\nsr()：send and receive，返回的两个参数分别是得到应答的数据包列表和未应答的包列表。 ttl=(4,30)：ttl参数在IP层表示ICMP包的转发次数（跳数）。此外，传入tuple表示一个范围，sr函数将会为这个范围内的每个值生成一个发包。（如果有多个tuple参数，则会按笛卡尔积规则生成发包列表） TCP(flags=0x2)：在TCP头部设定flag字段的值，0x2对应ACK，即确认收到包。 综合起来，这条代码将发送30个包，其ttl从1到30。并筛选返回ACK的包。 这样根据IP层路由算法，到达ttl的包无论是否找到目标都会返回，直到找到目标，TCP层返回ACK。遍历ttl形成的列表即是经过的所有路由。 Expand 0x301 网络层: 欺骗ping | ⭐ | TODO Intro 来源：https://seedsecuritylabs.org/Labs_20.04/Files/ICMP_Redirect/ICMP_Redirect.pdf 术语： Guidelines Task Expand 0x41 链路层: ARP缓存投毒 | ⭐⭐ | TODO https://seedsecuritylabs.org/Labs_20.04/Files/ARP_Attack/ARP_Attack.pdf\n0x21 传输层: TCP攻击 | ⭐⭐ | TODO https://seedsecuritylabs.org/Labs_20.04/Files/TCP_Attacks/TCP_Attacks.pdf\nTCP协议 SYN泛洪 TCP reset TCP session hijacking反弹shell （重点）\n0x31 网络层: NAT，DHCP和虚拟机 | ⭐⭐ | TODO 相信折腾过虚拟机的同学都绕不过这个问题：我的虚拟机怎么连不上网？本实验基于wmware虚拟机平台，讲解几种虚拟机网络模式及其原理。\n0x13 应用层: DNS本地攻击 | ⭐⭐⭐ | TODO https://seedsecuritylabs.org/Labs_20.04/Files/DNS_Local/DNS_Local.pdf\n0x14 应用层: SSL协议和HTTPS | ⭐⭐⭐⭐ | TODO 0x15 应用层: 多线程Web代理服务器 | ⭐⭐⭐⭐⭐ | TODO 0x151 应用层: VPN | ⭐⭐⭐⭐⭐ | TODO 探究VPN原理\n0x152 应用层: V2Ray协议学习 | ？？？ | TODO 有生之年研究一下Vmess等协议\n","date":"2021-10-22T23:55:54Z","permalink":"https://lonelyuan.github.io/p/%E4%BB%8Escapy%E5%92%8Cwireshark%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","title":"从scapy和wireshark学计算机网络"},{"content":" 上回书说到，网站初具雏形，但经高人指点，还是有很多不足。 本文将大胆扩充网站结构，目标是将网站拓展成一个 CMS 。 所以，不要停下来啊！👆（指开发\n0x00 蓝图与重构 与之前相比，网站将增加以下功能：\n图库：文件上传模块 评论：楼中楼功能 后台：权限模块，后台模块 优化：更健壮的数据库接口，更细致的权限控制 plus功能：用 redis 实现热搜 在开发这些功能之前，首先重整项目结构。如：\n完全蓝图化。参考 模板也放入独立子目录里，蓝图注册时使用template_folder参数，不过这样容易产生bug，flask 官方推荐使用硬编码，汗。 清理依赖，不使用维护状态差的库。 开发新功能的时候，去哪里找最佳实践，找好用的库呢？有一个 Github 搜索小技巧，名为 \u0026ldquo;awesome-xxx\u0026rdquo; 的仓库通常是某技术的优质资源列表。如：https://github.com/humiaozuzu/awesome-flask 0x01 文件系统 本部分参考了李辉大佬的系列文章， https://zhuanlan.zhihu.com/p/23731819?refer=flask\n头像，照片……文件上传是绕不开的话题。在上一篇参考的教程中，头像的实现是由托管网站生成随机的图片。遗憾的是并没有像 ORM 一样方便数据库处理的文件处理框架可供使用，还是自己把他啃下来吧。\n注意踩坑！大部份资料推荐使用Flask_uploads插件，然而使用该插件时出现如下报错：\n1 ImportError: cannot import name \u0026#39;secure_filename\u0026#39; from \u0026#39;werkzeug\u0026#39; 查阅Stackoverflow得知是PYPI源上的Flask_uploads插件不再维护了，于是和 werkzeug 库的api不兼容，是插件内在的bug。网上的解决方法有二：\n一是修改库源码 二是换另一个库，维护良好且可无缝迁移，名为Flask-Reuploaded 前者不利于后续部署，本人倾向于后者。然而，使用新库也遇到了诸多麻烦，使用UploadSet.url()方法时，报错如下：\n1 werkzeug.routing.BuildError: Could not build url for endpoint \u0026#39;_uploads.uploaded_file\u0026#39; with values [\u0026#39;filename\u0026#39;, \u0026#39;setname\u0026#39;]. UploadSet.url()方法返回对应文件的可访问url，返回的url默认带有_upload/前缀，这是 Flask-Uploads 自带的路由，也被称为 autoserve 。 然而官方文档里有这样一句话\nautoserve of uploaded images now has been deactivated; this was a poorly documented “feature”, which even could have lead to unwanted data disclosure; if you want to activate the feature again, you need to set UPLOADS_AUTOSERVE=True\n看来 Flask-Reuploaded 的作者似乎认为文件读取功能与我无瓜。好吧，这部分我们自己实现。\n// 浪费了一晚上debug，结果只是因为文档没看明白，再次证明读文档的重要性。\nFlask-Reuploaded: 文件上传 插件将上传的一类文件抽象成集合UploadSet。对每个 Set 有如下操作：\n配置文件类型：photos = UploadSet('photos', IMAGES) //类型包括：IMAGES、TEXT、AUDIO…… 配置存贮路径：app.config['UPLOADED_PHOTOS_DEST'] // Photos 为 Set 的变量名 保存文件：filename = photos.save(request.files['photo']) 返回链接：photos.url(filename) 最后，注册 Set 和插件注册类似：configure_uploads(app, [avatars, photos]) //可一次性全部注册\n实现头像上传的步骤如下：\n模型层： User 添加 avatar 字段，储存头像的文件名。原avatar()方法作为默认头像。 表单层： edit_profile 表单增加FileField字段 视图层： 储存文件，向数据库提交文件名。 模板层： 改用硬路由获取url。// 最终 .url() 还是有bug，再次说明不要乱用不知名的插件 图库模块 本模块包括如下路由：\n/index：主页显示瀑布流 /upload：上传接口：参考头像上传 /detail：详情，显示评论 /delete：删除接口：同时删除文件 由于本项目前端框架是 Bootstrap ，👴不想写Jquery，所以直接刷新页面，也不弄无限滚动了，按钮了事。另外为了不同列长度尽量均匀，故采用取巧的方法，平均分配。根据大数定理，只要随机图片足够多肯定会差不多均匀。。。。\n0x02 评论系统 数据库设计 评论包含了两个一对多关系，既是评论和文章的一对多关系，也是评论和用户的一对多。为此，只需要给User和Post添加关系即可。 然而，我们希望设计统一的Comment模型，评论的对象既可以是文章，也可以是图片，也可以是其他评论。为此，添加一个枚举类型的字段指示评论类型，从而采用不同的处理逻辑。\n楼中楼 而主流网站不光支持对文章评论，还支持楼中楼。对楼中楼的实现有以下几种方案：\n按时间平铺：以原百度贴吧为例 添加 reply_id 字段，指示要回复的人 套娃式缩进：以某些老式bbs为例 添加 parent_id 字段，指示父评论（顶层评论则为本身id），在实体类中保存子评论列表 弹窗式查看：以知乎，b站为例 在按时间平铺的基础上，若 reply_id存在添加“查看对话”按钮，递归的构建对话并弹窗。 其中，第一种实现简单，用户不友好；第二种实现复杂，对多层级对话无法胜任；第三种是最主流的实现方式。\n通过以reply_id作为指针，所有评论连接成了一棵树，在任意一个节点进行“查看对话”操作，就是执行树的寻根。“查看对话”函数如下：\n1 2 3 4 5 6 7 8 9 @staticmethod def view_dialogue(c_id): dialogue = [c_id] while Comment.query.get(c_id).type == \u0026#39;comment\u0026#39;: c_id = Comment.query.get(c_id).reply_id if Comment.query.get(c_id) is None: break dialogue.append(c_id) return dialogue 0x03 网站后台 网站的后台通常给管理员提供统一监管数据库的界面。有以下插件帮助实现：\nFlask-admin：一键生成后台页面，并可以自定义视图和模型。 Flask-Security： 比admin层次更高，封装了常用视图和模板。但是文档少，且很多功能我们已经实现了，再使用它就要推翻重做。遂弃用。 本教程中使用了 RBAC（Role-Based Access Control) 基于角色的访问控制，简单说就是设计一个角色表，用户表和角色表用关联表实现多对多关联。这样做的好处是，针对角色的权限分配，修改权限时无需修改每个用户。\n0x04 热搜 本节再加入一个重量级内容，利用 redis 实现浏览量排行榜，也就是热搜。当然，真正的热搜榜单排名规则更加复杂，这里只通过简单的浏览量计数来练习 redis 的使用。\n【👴有时间再做】\n不要让开发停下来 可以加的功能还有很多：时间线，emoji支持，多媒体，前后端分离(Vue)，，\n除了功能，当面对更高量级的流量时，网站性能便更加重要，这时候消息队列，PRC，微服务/分布式，，，更让人头秃。\nWeb开发之路，道阻且长。但是，只要开发不停下来，道路就会不断延申。。。（希望之花.mp3）\n","date":"2021-09-16T12:43:23Z","permalink":"https://lonelyuan.github.io/p/%E5%B9%B4%E8%BD%BB%E4%BA%BA%E7%9A%84%E7%AC%AC%E4%BA%8C%E4%B8%AA%E7%BD%91%E7%AB%99%E4%BA%8C-flask-supreme-tutorial/","title":"年轻人的第二个网站（二） - flask-supreme-tutorial"},{"content":" 本文为 Flask 框架学习笔记，主要参考了 The-Flask-Mega-Tutorial 和 《Flask Web开发：基于Python的Web应用开发实战》两本书，并在原项目的基础上拓展。（下文统称这两个资源为“本教程”） 不熟悉 Flask 框架请先阅读快速上手 - flask 中文文档 。\n这两本书的作者是同一个人，就内容上说后者算是前者的豪华版。本教程的优点是内容全面，从入门到部署一站式服务；缺点是不够深入，且有些过时，书中举例的诸多插件均为作者为了此书而开发的，已经许久不再维护，导致很难在其示例项目上拓展。一看扉页，2015年出版，那没事了。 至于第一个网站？参见#TODO:年轻人的第一个网站\n0x00 大型项目结构 在大部分面向初学者的 demo 中，应用以简单的项目结构甚至单文件表示。在大型项目中，网站的不同功能被拆分成独立的模块，以方便拓展和维护。一个更通用的 Flask 项目代码架构如下：（仅考虑业务代码）\n1 2 3 4 5 6 7 8 9 10 microblog/ # 根目录 app/ # 项目源码 __init__.py # 项目初始化，当该包被import，首先执行__init__.py routes.py forms.py ... main.py # 框架入口 config.py # Config配置类 .flaskenv ... 根目录下的文件有：\napp/所有网站源代码统一归到app目录下。 在app/内部，不同的功能可进一步划分成独立模块，详见[模块化应用](#0x05 模块化应用：功能解耦)一章。 main.py: 入口脚本，通过该文件引入app中的代码并生成应用实例（命名随意） .flaskenv: flask环境变量，以配合flask命令。入口脚本被定义为FLASK_APP，执行flask run时将启动该脚本。 config.py: 配置脚本，整个项目的配置信息都写在Config类里。与环境变量的区别在于，因为是python脚本，功能更强大，可被任何地方的代码引用。 0x01 Hello world：模板和视图 最基本的 web 功能，无非接受请求、返回数据。其中，路由 (route) 用来区分不同的请求，模板 (templates) 用来生成不同的数据。\n路由/视图 在非前后端分离的项目中，视图函数直接返回渲染好的网页，由@app.route()修饰后，视图和路由便绑定在一起。 在mvc模型中更像controller控制器的角色，然而在flask生态中更喜欢称为视图函数。\nurl_for() 使用URL到视图函数的内部映射关系来生成URL，用来替换硬链接。在业务功能解耦后必须使用这种方式。 NOTE：当路由和视图函数名不一致，访问该路由可以正确响应，但是使用url_for()调用该视图时会报错 {% extends \u0026quot;base.html\u0026quot; %} and {% include \u0026quot;_post.html\u0026quot; %} 使用子模板来实现网页公用的部分。如：页眉，页脚，列表项等。 模板和 Python 代码的关系有些类似与 JSP 和 Java 代码的关系，但模板语法并不是完整的脚本语言，相较而言限制更多，安全性更好。 表单 几乎所有成功的框架都有丰富的插件生态。下面引入新功能时，大多借助插件来方便的实现。大多数Flask插件使用flask_\u0026lt;name\u0026gt; 命名约定。\nFlask-WTF插件提供了对Web表单的抽象，只需定义表单类以及设置类属性即可。\n模板语法：\n{{ form.\u0026lt;name\u0026gt;.label }}渲染标签 {{ form.\u0026lt;name\u0026gt;() }}获取属性值 form.hidden_tag()模板参数生成了一个隐藏字段，其中包含一个用于保护表单免受CSRF攻击的token 将表单引入模板\n1 2 form = LoginForm() # 生成了一个实例传入模板 return render_template(\u0026#39;login.html\u0026#39;, title=\u0026#39;Sign In\u0026#39;, form=form) flash 闪现消息 flash 通过 session 储存，用于显示只出现一次的提示消息。用法：\n在路由中使用flash()，触发时消息便写入 session 中的 message 列表 在模板中使用get_flashed_messages()，从 session 中读取 0x02 数据库 ORM 很久很久以前，web网站和数据库交互还需要写很多很硬的 SQL 语句，效率低且容易出现注入漏洞(SQLi)。现代web开发都使用 ORM 框架简化数据库交互，且基本杜绝了 SQLi 漏洞。\n本项目使用如下插件打通数据库：\nFlask-SQLAlchemy: Python生态最知名的ORM框架 Flask-Migrate: 本教程作者编写的数据库迁移框架 插件首先要注册。统一流程: 初始化app实例，传入插件类作为插件实例的参数\n1 2 3 4 5 # app/__init__.py app = Flask(__name__) # flask基类 app.config.from_object(Config) db = SQLAlchemy(app) migrate = Migrate(app, db) SQLalchemy：model层 模型定义 使用类和类属性代表 table 和 colunm ，便可轻松编写数据模型。SQLalchemy 的概念抽象如下图： Flask-SQLAlchemy 自动设置类名为小写来作为对应表的名称，也可以用__tablename__类属性来定义。\n1 2 3 class Post(db.Model): # 表 id = db.Column(db.Integer, primary_key=True) # 列 .... CURD基本操作 ORM 框架通常集成了常用操作，但也支持更底层的数据库接口。\n在 Springboot Jpa 中，根据方法名的拼写来写自定义查询，而在 SQLalchemy 中，提供的接口通过链式调用拼接。\n在 SQLalchemy 中，基本操作大都有基于事务 (session) 的和基于查询 (query) 的两种方式。\n查\n1 session.query(User) query方法只有构造一个查询，只有在Query.get()、Query.all()、Query.one()等结束符之后才会执行查询\n增：\n1 2 db.session.add(user) db.session.commit() 删\n1 2 3 4 session.query(User).delete() # or session.delete(session.query(User).get(1)) session.commit() 改\n1 2 3 4 5 6 7 8 9 query = (session .query(User) .filter_by(id=1) .update({\u0026#34;username\u0026#34;: User.username + \u0026#34;a\u0026#34;}, synchronize_session=False) ) # or user = (session.query(User).get(1)) user.password = \u0026#34;zxcv\u0026#34; session.commit() Flask-Migrate: 数据库迁移 配置数据库的初始数据框架，一般写成SQL脚本形式。 migrate 框架直接根据 model 层生成迁移脚本，可以方便的跟踪数据模型的修改和数据库的切换。（这个框架还是本教程作者自己开发的，强）\nflask db子命令\nflask db init：初始化，生成migrations目录 flask db migrate：生成迁移脚本，修改model后使其生效 flask db migrate -m \u0026quot;posts table\u0026quot; flask db upgrade：应用数据库修改（开发阶段默认使用sqlite数据库 flask db downgrade：回滚上次的迁移 0x03 开发范式：用户系统 mixin：混入，多重继承的一种形式\n表单和数据库支持分别解决了前端和后端的基本需求，下面可以上线一个基本功能了，用户登录。 所需插件：Flask-Login。\nUserMixin类 UserMixin类集成了login插件要求的用户模型属性，将其混入到 User 模型中，即可用@login_required 实现权限控制。\n1 2 @app.route(\u0026#39;/result/\u0026#39;, methods=[\u0026#39;POST\u0026#39;]) # NOTE：有顺序关系，反之则不生效 @login_required 用户系统，包括登录、登出、注册几个功能。编写这些功能的步骤其实很类似：\n设计数据库，在model.py中 设计表单对象，在form.py中 设计页面，在模板.html中 设计视图函数，在routes.py中 也对应了mvc框架的设计理念，比如设计表单就有些像 javaweb 中的 DAO 层。但也有区别， Flask 框架更希望业务逻辑写在数据库模型中，而视图函数尽量保持简洁，以方便单元测试。\nPRG 模式 即为 Post/Redirect/Get，其格式大概如下：\n1 2 3 4 5 6 7 8 9 @bp.route(\u0026#39;/some_form\u0026#39;, methods=[\u0026#39;GET\u0026#39;, \u0026#39;POST\u0026#39;]) def some_form(): # prepare forms if form.validate_on_submit(): # submit modification return redirect(url_for(\u0026#39;main.some_form\u0026#39;)) elif request.method == \u0026#39;GET\u0026#39;: # GET data return render_template(\u0026#39;some_form.html\u0026#39;, form=form) 默认情况，提交 POST 请求后，如果直接刷新浏览器，会重新在 POST 一次。使用PRG模式即可解决重复提交表单的问题。\n0x04 深入数据库：粉丝机制 数据库关系 要关注别人，就要让数据库记住我关注的人的名字，当然，只记住名字肯定不够，万一改名了呢。因此每个用户都需要有唯一有效的标识（其实更重要的是性能因素）。正因如此，数据库中每个表都要有一个唯一的列，称为主键(primary key)。当不同表之间存在关系，一个表要通过主键寻找其他表项，其他表的主键储存在本表中，称为外键(foreign key)。外键关联既可以表示一对一的关系，也可以一对多(1-\u0026gt;n)。\nSQLalchemy 对关系的定义如下：\n外键：db.ForeignKey('user.id') 关系：db.relationship('Post', backref='author', lazy='dynamic') 参数1：所关联的表(n in 1-\u0026gt;n)，这里是模型的变量名 参数2：由 \u0026ldquo;n\u0026rdquo; 回调 \u0026ldquo;1\u0026rdquo; 的虚拟字段，用法：post.author 粉丝机制 然而，粉丝机制包括关注和被关注。这是一种多对多的关系，于是需要用含有两个外键的关联表表示。又因为关注者和被关注者在一个表里（User），这种关系又称为自引用。\n模型 关联表只有引用类型，故不需要派生模型类\n1 2 3 4 5 followers = db.Table( \u0026#39;followers\u0026#39;, db.Column(\u0026#39;follower_id\u0026#39;, db.Integer, db.ForeignKey(\u0026#39;user.id\u0026#39;)), db.Column(\u0026#39;followed_id\u0026#39;, db.Integer, db.ForeignKey(\u0026#39;user.id\u0026#39;)) ) 为User添加关系\n1 2 3 4 5 followed = db.relationship(\u0026#39;User\u0026#39;, # 右侧实体 secondary=followers, # 指定关联表 primaryjoin=(followers.c.follower_id == id), # 指定左关系 secondaryjoin=(followers.c.followed_id == id), # 指定右关系 backref=db.backref(\u0026#39;followers\u0026#39;, lazy=\u0026#39;dynamic\u0026#39;), lazy=\u0026#39;dynamic\u0026#39;) # 指定回调 复杂查询 查询粉丝列表\nSQL 语句：SELECT * FROM user, followers WHERE followers.follower_id = 3 AND followers.followed_id = user.id\nSQLalchemy 接口：user.followers.all()\n实际执行的 SQL 语句：（打印 query 对象得到）\n1 2 SELECT ,,, FROM user, followers WHERE followers.followed_id = ? AND followers.follower_id = user.id NOTE：如果方法集成在model里，方法名不要和字段名相同，自己定义的方法会覆盖该字段。\n查看已关注用户的动态\nSQL 语句：SELECT * FROM post JOIN followers on followers.followed_id = post.user_id where followers.follower_id = 2\nSQLalchemy 接口：\n1 2 3 4 Post.query.join( followers, (followers.c.followed_id == Post.user_id)).filter( followers.c.follower_id == self.id).order_by( Post.timestamp.desc()) 实际执行的SQL语句：\n1 2 3 4 5 6 7 8 9 SELECT ,,, FROM (SELECT ,,, FROM post JOIN followers ON followers.followed_id = post.user_id WHERE followers.follower_id = ? UNION SELECT * FROM post WHERE post.user_id = ? ) AS anon_1 ORDER BY anon_1.post_timestamp DESC 由于python的弱类型特征，有时候很难明白函数之间传递的是什么对象。我们从上往下梳理一遍：\n请求到达路由函数，开始执行查询Post.query.....，此时只是在构造查询，并未取得数据，此时的对象类型：\u0026lt;class 'sqlalchemy.orm.query.Query'\u0026gt; 直到get(),all(),paginate().items结束符等出现，查询才被执行，返回数据类型实例，如User。 数据类实例传入模板，并由__str__等方法参与渲染。 0x05 网站美化 本教程提供的flask-bootstrap插件，较为简陋，且该插件年久失修，遂替换之。在此之前，先搞明白目前项目前端的架构\n1 2 3 4 5 6 7 /templates auth/ errors/ base.html _posts.html index.html ... 所有模板都有一个父模版：base.html，其结构如下：\n1 2 3 4 5 6 7 8 9 {% extends \u0026#39;bootstrap/base.html\u0026#39; %} {% block title %}Hallo Wolrd{% endblock %} {% block head %} ... {% endblock %} {% block scripts %} ... {% endblock %} {% block navbar %} ... {% endblock %} {% block content %} ... {% block app_content %}{% endblock %} {% endblock %} app_content留空，即其余模板均在app_content内填充。\n进一步追溯bootstrap/base.html的源码，发现其它 block 诸如navbar也都留空或仅仅配置了 Bootstrap 的 cdn。 由此，只需将base.html迁移即可。\n在网上寻找新的UI模板，不要在中文互联网搜索，basically garbage。找到一个 Meterial 模板 还算顺眼，遂用之。\n不熟悉 Bootstrap 布局的可以使用可视化工具来设计前端，如：http://www.ibootstrap.cn/\n对照模板，将base.html掏空，效果如下：\n遇到的bug有：\n下拉菜单失效：查询得知有可能是bootstrap版本冲突 //结果并不是，只是忘记引入js文件而已，我是傻逼。 文件上传按钮消失：本教程中，表单渲染采用wtf.quick_form()，这玩意还是来自bootstrap/wtf.html 最后决定整个🐏了 Flask-Bootstrap 插件。\n富文本编辑器 在《Flask Web开发：基于Python的Web应用开发实战》中提到了markdown编辑器的实现。\n需要的包：\nPageDown: JS 版 Markdown 渲染器，用于客户端预览。 Flask-PageDown: flask 集成插件。该插件需要注册 Markdown: Python 版 Markdown 渲染器，用于服务端渲染。 Bleach: HTML 清理器，保证安全性 为了兼顾安全和效率，做法是同时保存 markdown 源文本和 HTML 文件。步骤如下：\n表单改为 PageDownField 模板引入 PageDown 宏，以实现即时预览 为 Post 模型增加字段，并添加 markdown 渲染方法，该方法为类方法，需要@staticmethod修饰 在模型外部监听数据库事件，仅当 markdown 文本出现变动时调用渲染方法。 修改模板以显示服务端返回的 html 文本 然而预览器过于简陋，也很难修改。在github仓库上发现该插件也是本教程作者写的，已经很久没有维护。顿时对本书作者有些不满。\n0x06 模块化应用：功能解耦 保持 app 作为全局变量的模式，可能会给后续引入新功能和单元测试带来麻烦。 要适应大型项目需求，需要把网站功能拆分成独立的模块。\nBlueprint化 要实现解耦，一种功能的相关代码可以借助Blueprint归类到一个包里。其文件结构大致如下：\n1 2 3 4 5 6 7 app/ some_fuction/ \u0026lt;-- blueprint package __init__.py \u0026lt;-- blueprint creation ... other code ... templates/ some_fuction/ \u0026lt;-- templates __init__.py \u0026lt;-- blueprint registration 创建blueprint与创建应用非常相似。\n1 2 3 from flask import Blueprint bp = Blueprint(\u0026#39;func\u0026#39;, __name__) from app.func import Func 而消灭了app，蓝图内部的引用统一变成了蓝图名。而外部诸如url_for的参数则需要加上包名.做前缀。\n应用工厂模式 工厂函数是一个外部函数，在这个函数内部执行插件注册和配置工作，并通过他返回应用实例。\n1 2 3 4 5 6 7 8 # app/__init__.py db = SQLAlchemy() # ... def create_app(config_class=Config): app = Flask(__name__) app.config.from_object(config_class) db.init_app(app) # ... 返回后，flask提供的上下文对象current_app将指向应用实例。详见官方文档：应用上下文\n多线程 current_app是线程绑定的，若要在诸如邮件服务的位于其他线程的功能调用他，则会发现没有赋值。 需要使用current_app._get_current_object()表达式。\nPython概念辨析：包，库，插件 包 (package) 是指一种代码结构，只要有文件夹和 __init__.py 都是包。 库 (library) 和插件 (plugin) 都是从外部引入的包，区别在于，插件要集成进应用，所以需要注册等步骤；而库更独立，可以随时随地调用\n0x07 开发帮手 本节讲解一些杂项。\n调试 flask shell命令：为避免每次调试都要重新import app，使用上下文调用解释器，用@app.shell_context_processor装饰上下文函数 单元测试 unittest 库，详见下一篇。\n记录日志到文件 logger 库\n1 2 3 4 5 6 7 8 9 10 11 12 if not app.debug: if not os.path.exists(\u0026#39;logs\u0026#39;): os.mkdir(\u0026#39;logs\u0026#39;) file_handler = RotatingFileHandler(\u0026#39;logs/microblog.log\u0026#39;, maxBytes=10240, backupCount=10) file_handler.setFormatter(logging.Formatter( \u0026#39;%(asctime)s %(levelname)s: %(message)s [in %(pathname)s:%(lineno)d]\u0026#39;)) file_handler.setLevel(logging.INFO) app.logger.addHandler(file_handler) app.logger.setLevel(logging.INFO) app.logger.info(\u0026#39;Microblog startup\u0026#39;) requirement.txt 装的库太多怎么办？只需要两条命令：\n1 2 pip freeze \u0026gt; requirements.txt pip install -r requirements.txt 0x08 网站上线 最后简单列出几种网站部署的方法，详情参考本教程或自行搜索。\nnative模式 买主机 连主机：ssh 买域名 配域名 配环境 数据库 服务器 其他依赖 持续运维 容器化技术：docker 写dockerfile docker-compose up \u0026ndash;build -d 云技术：PaaS 注册云平台账户 写Procfile git push ","date":"2021-09-09T20:18:56Z","permalink":"https://lonelyuan.github.io/p/%E5%B9%B4%E8%BD%BB%E4%BA%BA%E7%9A%84%E7%AC%AC%E4%BA%8C%E4%B8%AA%E7%BD%91%E7%AB%99-the-flask-mega-tutorial/","title":"年轻人的第二个网站 - The Flask Mega Tutorial"},{"content":"🛁 这是👴第一次打高达80支队伍的大型AWD，👴此行的目标就是称霸酒店的游泳池。后来发现游泳池要钱，👴只能遗憾败北。（后来发现情报出了问题，根本不要钱，血亏）总的来说，酒店浴缸很带，主办方态度很好，赛场很清真，参赛体验很爽，赚了。\n“终端越炫，嗨客越带；嗨客越带，帽子越带”\n🐐AWD复盘 首先根据参赛手册，进行一个规则的复制：\n1 2 3 4 5 6 7 8 9 10 11 1、 采用线下赛的方式，参赛团队通过有线连接到局域网，并进行网络连通性的测试。请自备连接网络所需要的设备如usb转RJ45转换器等工具。 2、 攻防赛部署若干道赛题，初始分值为10500分。 3、 使用xctf用户通过ssh连接GameBox，GameBox的ip地址和登录密码通过赛事页面下载获取。 4、 比赛10分钟/回合，每个回合会更新GameBox上的flag。 5、 每个回合内，一个战队的一个服务被渗透攻击成功（被获取到flag并提交），则扣除10分，攻击成功的战队平分这些分数。 6、 每个回合内，服务宕机或无法通过check则会被扣除10分，服务正常的战队平分这些分数。 7、 参赛战队在修复漏洞时，请保持服务的正常功能和打印字符、界面样式，否则将无法通过系统check。 8、 每个回合内，服务异常和被拿flag可以同时发生，即战队在一个回合内单个服务可能会被扣除两者叠加的分数，最多扣除20分。 。。。 7、 请参赛战队在比赛开始时对所有服务进行备份，主办方仅提供2次重置机会，2次机会使用后不予重置。申请重置时请提供战队名称。 8、 禁止使用通用防御方法如waf等工具，违规者第一次被发现扣除当前分值的10%，第二次被发现扣除当前分值的50%，第三次被发现取消参赛资格并向其学校发文进行通报批评。 比赛全程收手机，断外网，不能用waf，不准用不死马，大家都很清真，找回了ctf最初的快乐。 然后按照AWD开局的任务清单，进行一个盘的复：\n准备阶段 ssh连接： 主办方提供了ssh密钥，和靶机ip 于是省略 ssh-copy-id -i ~/.ssh/id_rsa.pub root@xx.xx.xx.xx环节。 但是万能的Windows Terminal连不上去（依然不知道为啥），👴只能用图形化ssh客户端添加私钥连接。 IP扫描： 共有7道题，3道web，4道pwn，每道题目一个独立靶机，有独立的ip地址。不同靶机d段不同，不同队伍c段不同，按初赛排名分配。平台上告知了全部的ip列表。 于是省略nmap -sn xx.xx.xx.0/24环节。 选手机和靶机池在一个局域网内。不同队伍c段不同，一个队伍内的不同电脑d段不同。 流量监控： 主办方贴心的提供了被打流量(但是只有下行流量)，直接在~/package目录下给出.pcap文件。 于是省略tcpdump tcp -i eth0 -t -s 0 and dst port ! 22 and src net 192.168.1.0/24 -w ./target.cap环节。 (不过用户名叫xctf，权限卡的很死。不给流量的话估计也只能在站里上流量监控脚本) 更新速度很快，被打之后几乎可以立刻找到流量。于是手速很重要。 开局阶段 备份源码：tar -zcvf w.tar.gz /var/www/html 结果\u0026gt; Permission Denied，遂跳过 扫马删马：D盾 👴直接在图形化shell里下载代码，然后崩屎了几次，手速慢了。 每个web题都有一个不明小文件，显然是小马，删除之。 备份数据库：mysqldump -uctf -p --databases [dbname] \u0026gt; /tmp/db.sql 结果\u0026gt; Permission Denied，遂跳过 改数据库密码：mysql\u0026gt;SET PASSWORD FOR ctf@localhost=PASSWORD('newpass'); 结果\u0026gt; Permission Denied，(╯▔皿▔)╯玩nm 然后开始源码审计(❌) 然后等待被打之后翻流量(✔️) 攻防阶段 👴只看得懂web题目。三道web题全是cms，是经典lamp环境。可是👴看不懂cms，👴是five。\nweb1：safecms 比赛一开始，啪的一下很快啊，全场被打，翻流量抓到payload，是一个模板文件的任意读漏洞。直接批量拿flag。 定位到路由，注释之，不好使，还是被打；删除这个.class.php，不好使；👴怀疑是运行时缓存不更新，直接service restart apache2 结果\u0026gt;Permission Denied，👴佛了 就这样被打了好一会，才发现直接修改index.php，能直接生效，血亏。 web2：eyou 这道题被打的很少，被宕机的很多。抓流量，发现很多混淆流量。（日志写shell？） 👴跟着流量尝试用过滤的方法修复，但是还是被宕。 若干轮后，👴没办法，只好申请重置，并在下一轮被宕。 若干轮后，👴没办法，只好申请重置，并在这一轮被宕。 若干轮后，👴没办法，只好白给，并在某一轮恢复正常并坚持到最后。我？？？ 该不会是某队或者裁判看我们太可怜帮我们重置了吧，世界上还有这么温柔的人，我真的哭死 这道题无了。（赛后才知道，有队伍找到sqli并登录后台，在后台关闭了站点并羊了管理员账号。修nm。 web3：lol 这道题是最后三小时放的，👴这时候已经自闭了几个小时。于是👴痛定思痛，开局直接把admin.php羊了，然后奇迹般的守到了最后。坏了，好起来了。 全场被打，翻流量找到payload，某路径下有白给shell，直接删马并反打。 某队使用了在网页输出中塞随机字符串的防御方法，但是没破坏flag，且填充的字符是固定的，被我肉眼识破，我直接进行一个if ip == xx: flag = flag[12:]。虽然没什么卵用，但是很快乐。 pwn： 一看到4个pwn👴直接傻掉。👴觉得👴不会做，因此也没去看，但听大佬说，直接抓流量进行一个转发就能拿分，👴下次一定准备好pwntools。\n🔒自动化攻防框架 AWD中，手交flag实在是很浪费时间的行为。虽然有时候自动化不太好写只能手交，像这次十分钟一轮，有72支队伍，就算你手速惊奇，也没有时间审计源码了。因此打AWD重点就在一个自动化。网上能找到各种框架，但是用的时候总是不顺手，遇到bug也不会修。只有自己写的才最好用。\n先说说用处最大的工具，就是批量攻击框架/自动化攻击脚本。这个框架主要有以下要素：\n输入： 待攻击ip列表：通常写在ip.txt里 攻击函数：即封装好的payload请求 交flag函数：根据平台接口封装 输出： 批量攻击，输出攻击结果 攻击成功则提交 反馈得分结果 框架的核心无非以下逻辑：\n1 2 3 4 5 6 7 8 while True: for j in challenge_list: # 攻击函数索引 for i in ip_list: # 首先生成ip列表 flag = get_flag(i,j) # 根据j找到相应攻击函数 if flag!=\u0026#39;Attacked failed\u0026#39;: submit_flag(flag) print_result(j) time.sleep(round) 比赛时，找到漏洞或者抓到流量，立刻写好相应的攻击函数，重启脚本即可。\n为了提高稳定性和易用性，这套框架可以写的很复杂。比如：\n加入多线程，让框架非阻塞的持续运行 加入面向对象，写成类库 自带一些trick，比如流量混淆器等。 当然，还可以写一个网站来可视化管理 这里就涉及框架编程了，能深挖的地方还有很多。\n除了批量攻击脚本，用到的脚本还有：\n权限维持/批量shell脚本：用于管理多个shell 但是不死马被禁用，因此本次比赛中shell出现的不是很多。 （👴还准备了拿到白给shell之后持久化的脚本，结果一个shell都没拿到，准备个🔨。 文件监控脚本：用于监控flag等重要文件被读取和修改的准确时间，可以帮助确定payload 再牛逼一点还可以提供系统备份和回复功能。 上述都是系统脚本，大多在本机用python写的。下面说几种网页脚本，即直接用require/include包含的php脚本\n流量监控脚本：区别于系统级流量监控，用于监控敏感流量以抓取payload 通防脚本：也就是waf，可以进行很充分的过滤 本次比赛中被禁用，因为确实破坏游戏体验 这些脚本，用好了才是趁手的兵器。这次比赛中👴的手速远不够快，延误了很多战机。\n🌊快进到《考试周破防》 回顾整场比赛，相比正经的漏洞挖掘，随机应变的能力对分数也有很大影响。总结几个因素：\nawd的得分是随时间积累的，因此要掌控全局，时刻盯紧每道题有无薄弱环节和突破口。本次比赛题目数量多达7道，👴队有大佬没来，还带了一个萌新，约等于二打四，出现了看不过来题的情况。\n还有就是手速，由于流量很及时，payload一被抓到，甚至可以在一轮check之内丢进批量攻击脚本，直接和首先挖掘到漏洞的队伍平分分数。这要求自动化脚本的熟练运用，尽量避免手交flag。\n最后还有一点策略问题。分析三种题目状态，列个表定性分析一波最优解：\n能反打 不能反打 场上大多数Attacked 先反打再修洞 不能修洞则down自己 场上大多数CheckDown 打他喵的 尽量别down 出现漏洞大部分人会被打，这时如果你不能立刻修补而能立刻反打，相当程度上是不亏的。如果你修不好也可以选择宕机，因为这样分摊了丢掉的分数。 尽量避免被打+被宕，扣双倍分数属实是血亏。如果决定宕机，先摸清check的时间和结算的时间，最好在新一轮结算后立即删站down自己。 当然，如果您能挖到洞，宁就是垂直上分的👴。 从8点半到6点半，打10个小时的AWD，要全程保持敏感和机智，确实对身体素质有些要求。👴坐高铁到合肥坐了6小时，打比赛坐了10小时，好悬没给我痔疮坐出来。晚上回到青岛并进行最后一次夜店，快进到《考试周破防》。\n","date":"2021-06-16T16:54:30Z","image":"https://lonelyuan.github.io/p/ciscn2021%E5%8D%8E%E4%B8%9C%E7%99%BE%E8%B5%9B%E5%8C%BA%E5%88%86%E5%8C%BA%E9%80%89%E6%8B%94%E8%B5%9Bawd%E5%A4%8D%E7%9B%98/awd-da-pian_hub2213acc3516fead069948e4c2b6c9af_78570_120x120_fill_q75_box_smart1.jfif","permalink":"https://lonelyuan.github.io/p/ciscn2021%E5%8D%8E%E4%B8%9C%E7%99%BE%E8%B5%9B%E5%8C%BA%E5%88%86%E5%8C%BA%E9%80%89%E6%8B%94%E8%B5%9Bawd%E5%A4%8D%E7%9B%98/","title":"CISCN2021华东百赛区分区选拔赛AWD复盘"},{"content":" 本文所述为计算机组成原理课拓展实验的相关记录，基于“龙芯体系结构与CPU设计教学实验系统” 项目官网： http://www.loongson.cn/business/general/teach/356.html； 相关资料代码：#TODO:: github仓库 PS：标题可简记为《基于基于的一种基于的一种实现》\n🤓吐槽时间 快考试了，👴发觉👴计组学了个🔨，👴去年也学了个🔨，但是去年可以归因于晦气的晦气，今年只能说自己晦气。难道还要重蹈去年的晦气吗？👴本应该回去背课本，刷考研题，但是👴一看ppt就想起我们敬爱的《计算机组成原理》课的任课老师，丐哥反复强调的至理名言：“听不懂的举手（无停顿）都没举手，都听懂了，非常好。”本人十分钦佩丐哥老师对幽默感的独特理解。\n（但是特此声明：本人不了解、不认同其关于\u0026quot;5G是个几把\u0026quot;，\u0026ldquo;高晓松很nb这个人\u0026rdquo;，\u0026ldquo;钱=浪漫\u0026quot;等议题的看法）\n而且👴这人很怪，课本上的重点，不好玩；选做的实验，好玩！哎就是玩，怪不得卷不过别人，你也配卷？滚去考研吧。\n众所周知，计算机学生的本科生涯，如果能做到在自己设计的CPU上运行自己写的操作系统并用自己写的编译器跑代码，那就非常成功了。👴差不多，👴能在自己搜的代码上写自己的注释并用自己的电脑截图，都是三个\u0026quot;自己\u0026rdquo;。那么今天给大家爆个啥捏，流水线奥。\n🔧 “用”计算机→“造”计算机 上回书说到（#TODO:: CSAPP大篇），汇编器(as)让我们得到了机器能看懂的比特流，最后一步只需要连接器(ld)将其和其他调用一起载入内存。这回答了程序如何在CPU这个平台上运行的问题，然而一个更基本的问题是，这个现有的平台是如何实现的？一个粗略的认识是，我们知道这些足以实现CPU的复杂的逻辑，其最小单元总对应到简单的诸如逻辑门上面，但是落实到真正的物理实现之上，如何使效率最高？功耗最小？这些问题所跨越的复杂度的量级依然是一片巨大的迷雾。照亮这片迷雾的知识，大概隶属于IC学科。\nHowever，作为CS专业而不是IC专业，我们的目标仅在于理解所谓“组成原理”。在IC产业的复杂度规模数轴上，向下是专有芯片（又称嵌入式？），功能专用，规模较小；向上是通用芯片，即手机电脑等的核心，其难度不言而喻。位于中间的FPGA则既兼顾了自由度也考虑了速度，因此，这玩意能满足CS本科教学的需要（主要是便宜耐操）。\n🔮高贵的IC工程师都用啥轮子 Vivado是一个FPGA集成设计平台（也算一个EDA？），他主界面左侧的工作流窗口很好的概括了利用FPGA开发的基本流程。即\n编写设计源码(Source)：使用Verilog语言编写逻辑或引入IP 设计仿真模拟(Simulation)：通过观察仿真波形图和编写testbench来对设计进行debug 综合(Systhesis)门级网表：从RTL级描述降维到门级网表 生成(Implementation)布局布线：根据管脚约束，将依然是虚拟的门级连线落实为实际的线路 进行硬件编程(program)：生成比特流并写入目标设备 名词解释： IC：集成电路 FPGA：现场可编程门阵列 Verilog：一种硬件描述语言，语法涵盖了自顶向下五个抽象层面：系统级、算法级、RTL级、门级、开关级。 RTL：寄存器传输级。一般使用最多的就是RTL级。 IP：Intellectual Property内核模块，可以理解为将代码封装为函数。分为，软IP内核(soft IP core)，固IP内核(firm IP core)和硬IP内核(hard IP core)3个层次，相当于集成电路的毛坯、半成品和成品。 SoC：片上系统，大概是芯片及其装载的第一层软件接口的集合，很宽泛的概念。 EDA：电子设计自动化。\n由此，我们可以大致探清了这片迷雾，CPU的设计如何从高抽象层次的逻辑，梳理成最底层的逻辑门，再实现为小小的芯片。那么我们有了轮子，要造一个CPU，还要确定目标指令集。由于本项目由龙芯公司赞助，那必然要选MIPS了。\n📌MIPS指令集格式 啥叫指令集呢，学过几种语言就不难理解。高级程序语言规定每个ascii码的组合所对应的含义，指令集规定0和1的组合所对应的寄存器，ALU的各种信号。MIPS指令集从属于RISC系列，最基本的指令有31条。\n//讲到这里本应该打个表展示31条指令，但是👴懒得打了。\nVivado中，.coe文件用于初始化IP核，本实验给出的.coe文件中存放了几条指令，不过是16进制数字，写个小脚本打印成可读的形式。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 # mips_dump.py with open(path,\u0026#39;r\u0026#39;) as f: hex_list = f.read().split(\u0026#39;\\n\u0026#39;) bin_list = list(map(lambda x:bin(int(x,16)),hex_list)) # bin_code_list = [\u0026#34;{:0\u0026gt;32}\u0026#34;.format(i[2:],\u0026#39;b\u0026#39;) for i in bin_list] bin_code_list = [i[2:].zfill(32) for i in bin_list] IType_op_dict = { \u0026#39;001000\u0026#39;:\u0026#39;addi\u0026#39;, \u0026#39;001001\u0026#39;:\u0026#39;addiu\u0026#39;, \u0026#39;001100\u0026#39;:\u0026#39;ori\u0026#39;, \u0026#39;001101\u0026#39;:\u0026#39;xori\u0026#39;, \u0026#39;001111\u0026#39;:\u0026#39;lui\u0026#39;, \u0026#39;100011\u0026#39;:\u0026#39;lw\u0026#39;, \u0026#39;101011\u0026#39;:\u0026#39;sw\u0026#39;, \u0026#39;000100\u0026#39;:\u0026#39;beq\u0026#39;, \u0026#39;000101\u0026#39;:\u0026#39;bne\u0026#39;, \u0026#39;001010\u0026#39;:\u0026#39;slti\u0026#39;, \u0026#39;001011\u0026#39;:\u0026#39;sltiu\u0026#39; } RType_func_dict = { \u0026#39;100000\u0026#39;:\u0026#39;add\u0026#39;, \u0026#39;100001\u0026#39;:\u0026#39;addu\u0026#39;, \u0026#39;100010\u0026#39;:\u0026#39;sub\u0026#39;, \u0026#39;100011\u0026#39;:\u0026#39;subu\u0026#39;, \u0026#39;100100\u0026#39;:\u0026#39;and\u0026#39;, \u0026#39;100101\u0026#39;:\u0026#39;or\u0026#39;, \u0026#39;100110\u0026#39;:\u0026#39;xor\u0026#39;, \u0026#39;100111\u0026#39;:\u0026#39;nor\u0026#39;, \u0026#39;101010\u0026#39;:\u0026#39;slt\u0026#39;, \u0026#39;101011\u0026#39;:\u0026#39;sltu\u0026#39;, \u0026#39;000000\u0026#39;:\u0026#39;sll\u0026#39;, \u0026#39;000010\u0026#39;:\u0026#39;srl\u0026#39;, \u0026#39;000011\u0026#39;:\u0026#39;sra\u0026#39;, \u0026#39;000100\u0026#39;:\u0026#39;sllv\u0026#39;, \u0026#39;000110\u0026#39;:\u0026#39;srlv\u0026#39;, \u0026#39;000111\u0026#39;:\u0026#39;srav\u0026#39;, \u0026#39;001000\u0026#39;:\u0026#39;jr\u0026#39;, } def f_hex(ori, width): # bin-\u0026gt;hex return \u0026#34;0x\u0026#34;+hex(int(ori,2))[2:].zfill(width) def f_reg(ori): # print register num return \u0026#34;$\u0026#34;+str(int(ori,2)).zfill(2) def code_dump(type:str,inst:str,params:list): if type == \u0026#39;R\u0026#39;: s = inst.ljust(6) + \u0026#34;, \u0026#34;.join([f_reg(params[0]),f_reg(params[1]),f_reg(params[2]),f_hex(params[3],2)]) elif type == \u0026#39;I\u0026#39;: s = inst.ljust(6) + \u0026#34;, \u0026#34;.join([f_reg(params[0]),f_reg(params[1]),f_hex(params[2],8)]) else: s = inst.ljust(6) +\u0026#39;0x\u0026#39;+ hex(int(params[0],2))[2:].zfill(8) return s assembly_list = [] for _ in bin_code_list: op = _[:6] # public field try: if op == \u0026#39;000000\u0026#39;: # R-Type rs = _[6:11] rt = _[11:16] rd = _[16:21] shamt = _[21:26] func = _[26:] assembly_list.append(code_dump(\u0026#39;R\u0026#39;,RType_func_dict[func],[rs,rt,rd,shamt])) elif op in [\u0026#39;000010\u0026#39;, \u0026#39;000011\u0026#39;]: # J-Type target = _[6:] assembly_list.append(code_dump(\u0026#39;J\u0026#39;,\u0026#39;j\u0026#39;,[target])) else: # I-Type rs = _[6:12] rt = _[12:18] imm = _[18:] assembly_list.append(code_dump(\u0026#39;I\u0026#39;,IType_op_dict[op],[rs, rt, imm])) except Exception as e: assembly_list.append(\u0026#34;***** decode error! *****\u0026#34;) head = \u0026#34;+---hexdump----|--------- assembly ---------+\u0026#34; print(head) addr = 0 for i in range(len(bin_code_list)): print(\u0026#34;|\u0026#34;+ f_hex(bin(addr),2) +\u0026#34; \u0026#34;+ hex_list[i] +\u0026#34; | \u0026#34;+ assembly_list[i].ljust(26) + \u0026#34; |\u0026#34;) addr += 4 tail = \u0026#34;+\u0026#34;+\u0026#34;-\u0026#34;*43+\u0026#34;+\u0026#34; print(tail) 打印出来👴傻了，怎么还有不在31条范围里的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 +---hexdump----|--------- assembly ---------+ |0x00 24010001 | addiu $00, $04, 0x00000001 | |0x04 00011100 | sll $00, $01, $02, 0x04 | |0x08 00411821 | addu $02, $01, $03, 0x00 | |0x0c 00022082 | srl $00, $02, $04, 0x02 | |0x10 28990005 | slti $09, $36, 0x00000005 | |0x14 07210010 | ***** decode error! ***** | |0x18 00642823 | subu $03, $04, $05, 0x00 | |0x1c AC050014 | sw $00, $20, 0x00000014 | |0x20 00A23027 | nor $05, $02, $06, 0x00 | |0x24 00C33825 | or $06, $03, $07, 0x00 | |0x28 00E64026 | xor $07, $06, $08, 0x00 | |0x2c AC08001C | sw $00, $32, 0x0000001c | |0x30 11030002 | beq $16, $12, 0x00000002 | |0x34 00C7482A | slt $06, $07, $09, 0x00 | |0x38 24010008 | addiu $00, $04, 0x00000008 | |0x3c 8C2A0014 | lw $02, $40, 0x00000014 | |0x40 15450004 | bne $20, $20, 0x00000004 | |0x44 00415824 | and $02, $01, $11, 0x00 | |0x48 AC2B001C | sw $02, $44, 0x0000001c | |0x4c AC240010 | sw $02, $16, 0x00000010 | |0x50 0C000019 | j 0x00000019 | |0x54 3C0C000C | lui $00, $48, 0x0000000c | |0x58 004CD007 | srav $02, $12, $26, 0x00 | |0x5c 003AD804 | sllv $01, $26, $27, 0x00 | |0x60 0360F809 | ***** decode error! ***** | |0x64 A07A0005 | ***** decode error! ***** | |0x68 0063682B | sltu $03, $03, $13, 0x00 | |0x6c 1DA00003 | ***** decode error! ***** | |0x70 00867004 | sllv $04, $06, $14, 0x00 | |0x74 000E7883 | sra $00, $14, $15, 0x02 | |0x78 002F8006 | srlv $01, $15, $16, 0x00 | |0x7c 1A000008 | ***** decode error! ***** | |0x80 002F8007 | srav $01, $15, $16, 0x00 | |0x84 240B008C | addiu $00, $44, 0x0000008c | |0x88 06000006 | ***** decode error! ***** | |0x8c 8D5C0003 | lw $21, $48, 0x00000003 | |0x90 179D0007 | bne $57, $52, 0x00000007 | |0x94 A0AF0008 | ***** decode error! ***** | |0x98 80B20008 | ***** decode error! ***** | |0x9c 90B30008 | ***** decode error! ***** | |0xa0 2DF8FFFF | sltiu $31, $35, 0x00003fff | |0xa4 0185E825 | or $12, $05, $29, 0x00 | |0xa8 01600008 | jr $11, $00, $00, 0x00 | |0xac 31F4FFFF | ori $31, $19, 0x00003fff | |0xb0 35F5FFFF | xori $31, $23, 0x00003fff | |0xb4 39F6FFFF | ***** decode error! ***** | |0xb8 08000000 | j 0x00000000 | +-------------------------------------------+ 总之，代码都给你了，下面给出一个vivado实验的完整流程，不全面，但是都是踩坑经验。\n🆒Vivado使用 本流程环境：Vivado 2020.2\n开发板型号：LS-CPU-EXB-1\n创建项目 下一步，下一步，下一步，，，确认。 这一步只需要注意选器件，一定要选对。否则有可能在Implementation遇到“端口电平不匹配”“端口数量不足”等硬件问题。当然，有可能型号相近的性能规格也差不多，这属于玄学问题了。实验书上选择的的型号应该是“xc7a200tfbg676-2”，但是👴用的是“xc7a200tfbv676-2”也能成功写入比特流。\n编写代码并仿真 本实验的代码大多来自“2016-04-14”，那就是龙芯公司给的源代码。在该系列代码中有一处bug，位于“单周期CPU实验”的single_cycle_cpu.v中。214行，resetn应该为{4{resetn}}，写使能位宽应为为4。 下面讲解一下项目结构，所有实验都是类似的： 三个顶层文件夹分别对应Add Source里的三类源文件：添加设计，添加仿真，添加约束。如果不需要上板，只完成仿真，那么只需要添加设计（几个.v），添加仿真（testbench.v/tb.v）就足够了，xxx_display.v也是上板需要的故而可以忽略。（实际上，图中我用箭头标记的都用不到）。\n编写tb，无非是给tb里声明为input的信号赋值，还可以使用#xx，让tb等待一段时间。\n点击Run Simulation，等一会就能看到波形图。波形图有三种颜色：\n绿色代表信号正常正常； 红色的X代表信号不确定； 蓝色的Z代表信号休眠。 一般遇到红X，都是未初始化问题。蓝Z大概是没有模块调用这些信号。Vivado波形图的操作极其难用，这里介绍一个相对好用的操作：左键从左向右水平划，会直接缩放到鼠标滑过的这一段。右键选择进制等操作略。\n仿真需要注意的问题：\n如果文件没问题，模块调用层次会被自动解析从而呈现成一棵树，而不是好几个顶层文件。 注意set as top，应该设为根部模块（调用其他模块的）和tb //如果设错了可能在Implementation会出现“端口未赋初值”的报错。 中文乱码是经典字符集问题，有可能在换行处导致语法错误。建议统一换成utf-8。 简单解决方法：从vscode里复制。 引入IP核 对于流水线CPU，data_ram和inst_rom需要同步写，自己实现比较复杂，故直接实例化封装好的内存块IP。如何引入？首先说明几种文件格式：\n.dcp 原意为checkpoints文件，是一种加密压缩文件。用于封装模块方便调用，但对版本要求极其敏感。 .xci/.xcix IP核配置文件，本质是一个xml。是Vivado在新版本提倡使用xci而不是dcp。 .xdc 管脚约束文件。在Implementation用到，此处按下不表。 这几种文件格式都是可以直接Add Source添加进来的。实验老师同时提供dcp和xci文件，添加dcp崩屎了，原因估计如上。添加xci之后，提示我将IP更新为core cointainer的形式\n更新就完了。然后需要等一会，IP还要执行一步synth，这段时间里IP属于锁住的状态，不能修改配置。\n注意更换器件后，IP核都会锁住。这表示IP的配置和当前环境不匹配。对所有IP锁住的问题，只需要点击菜单栏Reports→Reports IP Status，然后点upgrade即可解除锁定。\n我直接上板 直接点生成比特流，会一步步的按工作流向下运行，等待几分钟就能愉快的收获你的报错了！\n在把上文提到的坑都踩过一遍之后，终于没有critical warning，泪目。\n但是此时实验课已经结束了，👴偷溜到没人的实验室，并留下以下珍贵画面\n然后👴发现data_ram写入失败。但是👴没时间搞了，👴还是滚去复习课本吧。\n🗿多周期流水线CPU原理 最后，继续复习计组。\n","date":"2021-06-09T17:14:19Z","image":"https://lonelyuan.github.io/p/%E5%9F%BA%E4%BA%8Evivado%E7%9A%84%E5%9F%BA%E4%BA%8Efpga%E7%9A%84%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8Emips%E7%9A%84%E4%B8%80%E7%A7%8D%E4%BA%94%E7%BA%A7%E6%B5%81%E6%B0%B4%E7%BA%BFcpu%E5%AE%9E%E7%8E%B0%E7%9A%84%E6%B3%A8%E9%87%8A/mips_pipeline_cpu_hu41671eab994e10b990ecc8a898c73896_308650_120x120_fill_q75_box_smart1.jfif","permalink":"https://lonelyuan.github.io/p/%E5%9F%BA%E4%BA%8Evivado%E7%9A%84%E5%9F%BA%E4%BA%8Efpga%E7%9A%84%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8Emips%E7%9A%84%E4%B8%80%E7%A7%8D%E4%BA%94%E7%BA%A7%E6%B5%81%E6%B0%B4%E7%BA%BFcpu%E5%AE%9E%E7%8E%B0%E7%9A%84%E6%B3%A8%E9%87%8A/","title":"基于vivado的基于FPGA的一种基于MIPS的一种五级流水线CPU实现的注释"},{"content":"// 笑死，根本赢不了。受不鸟，直接投降~\n0x01 | 拖延症的生理基础\n0x02 | 对拖延症的方法论综述\n0x03 | 西西弗斯计划\n","date":"2021-04-15T23:01:29Z","image":"https://lonelyuan.github.io/p/%E6%88%91%E5%92%8C%E6%8B%96%E5%BB%B6%E7%97%87%E7%9A%84%E6%88%98%E4%BA%89/ProcrastinationWar_hu0b75bf0afc945e74174c5a743bf06a5b_26480_120x120_fill_q75_box_smart1.jfif","permalink":"https://lonelyuan.github.io/p/%E6%88%91%E5%92%8C%E6%8B%96%E5%BB%B6%E7%97%87%E7%9A%84%E6%88%98%E4%BA%89/","title":"我和拖延症的战争"},{"content":"CSAPP：Bomblab 逆向的传统艺能拆炸弹，👴的青春回来了。\n文件结构：\n1 2 3 4 bomb ├── README ├── bomb └── bomb.c 只有一个程序，给的源码基本没用，我们要用逆向工程的方法理解程序，找到正确的字符串。\n讲反汇编器的结果导出：objdump -d bomb \u0026gt; bomb.txt\n可以看到有6关，每一关接受一个字符串，若跳转到explode_bomb函数，则答案错误。\n第一关：字符串比较 1 2 3 4 0000000000400ee0 \u0026lt;phase_1\u0026gt;: 400ee0:\t48 83 ec 08 sub $0x8,%rsp 400ee4:\tbe 00 24 40 00 mov $0x402400,%esi 400ee9:\te8 4a 04 00 00 callq 401338 \u0026lt;strings_not_equal\u0026gt; 逻辑是直接比较字符串是否相等，不过$0x402400不是程序内地址，说明答案被藏在了我们看不到的内存位置。\n于是上GDB，在\u0026lt;phase_1\u0026gt;下断点，stepi单步执行到callq之前，查看寄存器:x\\s $esi，得到答案。（每台电脑的答案都不一样）\n第二关：循环 1 2 3 4 5 6 0000000000400efc \u0026lt;phase_2\u0026gt;: 400efc:\t55 push %rbp //压栈 400efd:\t53 push %rbx 400efe:\t48 83 ec 28 sub $0x28,%rsp //开辟栈帧 400f02:\t48 89 e6 mov %rsp,%rsi//栈顶地址→rsi参数二 400f05:\te8 52 05 00 00 callq 40145c \u0026lt;read_six_numbers\u0026gt; 如函数名所示，读6个数字，为什么是6呢，大概是因为存放参数的寄存器总共有6个吧。（然而并不）\n可以看到调用前开辟了0x28的栈上空间，足够存放6个整数。栈顶地址被存入%rsi，以此传递该地址。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 000000000040145c \u0026lt;read_six_numbers\u0026gt;: //%rsi:父进程\u0026lt;phase_2\u0026gt;的栈顶地址 40145c:\t48 83 ec 18 sub $0x18,%rsp //栈帧长24 401460:\t48 89 f2 mov %rsi,%rdx //rsi→参数三：num1 401463:\t48 8d 4e 04 lea 0x4(%rsi),%rcx //rsi+4→参数四：num2 401467:\t48 8d 46 14 lea 0x14(%rsi),%rax //rsi+20→rax 40146b:\t48 89 44 24 08 mov %rax,0x8(%rsp) //rax→栈顶+8：num6 401470:\t48 8d 46 10 lea 0x10(%rsi),%rax //rsi+16→rax 401474:\t48 89 04 24 mov %rax,(%rsp) //rax→栈顶：num5 401478:\t4c 8d 4e 0c lea 0xc(%rsi),%r9 //rsi+12→参数六：num4 40147c:\t4c 8d 46 08 lea 0x8(%rsi),%r8 //rsi+8→参数五：num3 401480:\tbe c3 25 40 00 mov $0x4025c3,%esi//0x4025c3:\u0026#34;%d %d %d %d %d %d\u0026#34; 401485:\tb8 00 00 00 00 mov $0x0,%eax //返回值赋0 40148a:\te8 61 f7 ff ff callq 400bf0 \u0026lt;__isoc99_sscanf@plt\u0026gt; //sscanf() 40148f:\t83 f8 05 cmp $0x5,%eax //返回值和5比较，即输入6个值才能通过 401492:\t7f 05 jg 401499 \u0026lt;read_six_numbers+0x3d\u0026gt; 401494:\te8 a1 ff ff ff callq 40143a \u0026lt;explode_bomb\u0026gt; 401499:\t48 83 c4 18 add $0x18,%rsp //出栈 40149d:\tc3 retq 看\u0026lt;read_six_numbers\u0026gt;，%rsi中的地址以4为步长被分别储存。猜测sscanf函数的返回值中，第一个表示输入参数的个数；程序要求6个输入，加上rsi被占用，于是多的两个存入栈中。且sscanf函数的返回值按参数寄存器（多的地址在栈上）存放的地址传输，即输入值被按顺序存入phase_2的栈帧中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 400f0a:\t83 3c 24 01 cmpl $0x1,(%rsp) //栈顶位置取双字和1比较 400f0e:\t74 20 je 400f30 \u0026lt;phase_2+0x34\u0026gt; 400f10:\te8 25 05 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 400f17:\t8b 43 fc mov -0x4(%rbx),%eax //循环头：num1→eax 400f1a:\t01 c0 add %eax,%eax // eax*2 400f1c:\t39 03 cmp %eax,(%rbx) //和num2比较 400f1e:\t74 05 je 400f25 \u0026lt;phase_2+0x29\u0026gt; //相等才通过 400f20:\te8 15 05 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 400f25:\t48 83 c3 04 add $0x4,%rbx //rbx增4 400f29:\t48 39 eb cmp %rbp,%rbx //rbx和rsp+24比较，相等则跳出 400f2c:\t75 e9 jne 400f17 \u0026lt;phase_2+0x1b\u0026gt; //循环尾，循环共6轮 400f2e:\teb 0c jmp 400f3c \u0026lt;phase_2+0x40\u0026gt; 400f30:\t48 8d 5c 24 04 lea 0x4(%rsp),%rbx //num2地址→rbx 400f35:\t48 8d 6c 24 18 lea 0x18(%rsp),%rbp//rbx地址→rbp 400f3a:\teb db jmp 400f17 \u0026lt;phase_2+0x1b\u0026gt; //开始循环 跳出\u0026lt;read_six_numbers\u0026gt;后，首先检查栈顶地址指向的值是否为1，即第一个数字是1。\n之后进入循环，循环体每次都会把当前数字*2和下一个数字比较，即每个数字都是前一个的二倍；%rbx作计数变量，共循环6次。答案呼之欲出。\n第三关：分支 1 2 3 4 5 6 7 8 9 10 11 12 13 14 0000000000400f43 \u0026lt;phase_3\u0026gt;: 400f43:\t48 83 ec 18 sub $0x18,%rsp 400f47:\t48 8d 4c 24 0c lea 0xc(%rsp),%rcx //rsp+12→rcx: mun2 400f4c:\t48 8d 54 24 08 lea 0x8(%rsp),%rdx //rsp+8→rdx: mun1 400f51:\tbe cf 25 40 00 mov $0x4025cf,%esi //0x4025cf: \u0026#34;%d %d\u0026#34; 400f56:\tb8 00 00 00 00 mov $0x0,%eax 400f5b:\te8 90 fc ff ff callq 400bf0 \u0026lt;__isoc99_sscanf@plt\u0026gt; 400f60:\t83 f8 01 cmp $0x1,%eax //不少于一个输入 400f63:\t7f 05 jg 400f6a \u0026lt;phase_3+0x27\u0026gt; 400f65:\te8 d0 04 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 400f6a:\t83 7c 24 08 07 cmpl $0x7,0x8(%rsp) // 400f6f:\t77 3c ja 400fad \u0026lt;phase_3+0x6a\u0026gt; //超过7则爆炸 400f71:\t8b 44 24 08 mov 0x8(%rsp),%eax //取num1 400f75:\tff 24 c5 70 24 40 00 jmpq *0x402470(,%rax,8) 此处*相当于c中的取地址符\u0026amp;，\n1 2 3 400f7c:\tb8 cf 00 00 00 mov $0xcf,%eax 400f81:\teb 3b jmp 400fbe \u0026lt;phase_3+0x7b\u0026gt; ······ 这里有7段形式重复的代码，结合第一个数字不能大于7，猜测这里是switch型结构。\n1 2 3 4 5 6 7 8 9 400fad:\te8 88 04 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 400fb2:\tb8 00 00 00 00 mov $0x0,%eax 400fb7:\teb 05 jmp 400fbe \u0026lt;phase_3+0x7b\u0026gt; 400fb9:\tb8 37 01 00 00 mov $0x137,%eax 400fbe:\t3b 44 24 0c cmp 0xc(%rsp),%eax //比较num2和eax 400fc2:\t74 05 je 400fc9 \u0026lt;phase_3+0x86\u0026gt; 400fc4:\te8 71 04 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 400fc9:\t48 83 c4 18 add $0x18,%rsp 400fcd:\tc3 retq 第二个数字是%eax的值，由第一个数决定。故答案有7个。\n第四关：递归 1 2 3 4 5 6 7 8 9 10 11 000000000040100c \u0026lt;phase_4\u0026gt;: ...... 401029:\t83 f8 02 cmp $0x2,%eax //只能有2参数 40102c:\t75 07 jne 401035 \u0026lt;phase_4+0x29\u0026gt; 40102e:\t83 7c 24 08 0e cmpl $0xe,0x8(%rsp) //0 \u0026lt;= num1 \u0026lt;= 14 401033:\t76 05 jbe 40103a \u0026lt;phase_4+0x2e\u0026gt; 401035:\te8 00 04 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 40103a:\tba 0e 00 00 00 mov $0xe,%edx 40103f:\tbe 00 00 00 00 mov $0x0,%esi 401044:\t8b 7c 24 08 mov 0x8(%rsp),%edi //num1→edi 401048:\te8 81 ff ff ff callq 400fce \u0026lt;func4\u0026gt; // 输入规则和上一关一样，第一个数需在0到14之间（cmpl只能用于无符号数？）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 0000000000400fce \u0026lt;func4\u0026gt;: //首次调用时：%eax:0x2 %ebx:0 %ecx:0 %edx:0xe %esi:0x0 %edi:num1 400fce:\t48 83 ec 08 sub $0x8,%rsp 400fd2:\t89 d0 mov %edx,%eax //eax:14 400fd4:\t29 f0 sub %esi,%eax //eax:14-0 400fd6:\t89 c1 mov %eax,%ecx //ecx:14 400fd8:\tc1 e9 1f shr $0x1f,%ecx //ecx:0 //逻辑右移31，即取符号位。 400fdb:\t01 c8 add %ecx,%eax //eax:14+0 400fdd:\td1 f8 sar %eax //算术右移1位？eax:14/2=7 400fdf:\t8d 0c 30 lea (%rax,%rsi,1),%ecx //ecx:7+0 400fe2:\t39 f9 cmp %edi,%ecx //比较num1和7 400fe4:\t7e 0c jle 400ff2 \u0026lt;func4+0x24\u0026gt; //不大于→r17 400fe6:\t8d 51 ff lea -0x1(%rcx),%edx //edx:ecx-1=6 400fe9:\te8 e0 ff ff ff callq 400fce \u0026lt;func4\u0026gt; //递归→r3 400fee:\t01 c0 add %eax,%eax 400ff0:\teb 15 jmp 401007 \u0026lt;func4+0x39\u0026gt; //跳出 400ff2:\tb8 00 00 00 00 mov $0x0,%eax 400ff7:\t39 f9 cmp %edi,%ecx //比较num1和7 400ff9:\t7d 0c jge 401007 \u0026lt;func4+0x39\u0026gt; //不小于 400ffb:\t8d 71 01 lea 0x1(%rcx),%esi //esi:ecx+1=8 400ffe:\te8 cb ff ff ff callq 400fce \u0026lt;func4\u0026gt; //递归→r3 401003:\t8d 44 00 01 lea 0x1(%rax,%rax,1),%eax //eax=2*eax+1 401007:\t48 83 c4 08 add $0x8,%rsp 40100b:\tc3 retq 前面一通算术操作，后面设计了递归。\n这里一步移位操作看起来像是取符号位，但是输入一定大于0，符号位是0，所以这个操作意义何在？\n人肉IDA走起：\n1 2 3 4 5 6 7 8 9 int fun4(int num1,int x,int y){ int s,a; s=(x-y)/2+y; if(num1\u0026gt;s)\treturn 2*fun4(num1,s-1,y); a=0; if(num1\u0026lt;s)\treturn 2*fun4(num1,x,s+1)+1; return a; } fun4(num1,14,0); 第一个数设为7可避免递归调用，但返回值不是0，不符合。\n1 2 3 4 5 6 7 40104d:\t85 c0 test %eax,%eax //eax=0 40104f:\t75 07 jne 401058 \u0026lt;phase_4+0x4c\u0026gt;//不等于0爆炸 401051:\t83 7c 24 0c 00 cmpl $0x0,0xc(%rsp) //mun2和0比较？ 401056:\t74 05 je 40105d \u0026lt;phase_4+0x51\u0026gt;//不等于0爆炸 401058:\te8 dd 03 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 40105d:\t48 83 c4 18 add $0x18,%rsp 401061:\tc3 retq 看到的返回值和num2皆需为0，则num2确定。\n大不了爆破呗，索性试了1次就成了。emm\n【后面三关施工中。。。】\n第五关 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 0000000000401062 \u0026lt;phase_5\u0026gt;: 401062:\t53 push %rbx 401063:\t48 83 ec 20 sub $0x20,%rsp 401067:\t48 89 fb mov %rdi,%rbx 40106a:\t64 48 8b 04 25 28 00 mov %fs:0x28,%rax //??? 401073:\t48 89 44 24 18 mov %rax,0x18(%rsp) 401078:\t31 c0 xor %eax,%eax //eax:0 40107a:\te8 9c 02 00 00 callq 40131b \u0026lt;string_length\u0026gt; 40107f:\t83 f8 06 cmp $0x6,%eax //输入长度为6 401082:\t74 4e je 4010d2 \u0026lt;phase_5+0x70\u0026gt; 401084:\te8 b1 03 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 401089:\teb 47 jmp 4010d2 \u0026lt;phase_5+0x70\u0026gt; 40108b:\t0f b6 0c 03 movzbl (%rbx,%rax,1),%ecx //循环头。新指令 40108f:\t88 0c 24 mov %cl,(%rsp) 401092:\t48 8b 14 24 mov (%rsp),%rdx 401096:\t83 e2 0f and $0xf,%edx 401099:\t0f b6 92 b0 24 40 00 movzbl 0x4024b0(%rdx),%edx //？？？ 4010a0:\t88 54 04 10 mov %dl,0x10(%rsp,%rax,1) 4010a4:\t48 83 c0 01 add $0x1,%rax //计数变量rax 4010a8:\t48 83 f8 06 cmp $0x6,%rax //循环6轮 4010ac:\t75 dd jne 40108b \u0026lt;phase_5+0x29\u0026gt; //循环尾 4010ae:\tc6 44 24 16 00 movb $0x0,0x16(%rsp) 4010b3:\tbe 5e 24 40 00 mov $0x40245e,%esi //？？ 4010b8:\t48 8d 7c 24 10 lea 0x10(%rsp),%rdi 4010bd:\te8 76 02 00 00 callq 401338 \u0026lt;strings_not_equal\u0026gt; 4010c2:\t85 c0 test %eax,%eax 4010c4:\t74 13 je 4010d9 \u0026lt;phase_5+0x77\u0026gt; 4010c6:\te8 6f 03 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 4010cb:\t0f 1f 44 00 00 nopl 0x0(%rax,%rax,1) //？？？ 4010d0:\teb 07 jmp 4010d9 \u0026lt;phase_5+0x77\u0026gt;//跳出 4010d2:\tb8 00 00 00 00 mov $0x0,%eax 4010d7:\teb b2 jmp 40108b \u0026lt;phase_5+0x29\u0026gt; 4010d9:\t48 8b 44 24 18 mov 0x18(%rsp),%rax 4010de:\t64 48 33 04 25 28 00 xor %fs:0x28,%rax //？？？ 4010e7:\t74 05 je 4010ee \u0026lt;phase_5+0x8c\u0026gt; 4010e9:\te8 42 fa ff ff callq 400b30 \u0026lt;__stack_chk_fail@plt\u0026gt; 4010ee:\t48 83 c4 20 add $0x20,%rsp 4010f2:\t5b pop %rbx 4010f3:\tc3 retq 第六关 隐藏关 隐藏关藏在每一关的后面，\nGDB使用： 基础：\n1 2 3 4 5 q : quit h : help file prog//加载程序，也可作为gdb命令的参数 r : run k : kill 断点：\n1 2 3 4 5 6 7 8 9 10 b : breakpoints break - func_name - *0x400522 - \u0026amp;var - main.c:100//源代码断点，运行前即可 - if con//条件断点 w : watch //观察对象变化时断点 d : delete - b n disable b n 执行：\n1 2 3 4 5 6 c : continue f : finish stepi n nexti set args ./a.txt //从文件读取输入 检查代码：\n1 2 3 4 5 6 disas //展示汇编 - funcname - 0x400000 - list edit 检查数据：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 x : examine p : print 格式控制：/[n][f][u] - n:内存单元个数 - f:显示格式： - x(hex) 按十六进制格式显示变量。 - d(decimal) 按十进制格式显示变量。 - u(unsigned decimal) 按十进制格式显示无符号整型。 - o(octal) 按八进制格式显示变量。 - t(binary) 按二进制格式显示变量。 - a(address) 按十六进制格式显示变量。 - c(char) 按字符格式显示变量。 - f(float) 按浮点数格式显示变量 - u:单元长度（按字节） i : info - r : registers - b [n] - $rsp 表达式：\n堆栈：\n1 bt : backtrace//显示堆栈 ","date":"2020-02-27T22:43:31Z","permalink":"https://lonelyuan.github.io/p/csapp-bomblab/","title":"CSAPP - Bomblab"},{"content":"第一个lab，关于位运算。通过受限制的c语言编程实现函数功能。这些函数都是非常基本的功能，正如书名《CS:APP》所示，启发我们从程序员视角理解计算机的深层更深层。\nREADME中说明了项目结构。直接读bits.c，只需要填充其中的函数。每次测试程序都要先make一下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 //1 /* * bitXor - x^y using only ~ and \u0026amp; * Example: bitXor(4, 5) = 1 * Legal ops: ~ \u0026amp; * Max ops: 14 * Rating: 1 */ int bitXor(int x, int y) { // x^y // = (~x\u0026amp;y)|(x\u0026amp;~y) // 异或公式 // = ~(~(~x\u0026amp;y)\u0026amp;~(x\u0026amp;~y)) // 德摩根律，ops: 8 // = ~((x|~y)\u0026amp;(~x|y)) // 德摩根律 // = ~(x\u0026amp;~x|x\u0026amp;y|y\u0026amp;~y|~x\u0026amp;~y) // 分配律 // = ~(x\u0026amp;y|~x\u0026amp;~y) // 吸收率 return ~(x\u0026amp;y)\u0026amp;~(~x\u0026amp;~y); // 德摩根律，ops: 7 } /* * tmin - return minimum two\u0026#39;s complement integer * Legal ops: ! ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 4 * Rating: 1 */ int tmin(void) { // For negative numbers: complement = inverse + 1 return 1 \u0026lt;\u0026lt; 31; // tmin=0x80, tmax=0x7f // 为什么是补码？ // 为了方便计算机处理，我们希望负数和其相反数相加之后自然的溢出得0。 // x+~x=1, 再加1则溢出得0。因此补码=反码+1。 // 同时符号位天然的蕴含在最高位上，这有许多好处。 // 其一是正数的表现和无符号整数一致。 // 其二是由于＋0和-0一致，相比显式符号位能多表示一个数字，范围是[-2^(n-1),2^(n-1)-1] } //2 /* * isTmax - returns 1 if x is the maximum, two\u0026#39;s complement number, * and 0 otherwise * Legal ops: ! ~ \u0026amp; ^ | + * Max ops: 10 * Rating: 1 */ int isTmax(int x) { // ! 逻辑取反，仅全0返回1，其余情况都返回0 // ~ 按位取反 // 补码相反数 = 反码 + 1 // 两个特例：~tmin+1=tmin; ~0+1=0. 相反数为自身 // 得到几个函数： // negate(x) (~x+1) // 取相反数 // iszero(x) (!!x) // 仅当!!0=0 // equal(x,y) !(x^y) // 判断相等 // ~tmax=tmin, 转换为筛选tmin和0xff // 因此答案为 equal(~x,negate(~x)) \u0026amp; iszero(~x) return !((x+1)^(~x)) \u0026amp; (!!~x); // ops: 8 } /* * allOddBits - return 1 if all odd-numbered bits in word set to 1 * where bits are numbered from 0 (least significant) to 31 (most significant) * Examples allOddBits(0xFFFFFFFD) = 0, allOddBits(0xAAAAAAAA) = 1 * Legal ops: ! ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 12 * Rating: 2 */ int allOddBits(int x) { // 掩码: x \u0026amp; 0b1111, 结果相当于只取了x的后4位 // 奇数位全为1，使用掩码0xAAAAAAAA提取奇数位，再使用equal(x,0xAAAAAAAA)判断即可 int mask = 0xAA; mask += mask \u0026lt;\u0026lt; 8; mask += mask \u0026lt;\u0026lt; 16; return !(x\u0026amp;mask ^ mask); // ops: 7 } /* * negate - return -x * Example: negate(1) = -1. * Legal ops: ! ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 5 * Rating: 2 */ int negate(int x) { return ~x+1; } //3 /* * isAsciiDigit - return 1 if 0x30 \u0026lt;= x \u0026lt;= 0x39 (ASCII codes for characters \u0026#39;0\u0026#39; to \u0026#39;9\u0026#39;) * Example: isAsciiDigit(0x35) = 1. * isAsciiDigit(0x3a) = 0. * isAsciiDigit(0x05) = 0. * Legal ops: ! ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 15 * Rating: 3 */ int isAsciiDigit(int x) { // x \u0026gt; y // =\u0026gt; x+(~y+1) \u0026gt; 0 // x+(-y)\u0026gt;0 // =\u0026gt; !(x+(~y+1) \u0026gt;\u0026gt; 31) // 使用符号位判断\u0026gt;0 // 得到比较函数： // gpos(x, y) !(x+(~y+1) \u0026gt;\u0026gt; 31) // 带入即可 !((0x39 + ~x+1)\u0026gt;\u0026gt;31) \u0026amp; !((x + ~0x30+1)\u0026gt;\u0026gt;31) // ops: 11 return !((~x+0x3A)\u0026gt;\u0026gt;31) \u0026amp; !((x + ~0x30+1)\u0026gt;\u0026gt;31); // ops: 10 } /* * conditional - same as x ? y : z * Example: conditional(2,4,5) = 4 * Legal ops: ! ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 16 * Rating: 3 */ int conditional(int x, int y, int z) { // 或运算两侧不同时为1即可构成条件判断，使用掩码控制输出内容 // 错误做法： // int mask = x \u0026gt;\u0026gt; 31; // 算数右移取符号位填充全部位 // x ? y : z 对x是逻辑判断不是算术判断 int mask= ~!x+1; // 仅0返回1 return (~mask\u0026amp;y)|(mask\u0026amp;z) ; // ops: 7 } /* * isLessOrEqual - if x \u0026lt;= y then return 1, else return 0 * Example: isLessOrEqual(4,5) = 1. * Legal ops: ! ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 24 * Rating: 3 */ int isLessOrEqual(int x, int y) { // gpos(x, y) 在跨符号的情况下失灵，增加两种情况判断: // 1. x=y：返回1 // 2. x和y不同符号：x为负时一定小于，返回1，x符号位也是1 // 因此答案为 equal(signx,signy) ? (gpos(y,x) | equal(x,y)) : signx int signx=!!(x\u0026gt;\u0026gt;31), signy=!!(y\u0026gt;\u0026gt;31); int mask = (signx^signy); return (!mask \u0026amp; (!(y+(~x+1)\u0026gt;\u0026gt;31)) | !((x)^(y))) | (mask\u0026amp;signx); // ops: 19 } //4 /* * logicalNeg - implement the ! operator, using all of * the legal operators except ! * Examples: logicalNeg(3) = 0, logicalNeg(0) = 1 * Legal ops: ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 12 * Rating: 4 */ int logicalNeg(int x) { // 仅0返回1，其余返回0 // 还是借助两个特例：~tmin+1=tmin; ~0+1=0. 相反数为自身 // 答案为 equal(x,~x+1) \u0026amp; !equal(x,tmin) // !(x^0) \u0026amp; !!(x^(1\u0026lt;\u0026lt;31)) return !((x^0) | !(x^(1\u0026lt;\u0026lt;31))); // ops: 6 } /* howManyBits - return the minimum number of bits required to represent x in * two\u0026#39;s complement * Examples: howManyBits(12) = 5 // [-16,15] * howManyBits(298) = 10 // [-512,511] * howManyBits(-5) = 4 // [-8,7] * howManyBits(0) = 1 * howManyBits(-1) = 1 // [-1,0] * howManyBits(0x80000000) = 32 * Legal ops: ! ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 90 * Rating: 4 */ int howManyBits(int x) { // 负数取反，统一处理 // x\u0026gt;\u0026gt;31 ? ~x:x = x\u0026gt;\u0026gt;31 \u0026amp; ~x | ~(x\u0026gt;\u0026gt;31) \u0026amp; x x = x\u0026gt;\u0026gt;31^x; // 位宽取决于最高位，问题转化为寻找最高位 // 90个操作符不足以遍历32个位，因此需要优化搜索算法，如二分。 // !!(x\u0026gt;\u0026gt;16) 判断x的高16位是否存在1 int b16 = !!(x\u0026gt;\u0026gt;16) \u0026lt;\u0026lt; 4; // 若存在，至少需要16位，因此b16赋值为16或0 x = x \u0026gt;\u0026gt; b16; // 通过移位实现二分搜索： // 若高位存在则舍弃低位，高位全0则判断低位 int b8 = !!(x\u0026gt;\u0026gt;8) \u0026lt;\u0026lt; 3; x = x \u0026gt;\u0026gt; b8; int b4 = !!(x\u0026gt;\u0026gt;4) \u0026lt;\u0026lt; 2; x = x \u0026gt;\u0026gt; b4; int b2 = !!(x\u0026gt;\u0026gt;2) \u0026lt;\u0026lt; 1; x = x \u0026gt;\u0026gt; b2; int b1 = !!(x\u0026gt;\u0026gt;1); x = x \u0026gt;\u0026gt; b1; return b16+b8+b4+b2+b1+x+1; } //float /* * floatScale2 - Return bit-level equivalent of expression 2*f for * floating point argument f. * Both the argument and result are passed as unsigned int\u0026#39;s, but * they are to be interpreted as the bit-level representation of * single-precision floating point values. * When argument is NaN, return argument * Legal ops: Any integer/unsigned operations incl. ||, \u0026amp;\u0026amp;. also if, while * Max ops: 30 * Rating: 4 */ unsigned floatScale2(unsigned uf) { unsigned s = uf \u0026amp; (1 \u0026lt;\u0026lt; 31); unsigned exp = (uf \u0026amp; 0x7f800000) \u0026gt;\u0026gt; 23; unsigned frac = uf \u0026amp; (~0xff800000); if (exp == 0) return frac \u0026lt;\u0026lt; 1 | s; // 非规格数乘2即可 if (exp == 255) return uf; // 特殊值直接返回 exp++; if (exp == 255) return 0x7f800000 | s; // 乘法不可能得到NaN，所以返回无穷 return s | (exp \u0026lt;\u0026lt; 23) | frac; } /* * floatFloat2Int - Return bit-level equivalent of expression (int) f * for floating point argument f. * Argument is passed as unsigned int, but * it is to be interpreted as the bit-level representation of a * single-precision floating point value. * Anything out of range (including NaN and infinity) should return * 0x80000000u. * Legal ops: Any integer/unsigned operations incl. ||, \u0026amp;\u0026amp;. also if, while * Max ops: 30 * Rating: 4 */ int floatFloat2Int(unsigned uf) { unsigned s = uf \u0026amp; (1 \u0026lt;\u0026lt; 31); unsigned exp = (uf \u0026amp; 0x7f800000) \u0026gt;\u0026gt; 23; unsigned frac = uf \u0026amp; (~0xff800000); int E = exp - 127; if (exp == 255 || E \u0026gt; 31) return 0x80000000; // 特殊值 if (E \u0026lt; 0) return 0; // 小数舍入为0 unsigned M = frac | (1 \u0026lt;\u0026lt; 23); // 1 + frac int V = (E \u0026gt; 23 ? M \u0026lt;\u0026lt; (E - 23) : M \u0026gt;\u0026gt; (23 - E)); // M已经被左移了23位 if (s) V *= -1; // 负数 return V; } /* * floatPower2 - Return bit-level equivalent of the expression 2.0^x * (2.0 raised to the power x) for any 32-bit integer x. * * The unsigned value that is returned should have the identical bit * representation as the single-precision floating-point number 2.0^x. * If the result is too small to be represented as a denorm, return * 0. If too large, return +INF. * * Legal ops: Any integer/unsigned operations incl. ||, \u0026amp;\u0026amp;. Also if, while * Max ops: 30 * Rating: 4 */ unsigned floatPower2(int x) { // V = (-1)^s * M * 2^E // E = e-127 E∈[-126,127] // s=0,f=0, x带入E即可得到 2^x // 为此，反演从E求e的过程 if (x \u0026gt;= 128) return 0x7f800000; // +INF if (x \u0026gt;= -126) return (x + 127) \u0026lt;\u0026lt; 23; // [-126,127]: 2^x为规格数, f=1.0, e=x+127 if (x \u0026gt;= -150) return 1 \u0026lt;\u0026lt; (x + 150); // [-150,-125]: 2^x为非规格数, f=2^(x+150), e=0 else return 0; // too small } 太史公曰：前面几个考察int的题目层层深入，从掩码思想到条件判断，每个新题目都可以用到前面题目的思路。只有howManyBits需要想到如何用移位构造迭代，有一定的难度。相比而言最后的浮点数题目由于放开了诸多限制，变成了一般的编程题，只需要熟练掌握浮点数规则即可作答。\n","date":"2020-01-21T00:00:03Z","permalink":"https://lonelyuan.github.io/p/csapp-datalab/","title":"CSAPP - Datalab"},{"content":"那个男孩不想玩人工智能呢？在玄学修bug之后，我终于跑通了jetbot自带的深度学习demo。\n怎样才能让ai程序发挥好的效果呢？众所周知，所谓人工智能，有多少人工就有多智能。\nAI的发展离不开三个要素：算力，算法和算材。根据摩尔定律，算力的发展是不会停滞的（虽然定律快失效了）；进几年来的AI热正是算法的突破，即深度学习相关算法的突飞猛进；而算材就是用来训练模型的数据，未来几年AI应用的进一步落地离不开算材的进一步开发（中国在AI方面的最大优势正在于此）。数据集的丰富程度和有效程度直接影响了AI应用的效果，我将在下文详细说明。\n在jetbot项目中，我们也能体验到用“人工”换“智能”的快乐。作为视觉识别类的AI应用，我们要在预设环境里创建数据集，并为其标注。有了数据集，jetbot搭载的NVIDIA牌GPU在方寸之间就能完成海量计算，仅用一颗摄像头就能实现自动避障，目标追踪，自动巡线等等炫酷功能！不要1999，也不要999，只要99！99刀NVIDIA计算卡带回家！（妮维雅打钱）\n给萌新理清几个概念：\n人工智能，机器学习，深度学习的关系：\n深度学习：一种实现机器学习的技术；机器学习：一种实现人工智能的方法 【包含关系图】 AI的发展路径：\n弱AI：单独领域工作效率超过人类→ 通用AI：可以广泛应用于大部分领域→ 强AI：有自主意识，即将灭绝人类（不是）→ 现在AI发展到什么地步了：弱AI，有生之年可能见到通用AI\n推荐一波汉化的很好的wiki，也有自己原创的内容：http://www.waveshare.net/wiki/JetBot_AI_Kit\n本篇详细介绍两个demo的代码和可能遇到的问题，最后附上神经网络的入门笔记。同样是初次接触，大佬请绕道。\ndemo1：自动避障 小车如何实现自动避障的呢？用通俗的不能再通俗的说法，AI程序通过学习你给他的数据集，知道了什么样的图像是死路，什么样的图像是通路。得到新图像时就能判断是死路的概率有多少，在程序里可以很简单的看出，当这个概率大于0.5的时候就触发小车转向。\n具体而言，你要在你的环境里拍至少200张照片，100张标记为通路（free），100张标记为死路（blocked）。这便是你的数据集（dataset）。构建数据集的时候尽量分散在环境的各个位置和各个方向，可以沿边界环绕一圈，走一段距离停下，转一圈，收集8-10张图片。反正你的数据越多，标记的越准确，模型效果越好。\n下一步就开始训练模型了，从代码里看出，这个demo使用AlexNet模型，用pytorch实现（废话）。第一次运行你会下载一个244M左右的大文件，在/home/jetbot/.torch/models目录下会看到这个.pth文件。这便是AlexNet了。\n继续运行程序，完整的输出结果有三十行，每行后面的小数代表当前模型的准确度（？），程序最后会从这30个模型中选取准确度最高的作为最终模型，也是一个pth文件：best_model.pth\n下载文件和训练模型都需要花挺长时间，看到kernel busy，也就是右上角的大黑点不要轻易打断。\n什么是模型呢？稍微解释一下机器学习的概念。\n模型就是函数，其要素为输入，输出，和变换关系。举例说明：\n模型 输入 输出 细菌向养分移动 外界环境的化学信号 催动鞭毛的电信号 学生参加高考 试卷反射的光信号 试卷上问题的答案 小车自动避障 摄像头传输图像信号 前方被堵塞的概率 实际上，知识的本质也是函数，生命延续的关键就在于该生命的模型是否适应环境。这里不深入解释了，觉得惊奇请参阅Yjango的频道https://space.bilibili.com/344849038他用机器学习的角度解释生物进化，非常颠覆三观。\n总之训练出来的模型就是这样一个函数。其输入为经过处理的摄像头的图形信号，输出一个0-1的数，越接近1越意味着模型认为小车要撞墙了。但是当他大于0.5的时候就会触发转向，也就实现了自动避障。\nAlexNet是2012年提出的一种卷积神经网络（即CNN）算法。首次实现gpu加速。\n主流深度学习框架：TensorFlow；PyTorch；Keras\n还挺好玩的😀\ndemo2：目标追踪 基于上一个demo，我们还要下载一个模型，coco数据集神经网络，可以检测90种不同的物体。按教程把.engine文件下载到指定位置，顺着跑就完事了。（引入模型也要花挺长时间）\n如果有数据集里的物品，从输出里能看到蓝框标出，小车会自动转向物体，同时还保留了自动避障的程序。\n遇到bug：程序仅能读取一张图像进行识别，摄像头更新的功能无法执行。\n修bug：摄像头问题 描述：摄像头只要调用了一次，后面就无法在其他地方调用。直接在jupyter上关闭输出并没有作用。而且只要在一个notebook里就能重复调用，换一个就不行。而且并没有报错信息，程序一直处在busy状态。\n找到源码，在jetbot/jetbot/camera.py，但是所有样例里面调用摄像头都是用的Camera.instance()方法，而这个instance是在traitlets库里的，于是找到trailets官方文档\nTraitlets是一个纯 python 库，支持：\n对 python 对象属性的强类型实施( 类型属性称为 \u0026ldquo;特征\u0026rdquo; ) ； 动态计算的默认值； 当尝试改变时，自动验证和强制特征属性； 当特征值改变时注册接收通知； 从文件或者 命令行 参数中读取值- 在traitlets上不同层，因这里可以在没有配置机器的情况下使用 traitlets。 Traitlets支持IPython和Jupyter的配置系统，以及IPython交互小部件的声明性 API。\nipython是一个 python 的交互式 shell，比默认的python shell 好用得多，支持变量自动补全，自动缩进，支持 bash shell 命令，内置了许多很有用的功能和函数。其中就包括traitlets库。\nhttps://traitlets.readthedocs.io/en/stable/config.html 在这里找到instance的功能：返回现有的类，如果没有就新建一个。\n下面是样例中调用摄像头的代码：\n1 2 3 4 5 6 7 8 import ipywidgets.widgets as widgets #图像模块 from IPython.display import display #ipy的显示模块 import traitlets from jetbot import Camera, bgr8_to_jpeg #摄像头驱动，图像格式转换 camera = Camera.instance(width=500, height=500)#初始化摄像头对象 image = widgets.Image(format=\u0026#39;jpeg\u0026#39;, width=400, height=400)#创建图像 camera_link = traitlets.dlink((camera, \u0026#39;value\u0026#39;), (image, \u0026#39;value\u0026#39;), transform=bgr8_to_jpeg) #连接摄像头到图像 display(image) #显示图像 尝试从camera.py里调用原始api。得到报错：Each object must be HasTraits, not \u0026lt;class 'NoneType'\u0026gt;，是说必须为对象指定类型。那么HasTraits这个类型是啥？文档说:任何具有trait属性的类都必须从 HasTraits 继承。\n再次梳理调用摄像头的流程：\n引入模型：model.load_state_dict(torch.load('best_model.pth')) 连接摄像头：见上文 模型执行： 1 2 3 4 def update(): ...#此处为模型执行函数，将输入图像预处理后，执行模型 update({\u0026#39;new\u0026#39;: camera.value}) #初始化该函数 camera.observe(update, names=\u0026#39;value\u0026#39;) #将update函数设为camera.value的observer 研究一下observe用法：当对象发生变化时调用函数。\nhttps://traitlets.readthedocs.io/en/stable/using_traitlets.html#validation\n执行如下代码：\n1 2 3 4 5 6 7 8 9 10 import ipywidgets.widgets as widgets #图像模块 from IPython.display import display #ipy的显示模块 import traitlets from jetbot import Camera, bgr8_to_jpeg #摄像头驱动，图像格式转换 camera = Camera.instance(width=500, height=500)#初始化摄像头对象 def update(change): x = change[\u0026#39;new\u0026#39;] display(x) #显示图像 update({\u0026#39;new\u0026#39;: camera.value}) camera.observe(update, names=\u0026#39;value\u0026#39;) 输出一大堆数组，说明camera.value是这一大堆像素。而且observe正常运行，数据一直冒出。\n1 2 3 4 5 6 7 8 9 10 11 12 array([[[122, 116, 130], [126, 113, 127], [125, 117, 129], ..., [ 84, 96, 107], [ 82, 96, 113], [ 93, 93, 113]], [[120, 119, 130], [122, 120, 119], [118, 123, 130], ..., 然而就是不实时更新数据，卒。\n👴佛了。\n","date":"2019-10-01T00:26:38Z","permalink":"https://lonelyuan.github.io/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8jetbot%E6%99%BA%E8%83%BD%E5%B0%8F%E8%BD%A6%E5%B0%9D%E9%B2%9C%E4%BA%8C/","title":"深度学习入门——jetbot智能小车尝鲜（二）"},{"content":"那个男孩不想玩树莓派呢？机缘巧合之下，我得到了一台价值上百美元的智能小车的使用权。\n小车的核心是NVIDIA家的jetson-nano开发板，这款19年三月才发布的微型AI计算机可谓是平民级核弹，四核A57的CPU，128核心Maxwell架构的GPU，4g内存，支持4k视频解码，而且这只五脏俱全的麻雀只需要5W的电源支持，任何一支充电宝都可以胜任。而它的定位是用它简单的搭建人工智能应用，非常的amazing。\n本文的目的,不完全是新手教程,还有自己学习过程的记录和分享.初次接触,多有疏漏,欢迎指教.\n【图片：主板证件照】\n给萌新理清几个概念：\n单片机：Single-Chip Microcomputer。\n树莓派：一款著名的微型电脑品牌（本文介绍的jetson-nano可以理解为是树莓派的竞品，相比树莓派，这款单片机价格更高，性能更好，主打AI应用）\njetbot：以jetson-nano为平台搭建的ai机器人应用，也就是所谓智能小车\n硬件组装:积木和电工 本人拿到的是零件状态的小车，所以首先讲一讲组装的问题。有关具体步骤，官网教程十分详细，贴个连接给懒人吧：https://www.ncnynl.com/archives/201904/2927.html\n这里只讲一讲我作为初学者的一些理解。首先，玩单片机和玩积木的区别就在于编程。当然，入门单片机还需要其他技能。比如，电工技能：你需要进行线材的简单加工，引脚的焊接，准备基本的工具就好，毕竟那个男孩没有一根热热的棒子呢（指电烙铁）。然后，各个部件的拼接固定需要一些做手工的技巧，这个也不用怕，赫鲁晓夫曾经说过：热熔胶可以让我们创造奇迹。\n在这个层面上，初学者会浪费许多耗材，这是必要的练习手段，所以初学者也可以从最简单的芯片入手。同时你还要学习诊断硬件方面的问题，万用表会很有帮助。关于更详细的工具和耗材的需要，请自行查阅单片机入门有关资料。\n在本项目中，焊接工作已经完成，剩下的连接都是可插拔式的。我们只需要两把螺丝刀即可完成组装。即便如此，本人还是花了一晚上才把小车点亮，原因是我得到的线材损坏近半，只得自己寻找和修理。\n下面分析一下小车的结构:\njetson-nano开发板:即本机的主板,可以看到有两层芯片,上层为核心层,包括cpu,gpu和内存可以像笔记本内存条一样拆卸;下层为主板,用于连接各种设备 intel无线网卡:将上层拆下即可安装.令连出两根天线,缠绕机身即可. PiOLED显示器和拓展版:连接在I2C主线上 相机模块:官方样例展示了只用一个摄像头通过深度学习进行自动避障的demo. 马达和其驱动板:下文重点讲解 开发板就可以运行一个完整的Ubuntu系统,其余设备是为其拓展功能的.\n硬件架构：驱动芯片和I2C主线 我在玩小车的过程中耽误最长时间的就是电机（即马达）驱动了，借此讲一讲系统架构的事。\n让轮子前进要靠马达，给马达供电不能直接让主板来做，要让主板给另一块小芯片发送指令，这块小芯片连接着独立的电源，收到指令才会给马达通电。这块小芯片即是电机驱动板。\n驱动芯片是从硬件走向软件的第一道桥梁，可以类比PC的IO设备来理解。和物理世界交互的各种功能，都需要有专门的驱动芯片。包括马达，摄像头，扬声器，机械臂等等，只不过有的可以集成在一起，如：小车上的摄像头，PiOLED显示器等；有的出于体积，安全性，模块化的考虑需要分开，如电机和驱动板。\n电机驱动板 官方给出的电机驱动板型号为:DC-Stepper-Motor PCA9685+TB6612.可以驱动两个步进电机或四个直流电机。（四轴飞行器gkd）本项目只用到了两个直流电机。\n各个引脚的讲解：https://learn.adafruit.com/adafruit-stepper-dc-motor-featherwing/pinouts\n电机驱动板上共连接有10根跳线。一对电源输入，两对为马达输出。还需四根母-母杜邦线来连接至主板的I2C总线,具体来说,是在LED屏旁边的拓展板。分别是：\n驱动板引脚 主板I2C引脚 功能 3V3 3V3 为驱动板供电,即电源正极 GND GND 接地,即电源负极 SDA 3 串行数据线，传输数据 SCL 5 串行时钟线，传输控制信号 【图片：驱动板引脚】\n接错了有可能烧坏板子哦\nI2C总线 所谓总线,可以理解为一条街道,每个设备就是街道两旁的房子,房内的住户出门走亲访友就是数据在不同设备间的传输。\nI2C总线是常用于嵌入式系统的一种简易串行总线.他有简洁的双线结构(SCL+SDA),每个设备都有一个地址码,以此实现多个设备相互通讯。设备有主从之分，主设备/主端必须是带有CPU的逻辑模块，在同一总线上同一时刻使能有一个主端，可以有多个从端，从端的数量受地址空间和总线的最大电容 400pF的限制。\n可以使用i2c-tools调试i2c总线:\n检测有几组i2c总线在系统上i2cdetect -l 检测挂载在i2c-1上的设备i2cdetect -r -y 1 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 a b c d e f 00: -- -- -- -- -- -- -- -- -- -- -- -- -- 10: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 20: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 30: -- -- -- -- -- -- -- -- -- -- -- -- 3c -- -- --（led） 40: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 50: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 60: 60 -- -- -- -- -- -- -- -- -- -- -- -- -- -- --（电机驱动） 70: 70 -- -- -- -- -- -- -- 查看设备(地址为0x20)上所有寄存器的值i2cdump -f -y 1 0x20\n对单个寄存器进行读写:\ni2cset -f -y 1 0x20 0x77 0x3f （设置i2c-1上0x20器件的0x77寄存器值为0x3f）\ni2cget -f -y 1 0x20 0x77 （读取i2c-1上0x20器件的0x77寄存器值）\njetson-nano开发板提供了6条I2C主线,以及其他丰富的接口。理解这些接口是拓展各种设备的前提。\n软件连接:ssh远程桌面 从头开始的话，我们还需要往sd卡里烧写系统镜像，不过我拿到的已经完成了这一步骤，故不再赘述。\n在官方教程中,需要hdmi线连接显示屏,usb连接鼠标键盘,来进入jetson-nano的Ubuntu系统.其目的在于首次连接一个无线网络(手机热点),之后只要电脑和nano在同一网络,即可用电脑访问nano的IP(8888端口),直接操纵jetbot.\n由于我并没有hdmi线,只有一根网线,反正都能插,插谁不一样?所以用网线把小车和笔记本连接起来组成局域网.用ssh的方式进入nano的系统.具体步骤如下:\nip发现:在插入网线前后执行两次:arp -a,比较不同,会发现多出一个地址,类型为动态,此即为小车的内网IP.小车的led屏也会自动显示其ip.如eth0:192.168.x.x\n(如此,我们可以直接从浏览器访问这个ip的8888端口,并能运行jupyter notebook了.但我们不能让小车拖着网线跑啊,所以还是要配置无线网络.)\n将笔记本的wifi连接设为对以太网可共享,这一步是为了让小车能通过笔记本联网\n端口扫描:nmap -sT 192.168.x.x发现22端口开放,故连接之:ssh jetbot@192.168.x.x,就用官方教程给的账户密码.\n连接成功后,就可以用命令行工具连接WiFi了,但还是安装一下远程桌面吧.\n配置远程桌面:执行以下命令:\n1 2 3 sudo apt-get install tightvncserver sudo apt-get install xrdp sudo apt-get install vnc4server tightvncserver 之后在你的主机win+R，输入mstsc,进入远程登录桌面，输入小车的ip地址，点击连接\n在xrdp的登陆界面输入用户名密码即可打开远程桌面\n(这里我用jetbot用户登陆遭遇闪退,用root就可以,不清楚原因)(另外开了远程桌面内存疯涨,就很离谱)\n连接上wifi后,你能在小车的led板上看到另一个ip:wlan0:192.168.x.x\n不管怎样,连接上wifi之后的操作就很简单了.跟着教程,跑一跑demo,还是很有成就感的.\n排查bug 然而demo并没有让我跑出来,且指向同一个错误:\n1 OSError: [Errno 121] Remote I/O error 沿着jupyter notebook的报错一直走,一直到了最底层,向设备写入数据报错,remote IO error.\n看起来像是硬件的问题。一步一步排查呗\n怀疑跳线错误\n更换跳线——无果 用万用表测量线两端的信号——正常，排除连接问题 时钟线保持3.3v每隔几秒跳到2.2v又回来，结合i2c的原理应该是正常现象？ 数据线同样保持3.3v，间断跳至2.3，2.0 软件方法检验设备连接性\n用i2ctools可以检测到设备，拔下4根接线，在0x60,0x70处的设备消失（一个是i2c线，一个是逻辑供电？） 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 a b c d e f 00: -- -- -- -- -- -- -- -- -- -- -- -- -- 10: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 20: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 30: -- -- -- -- -- -- -- -- -- -- -- -- 3c -- -- -- 40: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 50: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 60: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 70: -- -- -- -- -- -- -- -- 然而，在通电状态下，把连线拔下又插上之后，i2c又能检测到设备，然后示例代码就能运行了？？？\n迷惑。所以开机时机器并没能正确载入设备，反倒是重新连接后能识别了？？？本来我都要换驱动板了，orz。\n又或者是和驱动板上的reset按钮有关？等下次遇到问题再说吧。\n拾遗 linux内存占用 led屏会显示内存占用，然鹅时间长了总会到90%以上，可我并没有运行什么程序。\n经查阅此处显示的是实际占有的加上buffer和cached mem部分，可以理解为缓存的，随时清理，并不占用实际内存。\n可用top命令查看内存详情。\n供电问题 用充电宝供电方便，但是只要一断电系统就会重启，这对linux系统而言伤害很大。\n而在充电宝电量不满时，经常发生开不了机的问题，大概是因为电量不足导致电压不稳。\n关机命令： sudo shutdown -h now\n重启： shutdown -h now -r\n下一篇：操纵小车和AI初探\n参考链接 https://github.com/NVIDIA-AI-IOT/jetbot/wiki/Hardware-Setup\nhttps://robocarstore.cn/\nhttp://www.gpus.cn/gpus_list_page_techno_support_content?id=50\nhttps://www.jianshu.com/p/789944463fd7\n","date":"2019-09-20T00:25:55Z","permalink":"https://lonelyuan.github.io/p/%E5%8D%95%E7%89%87%E6%9C%BA%E5%85%A5%E9%97%A8jetbot%E6%99%BA%E8%83%BD%E5%B0%8F%E8%BD%A6%E5%B0%9D%E9%B2%9C%E4%B8%80/","title":"单片机入门——jetbot智能小车尝鲜(一)"}]
=======
[{"content":"《CSAPP排第一，6.828排第二》 课程简介：MIT 6.S081: Operating System Engineering - CS自学指南 (csdiy.wiki) MIT的课程体系一直在发展，为避免混淆这里简单梳理一下： 6.828：6.828 / Fall 2018 (mit.edu) 截至2018年，6.828课程的实验使用的是基于 x86 的 JOS 6.S081：6.S081 / Fall 2019 (mit.edu) 2019年新增6.S081（操作系统导论）作为6.828的附属课程。与此同时实验部分首次升级为基于 RISC-V 的 xv6 随后在2020年两门课分离。6.S081作为本科生课程继续发挥导论的作用。而6.828作为面向研究生的研讨课研究更前沿的课题。 6.1810：6.1810 / Fall 2023 (mit.edu) 2022年，课程号更新为 6.5810（原 6.828）和 6.1810（原 6.S081） 配环境 官网文档十分详细：\nLab: Xv6 and Unix utilities (mit.edu) 在本系列实验中，每个实验只关注操作系统的某个部分，因此不同实验用git管理：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 root@55724e7ba091:/xv6-labs-2023# git branch -r origin/HEAD -\u0026gt; origin/util origin/cow origin/debugging-demo origin/fs origin/lock origin/mmap origin/net origin/pgtbl origin/riscv origin/syscall origin/thread origin/traps origin/util 于是要切换到某个实验只需git switch -c \u0026lt;branch\u0026gt;切换分支即可。当然要注意保存当前branch的结果。\nXV6，启动！ QEMU（Quick Emulator）是一个开源的虚拟化和模拟器工具，它可以模拟多个硬件架构，包括x86、ARM、MIPS等。QEMU支持在主机系统上模拟虚拟机，并提供了一种灵活的方式来进行虚拟化开发和测试。——from GPT\n环境配好后，运行make qemu即可进入xv6系统。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 xv6 kernel is booting hart 1 starting hart 2 starting init: starting sh $ ls . 1 1 1024 .. 1 1 1024 README 2 2 2305 xargstest.sh 2 3 93 cat 2 4 32312 echo 2 5 31184 forktest 2 6 15296 grep 2 7 35664 init 2 8 31984 kill 2 9 31192 ln 2 10 31104 ls 2 11 34224 mkdir 2 12 31232 rm 2 13 31208 sh 2 14 53464 stressfs 2 15 32080 usertests 2 16 180664 grind 2 17 47288 wc 2 18 33312 zombie 2 19 30760 console 3 20 0 可以发现这里的可执行文对应着项目文件夹里user目录下的源代码。也就是说目前我们处于用户态。But how it works？\n由于执行的是make指令，当然要去阅读Makefile了：\n1 2 3 4 5 6 7 QEMUOPTS = -machine virt -bios none -kernel $K/kernel -m 128M -smp $(CPUS) -nographic QEMUOPTS += -global virtio-mmio.force-legacy=false QEMUOPTS += -drive file=fs.img,if=none,format=raw,id=x0 QEMUOPTS += -device virtio-blk-device,drive=x0,bus=virtio-mmio-bus.0 qemu: $K/kernel fs.img $(QEMU) $(QEMUOPTS) 这里真正启动了qemu程序，系统的内核、文件系统都在QEMUOPTS中指定。而我们的用户态程序都位于fs.img内：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 UPROGS=\\ $U/_cat\\ $U/_echo\\ $U/_forktest\\ $U/_grep\\ $U/_init\\ $U/_kill\\ $U/_ln\\ $U/_ls\\ $U/_mkdir\\ $U/_rm\\ $U/_sh\\ $U/_stressfs\\ $U/_usertests\\ $U/_grind\\ $U/_wc\\ $U/_zombie\\ fs.img: mkfs/mkfs README $(UEXTRA) $(UPROGS) mkfs/mkfs fs.img README $(UEXTRA) $(UPROGS) 这里让mkfs程序将文件系统构建成img格式的镜像。用户态程序都包含在UPROGS变量中。那么这些下划线开头的可执行文件又是谁编译的呢：\n1 2 3 4 _%: %.o $(ULIB) $(LD) $(LDFLAGS) -T $U/user.ld -o $@ $^ $(OBJDUMP) -S $@ \u0026gt; $*.asm $(OBJDUMP) -t $@ | sed \u0026#39;1,/SYMBOL TABLE/d; s/ .* / /; /^$$/d\u0026#39; \u0026gt; $*.sym 这里涉及到Makefile的一个通用技巧：-o $@ $^中的$@表示当前目标也，即_%，$^表示当前的依赖，即%.o $(ULIB)。于是我们知道这一步执行的是链接操作，那么编译又是谁干的呢？\n伟大的gpt老师告诉我们，makefile中存在这样的隐含规则，他会自动为.o文件寻找.c来编译：\n1 2 %.o: %.c $(CC) -c $(CFLAGS) $\u0026lt; -o $@ 终于捋顺了。虽然我们对操作系统内核的认识还很黑箱，但这些说的道理足以完成第一个实验了。\nLab1 Utils 第一个实验要求完成编写几个用户态函数，首先要明确一点，我们是在一个全新的操作系统，已经没有libc可用了！我们能够使用的只有XV6提供的系统调用，其定义都在user/user.h中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 struct stat; // system calls int fork(void); int exit(int) __attribute__((noreturn)); int wait(int*); int pipe(int*); int write(int, const void*, int); int read(int, void*, int); int close(int); int kill(int); int exec(const char*, char**); int open(const char*, int); int mknod(const char*, short, short); int unlink(const char*); int fstat(int fd, struct stat*); int link(const char*, const char*); int mkdir(const char*); int chdir(const char*); int dup(int); int getpid(void); char* sbrk(int); int sleep(int); int uptime(void); // ulib.c int stat(const char*, struct stat*); char* strcpy(char*, const char*); void *memmove(void*, const void*, int); char* strchr(const char*, char c); int strcmp(const char*, const char*); void fprintf(int, const char*, ...); void printf(const char*, ...); char* gets(char*, int max); uint strlen(const char*); void* memset(void*, int, uint); void* malloc(uint); void free(void*); int atoi(const char*); int memcmp(const void *, const void *, uint); void *memcpy(void *, const void *, uint); sleep sleep i命令要求进程暂停一定时间。输入一个整数，表示时间量，其单位则是系统定义的tick。\n天下代码一大抄，我们观察到kill指令的输入和sleep差不多，都是整数，只不过kill可以接受多个输入。而kill和sleep都有系统调用的定义，因此直接抄过来：\n1 2 3 4 5 6 7 8 9 10 11 #include \u0026#34;kernel/types.h\u0026#34; #include \u0026#34;user/user.h\u0026#34; int main(int argc, char **argv){ if(argc != 2){ fprintf(2, \u0026#34;usage: sleep tick\\n\u0026#34;); exit(1); } int ret = sleep(atoi(argv[1])); exit(ret); } 完成代码编写后按规则讲sleep加入UPROGS参数，最后执行评分脚本：\n1 2 3 4 5 6 root@55724e7ba091:/xv6-labs-2023# ./grade-lab-util sleep make: \u0026#39;kernel/kernel\u0026#39; is up to date. == Test sleep, no arguments == sleep, no arguments: OK (1.4s) == Test sleep, returns == sleep, returns: OK (0.9s) == Test sleep, makes syscall == sleep, makes syscall: OK (1.0s) (Old xv6.out.sleep failure log removed) Extra: uptime 实验文档中的最后给出了一些隐藏关，第一关要求实现uptime，也是掉接口，比sleep更简单：\n1 2 3 4 5 6 7 #include \u0026#34;kernel/types.h\u0026#34; #include \u0026#34;user/user.h\u0026#34; int main(int argc, char **argv){ fprintf(2, \u0026#34;uptime: %d\\n\u0026#34;, uptime()); exit(0); } pingpong pingpong命令将创建两个进程，并通过管道在两个进程间通信一个字节。官方文档对这个命令的实现描述的很清楚了：\nUse pipe to create a pipe. Use fork to create a child. Use read to read from a pipe, and write to write to a pipe. Use getpid to find the process ID of the calling process. 需要注意int pipe(int fd[2])仅支持单向通信，输入是两个fd分别表示读/写。因此读和写需要两个pipe。pipe返回fd之后，再执行fork即可让父子两个进程共享相同的pipe。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #include \u0026#34;kernel/types.h\u0026#34; #include \u0026#34;user/user.h\u0026#34; int main(int argc, char *argv[]) { int pid, p1[2], p2[2]; char buf[] = {\u0026#39;?\u0026#39;}; pipe(p1); pipe(p2); int ret = fork(); if (ret == 0) { // 返回0表示子进程 pid = getpid(); read(p1[0], buf, 1); printf(\u0026#34;%d: received ping\\n\u0026#34;, pid); write(p2[1], buf, 1); exit(0); } else { pid = getpid(); write(p1[1], buf, 1); read(p2[0], buf, 1); printf(\u0026#34;%d: received pong\\n\u0026#34;, pid); exit(0); } } primes 在上一个程序的基础上，primes希望使用多进程机制实现素数筛。具体流程为：\n每个进程通过管道从其左邻居读取数据，并通过另一个管道写入其右邻居。 每个进程代表一个素数，并判断传来的数是否是自己的倍数。当遇到新的素数时，创建新的子进程。 因此，针对第一步，每个进程都保持两个管道，一个临时变量，不断进行”读→判断→写“的循环。\n1 2 3 4 5 6 7 8 9 int me = 0, tmp = 0; int read_pipe[2], write_pipe[2]; while (1) { read(read_pipe[0], \u0026amp;tmp, 4); // 从左边读 if (tmp % me != 0) { try_fork(); write(write_pipe[1], \u0026amp;tmp, 4); // 往右边写 } } 针对第二步，当且仅当不被任何一个进程的数整除的时候进行fork。也就是当输入的数流动到最后/最新的进程的时候。因此需要一个状态变量判断自己是否是最新进程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 int me = 0, tmp = 0, forked=0; int read_pipe[2], write_pipe[2]; while (1) { read(read_pipe[0], \u0026amp;tmp, 4); if (tmp % me != 0) { if (!forked) { pipe(write_pipe); // 初始化管道 forked = 1; if (fork() == 0) { // 子进程重新进行初始化 read_pipe[0] = write_pipe[0]; // 读写管道交换 forked = 0; me = 0; } } write(write_pipe[1], \u0026amp;tmp, 4); } } 最后，主函数应该向管道中写入35个数，并且完成关闭多余的fd，终止条件等操作：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 #include \u0026#34;kernel/types.h\u0026#34; #include \u0026#34;user/user.h\u0026#34; int main(int argc, char *argv[]) { int me = 0, tmp = 0, forked=0; int read_pipe[2], write_pipe[2]; pipe(read_pipe); for (int i = 2; i \u0026lt;= 35; i++) write(read_pipe[1], \u0026amp;i, 4); // 初始先往read_pipe里写满 close(read_pipe[1]); while (1) { if(read(read_pipe[0], \u0026amp;tmp, 4)){ if (me == 0) { me = tmp; printf(\u0026#34;prime %d\\n\u0026#34;, me); } if (tmp % me != 0) { if (!forked) { pipe(write_pipe); forked = 1; if (fork() == 0) { close(write_pipe[1]); // 子进程的write_pipe尚未开发 close(read_pipe[0]); read_pipe[0] = write_pipe[0]; forked = 0; me = 0; } else close(write_pipe[0]); } if (forked) write(write_pipe[1], \u0026amp;tmp, 4); } } else { // 所有数都读完了，等待子进程退出 close(read_pipe[0]); if (forked) { close(write_pipe[1]); int child_pid; wait(\u0026amp;child_pid); } exit(0); } } } find find指令要求在特定名称的目录树中查找文件。程序大部分可以借鉴ls的实现，只需要在输出的时候执行字符串比较，并且实现递归查找。不过首先要了解文件系统的接口：\n1 2 3 4 5 6 7 8 9 10 11 12 13 // kernel/fs.h struct dirent { // Directory is a file containing a sequence of dirent structures. ushort inum; char name[DIRSIZ]; }; // kernel/stat.h struct stat { // 文件状态结构体 int dev; // File system\u0026#39;s disk device uint ino; // Inode number short type; // Type of file short nlink; // Number of links to file uint64 size; // Size of file in bytes }; 于是遍历目录的操作通常为：\n1 2 3 4 5 6 7 fd = open(path, O_RDONLY)) \u0026lt; 0); fstat(fd, \u0026amp;st); switch(st.type){ case T_DIVICE: ... case T_FILE: ... case T_DIR: ... } 于是在T_DIR分支内实现递归，在T_FILE分支内查找字符串即可：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 switch(st.type){ case T_FILE: if(match(path, pattern)\u0026gt;=0) printf(\u0026#34;%s\\n\u0026#34;, path); break; case T_DIR: strcpy(buf, path); p = buf+strlen(buf); *p++ = \u0026#39;/\u0026#39;; while(read(fd, \u0026amp;de, sizeof(de)) == sizeof(de)){ if (de.inum == 0 || trcmp(de.name, \u0026#34;.\u0026#34;) == 0 || strcmp(de.name, \u0026#34;..\u0026#34;) == 0) continue; memmove(p, de.name, DIRSIZ); p[DIRSIZ] = 0; if(stat(buf, \u0026amp;st) \u0026lt; 0){ printf(\u0026#34;find: cannot stat %s\\n\u0026#34;, buf); continue; } find(buf, pattern); } break; } 而match函数随便写一个字符串匹配或者KMP算法即可。\nExtra：find支持正则 给了grep.c，直接调接口\nxargs xargs command命令的参数同样是shell指令，它读取stdout作为参数指令的参数。简单来说，xargs把左边指令的输出放到最右边当作输入。但在我们的实现中，还有诸多细节：\nstdout中每一行作为一个参数，也就是需要以\\n分割。然而这里xv6并没有方便的库函数读取一行输入，需要自己实现readline() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 int readline(char* buf) { char ch, line[MAXARG] = {0}; int bytesRead = 0; while (read(0, \u0026amp;ch, 1)) { // Read a char from stdout if (ch != \u0026#39;\\n\u0026#39;) { line[bytesRead++] = ch; if (bytesRead + 1 \u0026gt;= MAXARG) { printf(\u0026#34;xargs: line too long\\n\u0026#34;); return -1; } } else { // End of line if (bytesRead \u0026gt; 0) { line[bytesRead] = \u0026#39;\\0\u0026#39;; return 1; } } } return -1; } 执行子命令使用fork+exec+wait 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 int main(int argc, char *argv[]) { char buf[buf_size + 1] = {0}; char *xargv[MAXARG] = {0}; for (int i = 1; i \u0026lt; argc; i++) // 去掉xargs xargv[i - 1] = argv[i]; while (1) { int read_bytes = readline(buf); if (read_bytes \u0026lt;= 0) break; char xbuf[buf_size + 1] = {0}; memcpy(xbuf, buf, strlen(buf)); xargv[argc - 1] = xbuf; if (fork() == 0) { // in child if (exec(argv[1], xargv) \u0026lt; 0) { fprintf(2, \u0026#34;xargs: exec fails with -1\\n\u0026#34;); exit(1); } } else { int pid; wait(\u0026amp;pid); } } Extra：还说🔪的事 在当前实现里，每exec一个shell都会打印一个$，导致运行test脚本时的输出实际上是：\n1 2 3 4 5 sh \u0026lt; xargstest.sh $ $ $ $ $ $ hello hello hello $ $ 为了消除烦人的$，我们需要修改shell源码，让其判断是否从文件中打开。相关逻辑位于：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // user/sh.c:134 int getcmd(char *buf, int nbuf){ write(2, \u0026#34;$ \u0026#34;, 2); // 加入判断逻辑 memset(buf, 0, nbuf); gets(buf, nbuf); if(buf[0] == 0) // EOF return -1; return 0; } int main(void){ static char buf[100]; int fd; // Ensure that three file descriptors are open. while((fd = open(\u0026#34;console\u0026#34;, O_RDWR)) \u0026gt;= 0){ if(fd \u0026gt;= 3){ close(fd); break; } } // Read and run input commands. while(getcmd(buf, sizeof(buf)) \u0026gt;= 0){ if(buf[0] == \u0026#39;c\u0026#39; \u0026amp;\u0026amp; buf[1] == \u0026#39;d\u0026#39; \u0026amp;\u0026amp; buf[2] == \u0026#39; \u0026#39;){ // Chdir must be called by the parent, not the child. buf[strlen(buf)-1] = 0; // chop \\n if(chdir(buf+3) \u0026lt; 0) fprintf(2, \u0026#34;cannot cd %s\\n\u0026#34;, buf+3); continue; } if(fork1() == 0) runcmd(parsecmd(buf)); wait(0); } exit(0); } 只需要加入一个状态变量判断是否经过fork即可。\nExtra：sh user/sh.c作为shell功能很受限，可以为其添加更多常用功能，如：\n支持wait 支持; 支持子shell：(，) 支持tab自动补全 支持history 详情请参考《CSAPP-shellLab》\n打个分⑧： ","date":"2023-12-01T00:00:00Z","image":"https://lonelyuan.github.io/p/xv6-utilities/util-grade_hu29693ed85ff5987b48267af9c379c744_33770_120x120_fill_box_smart1_3.png","permalink":"https://lonelyuan.github.io/p/xv6-utilities/","title":"XV6 Lab - Utilities"},{"content":"挂梯子每个人都玩过，但你知道梯子的原理吗。最后一个lab，实现一个HTTP代理服务器。本实验难度相对前面两个lab有所下降，但综合性比较强，涉及教材最后三章的所有内容以及malloc和cache两个lab。\n项目结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 . |-- csapp.c /* |-- csapp.h * 这三个文件是项目主体，可以随意修改 |-- proxy.c */ |-- driver.sh # 测评脚本 |-- free-port.sh /* |-- nop-server.py * 工具脚本 |-- port-for-user.pl */ `-- tiny |-- cgi-bin/ # 动态程序 |-- static/ # 静态文件 |-- csapp.c /* |-- csapp.h * 课本中提到的tiny实现，建议详细阅读 `-- tiny.c */ csapp.c csapp.c和csapp.h是课本后三章提到的函数代码实例，包括以下几组函数实现：\n进程控制：Fork(),Execve(),Wait(),Kill(),Sleep(),Pause()\u0026hellip; 信号控制：Signal(),Sigprocmask(),Sig***set() I/O操作：Open(),Read(),Write(),Lseek(),Close()\u0026hellip; Signal-safe I/O Standard I/O Robust I/O 目录操作：Opendir(),Readdir(),Closedir() 动态内存分配：Malloc(),Realloc(),Calloc(),Free() 内存映射：Mmap(),Nunmap() Socket接口：Socket(),Bind(),Listen(),Accept(),Connect() 网络信息：Getaddrinfo(),Gethostbyname(),Inet_ntop()\u0026hellip; 可重入接口：Open_clientfd(),Open_listenfd() Pthreads多线程：create(),join(),cancel(),detach(),exit(),self(),once() POSIX信号量：Sem_init(),P(),V() 这也太多了8。实际上这些都是系统函数的封装，我们并不需要用到所有函数。可以看到，本实验将后三章讲述的内容全部抛出，让我们自己思考并选用这些工具来完成目标。当然，也可以随意修改这些封装或者直接使用系统接口。\ntiny.c 此外，tiny目录下也有相同的csapp.c和csapp.h，而tiny.c是课本上提到的简易web服务器实现，于是我们可以将其作为proxy的初始代码框架。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 int main(int argc, char **argv){ int listenfd, connfd; char hostname[MAXLINE], port[MAXLINE]; socklen_t clientlen; struct sockaddr_storage clientaddr; listenfd = Open_listenfd(argv[1]); while (1) { clientlen = sizeof(clientaddr); connfd = Accept(listenfd, (SA *)\u0026amp;clientaddr, \u0026amp;clientlen); Getnameinfo((SA *) \u0026amp;clientaddr, clientlen, hostname, MAXLINE, port, MAXLINE, 0); printf(\u0026#34;Accepted from (%s, %s)\\n\u0026#34;, hostname, port); doit(connfd); Close(connfd); } } Socket接口是一切网络程序的底层，有关socket模型请随便搜索那一张流程图并熟记于心（或者参考👴的文章）。这里简单总结一下要点：\n地址标记主机，端口标记进程。 客户端执行Connect()，服务器执行Bind(),Listen(),Accept()。 unix系统中一切皆文件，打开的文件通过文件描述符fd标记。 网络连接也是一种特殊的文件，即Socket()也返回一个fd。 于是对该fd使用传统I/O函数即可进行通信内容的读写。本质上就是读写Socket提供的缓冲区 于是服务器需要维护listenfd,connfd两个fd分别代表监听端口和客户端端口。 而服务器是一个需要长久运行的程序，因此他的核心进程往往运行着一个死循环，也称为主事件循环。 在循环中服务器不断接受着客户端的请求，于是connfd在循环中不断地创建和销毁，而listenfd保持不变。 而具体到单个请求的处理，tiny将其交给了doit()函数。其功能分为以下几步：\n从缓冲区中读取HTTP报文 tiny只针对GET请求做出响应 读第一行，判断HTTP方法 读取处理剩余的HTTP首部 判断请求的是静态文件还是动态程序（cgi-bin） 静态请求，读取文件内容 动态请求，调用cgi程序 此外，面对错误情况要返回相应的状态码，而服务器进程不能结束。 得分点 BasicCorrectness: 40 （基本代理） Concurrency: 15 （并发性） Cache: 15 （使用缓存） Part1: Basic Proxy proxy在client面前扮演服务器，在server面前扮演客户端。也就是说在proxy中需要同时实现这两个功能，而tiny已经有了服务器端的实现，故而只需要考虑客户端的实现即可。\n1 2 3 4 5 ┌──────┐ (2) ┌─────┐ (1) ┌──────┐ │ │◄──────┤ │◄───────┤ │ │Server│ (3) │Proxy│ (4) │Client│ │ ├──────►│ ├───────►│ │ └──────┘ └─────┘ └──────┘ 具体来说，只需要修改doit函数。首先建立最简单的模型：\n1 2 3 4 5 6 7 8 9 10 11 12 13 // v0.1: score 16/40 void doit(int cfd){ char request[MAXLINE], host[16],port[5], response[MAXLINE]; /* (1) client -\u0026gt; proxy */ read_req(cfd, request, host, port); /* (2) proxy -\u0026gt; server */ int sfd = Open_clientfd(host, port); Rio_writen(sfd, request, strlen(request)); /* (3) server -\u0026gt; proxy */ read_res(sfd, response); /* (4) proxy -\u0026gt; client */ Rio_writen(cfd, response, strlen(response)); } read_req()和read_res()封装了从Rio缓冲区读取报文的细节。下面详细介绍：\n在client面前扮演server 对于请求报文，首先需要解析出地址和端口以便找到目的服务器，其次需要注意curl --proxy的第一行发包：\n1 GET http://localhost:81/ HTTP/1.1 这里路径变成了服务器的完整地址，直接丢给tiny是会报404的。因此，👴直接对第一行提取host,port,path。（注意分清sscanf()和sprintf()）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 void read_req(int fd, char* message, char* host, char* port, char* path){ rio_t rio; Rio_readinitb(\u0026amp;rio, fd); memset(message, 0, strlen(message)); char buf[MAXBUF], host_port_path[MAXLINE],host_port[MAXLINE], path_line[MAXLINE]; // Receive: \u0026#34;GET http://host:port/path HTTP/1.1\u0026#34; Rio_readlineb(\u0026amp;rio, buf, MAXLINE); sscanf(buf, \u0026#34;GET %s HTTP/1.1\\n\u0026#34;, host_port_path); sscanf(host_port_path, \u0026#34;http://%[^/]%s\u0026#34;, host_port, path); if(sscanf(host_port, \u0026#34;%[^:]:%s\u0026#34;, host, port) == 1) port = \u0026#34;80\u0026#34;; // Send: \u0026#34;GET /path HTTP/1.1\u0026#34; sprintf(path_line, \u0026#34;GET %s HTTP/1.1\\n\u0026#34;, path); strcat(message, path_line); while(strcmp(buf, \u0026#34;\\r\\n\u0026#34;)) { Rio_readlineb(\u0026amp;rio, buf, MAXLINE); strcat(message, buf); } } 在server面前扮演client 对于响应报文，则需要考虑包体长度问题。代码中设置了MAXBUF常量为8192，在测评脚本中有几个样例是远超过这个数字的。因此需要考虑流式传输，一边接受一边发送。于是doit()也需要进行修改\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // v0.2: score 40/40 void doit(int cfd){ char request[MAXLINE], host[16],port[5], res_buf[MAXBUF]; /* (1) client -\u0026gt; proxy */ read_req(cfd, request, host, port); /* (2) proxy -\u0026gt; server */ int sfd = Open_clientfd(host, port); Rio_writen(sfd, request, strlen(request)); /* (3) server -\u0026gt; proxy */ int n; while ((n = Rio_readn(sfd, res_buf, sizeof res_buf)) \u0026gt; 0) /* (4) proxy -\u0026gt; client */ Rio_writen(cfd, res_buf, n * sizeof(char)); } Part2: Concurrency 在并发性测试中，测评脚本会调用nop-server.py，其核心逻辑如下：\n1 2 3 4 5 serversocket.listen(5) while 1: channel, details = serversocket.accept() while 1: continue 可以看到，nop-server在接受请求之后会进入死循环，也就是说连接被永远阻塞了。这要求proxy能够同时接受多个连接。Pthread库的多线程接口较为简单，只需要将主事件循环中插入Pthread_create()，而doit()则被封装进线程的入口函数中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 // v0.3 55/70 int main(){ // ... while (1) { // ... Pthread_create(\u0026amp;tid, NULL, thread, connfd); } } void thread(int fd){ Pthread_detach(pthread_self()); // 设置为可分离状态，自动回收资源 doit(fd); Close(fd); } Part3: Cache 在缓存测试中，测评脚本会在执行过一定的请求之后杀死tiny服务器，要求服务器对之前的请求进行保存。结合上一步的多线程，这里便存在着并发读写的问题。\n而缓存的实现细节有非常多可说的部分，这里首先抽象出接口：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // v0.4 70/70 void doit(int cfd) { char request[MAXLINE], host[MAXLINE],port[MAXLINE], path[MAXLINE], response[MAXLINE]; /* (1) client -\u0026gt; proxy */ read_req(cfd, request, host, port, path); /* (1.1) proxy -\u0026gt; cache */ char *value = read_cache(\u0026amp;cache, \u0026amp;path); if (value != NULL) { /* (1.2) cache -\u0026gt; client */ Rio_writen(cfd, value, strlen(value)); return; } /* (2) proxy -\u0026gt; server */ int n, sfd = Open_clientfd(host, port); Rio_writen(sfd, request, strlen(request)); /* (3) server -\u0026gt; proxy */ char buf[MAXBUF], res[MAX_CACHE_SIZE]; while ((n = Rio_readn(sfd, buf, sizeof buf)) \u0026gt; 0) { /* (4) proxy -\u0026gt; client */ Rio_writen(cfd, buf, n * sizeof(char)); strncat(res, buf, n * sizeof(char)); } /* (4.1) proxy -\u0026gt; cache */ write_cache(\u0026amp;cache, \u0026amp;path, res); Close(sfd); } 具体到缓存设计这里可以自由发挥。如果面向评测脚本编程，只需要缓存容量为3，连缓存删除的策略都不用实现就可以满分。不过考试就考这个LRU、OPT啥的，还是得理解一下。\n下面是👴让gpt写的基于循环链表的LRU策略的缓存系统：\n数据结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 typedef struct CacheEntry { char* key; char* value; struct CacheEntry* next; struct CacheEntry* prev; } CacheEntry; typedef struct { int size; int capacity; CacheEntry* head; CacheEntry* tail; pthread_mutex_t lock; } Cache; 初始化 1 2 3 4 5 6 7 Cache* createCache(int capacity) { Cache* cache = (Cache*)malloc(sizeof(Cache)); cache-\u0026gt;size = 0; cache-\u0026gt;capacity = capacity; pthread_mutex_init(\u0026amp;cache-\u0026gt;lock, NULL); return cache; } 读缓存 1 2 3 4 5 6 7 8 9 10 11 12 13 14 char* read_cache(Cache* cache, const char* key) { pthread_mutex_lock(\u0026amp;cache-\u0026gt;lock); // 查找是否存在相同的 key CacheEntry* current = cache-\u0026gt;head; while (current != NULL) { if (strcmp(current-\u0026gt;key, key) == 0) { pthread_mutex_unlock(\u0026amp;cache-\u0026gt;lock); return current-\u0026gt;value; } current = current-\u0026gt;next; } pthread_mutex_unlock(\u0026amp;cache-\u0026gt;lock); return NULL; } 写缓存 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 void write_cache(Cache* cache, const char* key, const char* value) { // 初始化Entry CacheEntry* entry = (CacheEntry*)malloc(sizeof(CacheEntry)); entry-\u0026gt;key = strdup(key); entry-\u0026gt;value = strdup(value); entry-\u0026gt;next = NULL; entry-\u0026gt;prev = NULL; pthread_mutex_lock(\u0026amp;cache-\u0026gt;lock); // 查找是否已存在相同的 key CacheEntry* current = cache-\u0026gt;head; while (current != NULL) { if (strcmp(current-\u0026gt;key, key) == 0) {// 更新值 free(current-\u0026gt;value); current-\u0026gt;value = strdup(value); pthread_mutex_unlock(\u0026amp;cache-\u0026gt;lock); return; } current = current-\u0026gt;next; } // 插入新节点到链表头部 entry-\u0026gt;next = cache-\u0026gt;head; if (cache-\u0026gt;head != NULL) { cache-\u0026gt;head-\u0026gt;prev = entry; } else { cache-\u0026gt;tail = entry; } cache-\u0026gt;head = entry; // 如果超过容量限制，删除尾部节点 if (cache-\u0026gt;size == cache-\u0026gt;capacity) { CacheEntry* tail = cache-\u0026gt;tail; cache-\u0026gt;tail = tail-\u0026gt;prev; cache-\u0026gt;tail-\u0026gt;next = NULL; free(tail-\u0026gt;key); free(tail-\u0026gt;value); free(tail); } else { cache-\u0026gt;size++; } pthread_mutex_unlock(\u0026amp;cache-\u0026gt;lock); } 评价：最后一个实验满分的要求还是很低的。由于c语言编程实在繁琐，👴这个实验追求的是满分前提下的代码极简主义。\n结束了吗 实际上，生产级代理服务器需要考虑的远比本实验复杂几个数量级，在此提出几个思路以抛砖引玉：\n完备的协议支持： tiny仅支持GET方法，且不支持请求头，这实际上是被称为HTTP 0.9的一个历史版本。而目前最广泛使用的HTTP 1.1，为了实现对它的兼容，需要实现以下特性： 增加HEAD、POST方法，支持头域（HTTP 1.0中被引入） 支持Keep-Alive头，满足http请求重用tcp连接 支持Transfer-Encoding: chunked头，实现分块传输编码，满足大文件请求的需求 支持Accept-Ranges头，实现字节范围请求 支持请求流水线等其他特性 虽然实现HTTP协议是服务器的任务，但是对代理服务器的稳健性提出了更高的要求。 另外，本实验实现的proxy基本上是明文http代理。然而在实际应用中https才是更常用的协议。为此代理需要实现对TLS的支持。 更高的性能 我们完全可以自己修改评分脚本，把对缓存的考察上点强度。为了满足更高的性能，需要更高效的数据结构，如： 使用信号量代替互斥锁，使用读者写者模型 使用哈希表，红黑树等高级数据结构，提高查询速度 从更实际的开发的角度，不必将目光局限于c语言。有大量的其他语言生态的高性能库供我们挑选。 加密传输 保密性也是一个重要需求。更常见的代理架构是客户端和服务器都运行着代理服务器进程，在本地代理和远程代理之间运行着私有的加密通信协议。(Shadowsocks(R), VMess/VLess, Trojan\u0026hellip;) 路由规则 本地代理统管着所有出网流量，但客户端不希望所有请求都经过代理。为此需要为不同目标的流量设计不同的路由规则。 另一方面，客户端还希望管理多个代理服务器(clash) VPN和代理服务器原理不同，VPN是如何实现路由的？ 猫鼠游戏 想象你是局域网管理员，你观察到网络中某些IP的大部分流量都集中至一个外部IP的特定高位端口，你能否判断这些IP存在异常行为？ 你观察到某些IP的流量不再通往高位端口了，反而都是通往443端口的https流量，该外部IP运行着一个简单的网站，如何判断？ 详情自行搜索相关论文。关键词：GFW ","date":"2023-10-05T00:00:03Z","permalink":"https://lonelyuan.github.io/p/csapp-proxylab/","title":"CSAPP - Proxylab"},{"content":" 本系列是学习《Fuzzing101 with LibAFL》系列博客（后文统称：原博客）的笔记分享，在学习介绍 LibAFL 用法的同时总结 Rust 知识点。\n前置知识： fuzz基本概念、AFL基本使用 本篇要点：\nLibAFL Forkserver模式: Sugar API AFL tools：afl-cmin、optmin、afl-tmin、afl-cov 字段固定 Rust Builder clap Execise-3 source \u0026amp; corpus 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # tcpdump wget https://github.com/the-tcpdump-group/tcpdump/archive/refs/tags/tcpdump-4.9.1.tar.gz tar -xzvf tcpdump-4.9.1.tar.gz mv tcpdump-tcpdump-4.9.1 tcpdump rm tcpdump-4.9.1.tar.gz # tcpdump的依赖pcap wget https://github.com/the-tcpdump-group/libpcap/archive/refs/tags/libpcap-1.8.0.tar.gz tar -xzvf libpcap-1.8.0.tar.gz mv libpcap-libpcap-1.8.0/ libpcap rm libpcap-1.8.0.tar.gz # 用scapy生成corpus ## 原文使用poetry,直接pip也可 pip install scapy python create-bootp.py # 本篇没用到qemu，但依然需要这个依赖 apt-get install -y ninja-build Makefile.toml 还是熟悉的配方，还是熟悉的cargo make build。还是不熟悉的bug。。。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 [tasks.build] dependencies = [ \u0026#34;build-cargo\u0026#34;, \u0026#34;copy-project-to-build\u0026#34;, \u0026#34;build-libpcap\u0026#34;, \u0026#34;build-tcpdump\u0026#34;, ] [tasks.build-cargo] command = \u0026#34;cargo\u0026#34; args = [\u0026#34;build\u0026#34;, \u0026#34;--release\u0026#34;] [tasks.copy-project-to-build] script = \u0026#34;\u0026#34;\u0026#34; mkdir -p build/ cp ../target/release/exercise-3 build/ sudo setcap cap_sys_admin+epi build/exercise-3 \u0026#34;\u0026#34;\u0026#34; [tasks.build-libpcap] env = { \u0026#34;CC\u0026#34; = \u0026#34;afl-clang-lto\u0026#34;, \u0026#34;LLVM_CONFIG\u0026#34; = \u0026#34;llvm-config-15\u0026#34;, \u0026#34;AFL_MAP_SIZE\u0026#34; = \u0026#34;86217\u0026#34;, \u0026#34;AFL_USE_ASAN\u0026#34; = \u0026#34;1\u0026#34; } cwd = \u0026#34;libpcap\u0026#34; script = \u0026#34;\u0026#34;\u0026#34; ./configure --enable-shared=no --prefix=\u0026#34;${CARGO_MAKE_WORKING_DIRECTORY}/../build/\u0026#34; make make install \u0026#34;\u0026#34;\u0026#34; [tasks.build-tcpdump] cwd = \u0026#34;tcpdump\u0026#34; script = \u0026#34;\u0026#34;\u0026#34; ./configure --prefix=\u0026#34;${CARGO_MAKE_WORKING_DIRECTORY}/../build/\u0026#34; make make install sudo setcap cap_sys_admin+epi ../build/sbin/tcpdump mkdir -p ../solutions \u0026#34;\u0026#34;\u0026#34; [tasks.build-tcpdump.env] \u0026#34;CC\u0026#34; = \u0026#34;afl-clang-lto\u0026#34; \u0026#34;LLVM_CONFIG\u0026#34; = \u0026#34;llvm-config-15\u0026#34; \u0026#34;AFL_USE_ASAN\u0026#34; = \u0026#34;1\u0026#34; \u0026#34;AFL_MAP_SIZE\u0026#34; = \u0026#34;86217\u0026#34; \u0026#34;CFLAGS\u0026#34; = \u0026#34;-I${CARGO_MAKE_WORKING_DIRECTORY}/../build/include/\u0026#34; \u0026#34;LDFLAGS\u0026#34; = \u0026#34;-L${CARGO_MAKE_WORKING_DIRECTORY}/../build/lib/\u0026#34; 补充：Linux中的Capability机制 只有root和普通进程的权限管理不够灵活，普通进程要么什么都不能做，要么sudo什么都能做。于是将root特权分割成诸多能力Capability。\n进程拥有三组能力集：\ncap_effective：可用能力集 cap_inheritable：可继承能力集 cap_permitted：最大能力集 可执行文件也有三组能力集，与进程对应：\ncap_effective： cap_allowed：可继承的能力集 cap_forced：必须拥有才能执行的能力集 均可简记为eip。setcap是配置Capability的工具，其操作类似chmod。\nDebug: build-libpcap 啥叫 -ldw 1 2 = note: /usr/bin/ld: cannot find -ldw: No such file or directory collect2: error: ld returned 1 exit status -ldw代表libdw.so，apt安装即可 我afl-clang-lto呢 1 2 3 configure:2853: afl-clang-lto --version \u0026gt;\u0026amp;5 ./configure: line 2855: afl-clang-lto: command not found configure:2864: $? = 127 让CC指向AFLpulsplus里面的afl-clang-lto。切记要绝对路径 你根本不在bpf/net 1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ make --debug Reading makefiles... Updating makefiles.... Updating goal targets.... File \u0026#39;all\u0026#39; does not exist. File \u0026#39;libpcap.a\u0026#39; does not exist. Prerequisite \u0026#39;grammar.c\u0026#39; is newer than target \u0026#39;grammar.h\u0026#39;. Must remake target \u0026#39;grammar.h\u0026#39;. Successfully remade target file \u0026#39;grammar.h\u0026#39;. File \u0026#39;bpf_filter.o\u0026#39; does not exist. File \u0026#39;bpf_filter.c\u0026#39; does not exist. File \u0026#39;bpf/net/bpf_filter.c\u0026#39; does not exist. Must remake target \u0026#39;bpf/net/bpf_filter.c\u0026#39;. make: *** No rule to make target \u0026#39;bpf/net/bpf_filter.c\u0026#39;, needed by \u0026#39;bpf_filter.c\u0026#39;. Stop. 好熟悉的bug，👴模糊的记得之前捣鼓别的fuzzer的时候好像也遇到过，但是👴清楚的记得当时我没解决。\n于是，👴开始排查是否有依赖缺失，sudo apt-get install libpcap-dev，没用。总不能是 WSL 内核就少点东西吧，我都WSL2了。\n又回头看了看源码，发现 libpcap 的 Github 上有一份bpf_filter.c，而作者给的fuzzing-101-solution里面没有。👴直接上libpacp仓库复制，没用。\n再看看 fuzzing-101 仓库，他用的是 libpacp1.80 版本，👴去翻仓库的标签，果然1.8版本有bpf/net/bpf_filter.c。破案了。👴直接进行一个issue的提。\n后面一步没报错。偶剋~\n1 2 3 4 5 6 7 8 $ ./build/sbin/tcpdump --h tcpdump version 4.9.1 libpcap version 1.8.0 OpenSSL 3.0.2 15 Mar 2022 Compiled with AddressSanitizer/CLang. $ ./build/sbin/tcpdump -r corpus/bootp-testcase.pcap reading from file corpus/bootp-testcase.pcap, link-type IPV4 (Raw IPv4) 15:11:03.147545 IP localhost.bootps \u0026gt; 127.1.1.1.bootpc: BOOTP/DHCP, Request from 00:00:00:00:00:00 (oui Ethernet), length 236 fuzzer 1 2 3 4 5 6 7 8 9 10 11 12 13 14 fn main() { let parsed_opts = parser::parse_args(); let cores = Cores::from_cmdline(\u0026amp;parsed_opts.cores).expect(\u0026#34;Failed to parse cores\u0026#34;); ForkserverBytesCoverageSugar::\u0026lt;86217\u0026gt;::builder() .input_dirs(\u0026amp;[parsed_opts.input]) .output_dir(parsed_opts.output) .cores(\u0026amp;cores) .program(parsed_opts.target) .debug_output(parsed_opts.debug) .arguments(\u0026amp;parsed_opts.args) .build() .run() } Sugar API to simplify the life of the naive user of LibAFL\nLibAFL贴心的为我这种 naive user 准备了一条龙服务，提供了 Sugar API 将前两篇的样板代码进一步简化。好的，fuzzer写完了。\nRust 基础之 Builder parser.rs 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #[derive(Parser, Debug)] pub struct FuzzerOptions { #[clap(short, long, default_value = \u0026#34;solutions\u0026#34;)] pub output: PathBuf, #[clap(short, long, default_value = \u0026#34;corpus\u0026#34;, multiple_values = true)] pub input: PathBuf, #[clap(short, long)] pub cores: String, #[clap(short, long, required = true, takes_value = true)] pub target: String, #[clap(short, long)] pub debug: bool, #[clap( short, long, allow_hyphen_values = true, multiple_values = true, takes_value = true )] pub args: Vec\u0026lt;String\u0026gt;, } pub fn parse_args() -\u0026gt; FuzzerOptions { FuzzerOptions::parse() } 这里使用了 clap 库来解析命令行参数，转换为数据结构FuzzerOptions。\nRust 基础之 注解 跑🏃‍ 直接跑是很dumb的，迟迟跑不出结果。这里先抄个答案\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 $ ./build/sbin/tcpdump -r corpus/bootp_asan.pcap -v [2:27:14] reading from file corpus/bootp_asan.pcap, link-type EN10MB (Ethernet) 08:00:00.000000 IP (tos 0x0, ttl 252, id 40207, offset 0, flags [+, DF, rsvd], proto UDP (17), length 60951, bad cksum ff (-\u0026gt;8336)!) ================================================================= ==23730==ERROR: AddressSanitizer: heap-buffer-overflow on address 0x6060000000b4 at pc 0x56339a3e4010 bp 0x7fffaf70f850 sp 0x7fffaf70f848 READ of size 2 at 0x6060000000b4 thread T0 #0 0x56339a3e400f in bootp_print /home/czy/fuzzing-101-solutions/exercise-3/tcpdump/./print-bootp.c:325:2 #1 0x56339a46960a in ip_print_demux /home/czy/fuzzing-101-solutions/exercise-3/tcpdump/./print-ip.c:387:3 #2 0x56339a47008b in ip_print /home/czy/fuzzing-101-solutions/exercise-3/tcpdump/./print-ip.c:658:3 #3 0x56339a4207c2 in ethertype_print /home/czy/fuzzing-101-solutions/exercise-3/tcpdump/./print-ether.c:333:10 #4 0x56339a41e731 in ether_print /home/czy/fuzzing-101-solutions/exercise-3/tcpdump/./print-ether.c:236:7 #5 0x56339a36bff1 in pretty_print_packet /home/czy/fuzzing-101-solutions/exercise-3/tcpdump/./print.c:339:18 #6 0x56339a36bff1 in print_packet /home/czy/fuzzing-101-solutions/exercise-3/tcpdump/./tcpdump.c:2506:2 #7 0x56339a74458a in pcap_offline_read /home/czy/fuzzing-101-solutions/exercise-3/libpcap/./savefile.c:507:4 #8 0x56339a362050 in pcap_loop /home/czy/fuzzing-101-solutions/exercise-3/libpcap/./pcap.c:875:8 #9 0x56339a362050 in main /home/czy/fuzzing-101-solutions/exercise-3/tcpdump/./tcpdump.c:2009:12 答案是管用的，但是直接丢进 Libafl 却没有crash。\n优化 目前的fuzzer原作者跑了一晚上啥也没跑出来，由此引入一些优化方法。\n语料库压缩：optmin optmin 是 afl-tmin 的优化版。将语料库中触发重复路径的部分最小化，有助于fuzzer减少重复尝试。这里的语料库在/solutions/queue，也就是AFL执行过若干轮后的。\n1 2 3 4 5 6 7 # build cd AFLplusplus/utils/optimin ./build_optimin.sh mv optimin ../../../exercise-3 # run cp -r solutions/queue/* queue_for_cmin AFL_MAP_SIZE=86217 ASAN_OPTIONS=abort_on_error=1 ./optimin -f -i queue_for_cmin -o cminnified ./build/sbin/tcpdump -vr @@ 样例压缩：afl-tmin 另一方面，tmin对单个输入进行压缩，减小文件大小也有助于提高效率。\n1 2 3 4 5 6 7 # build cd AFLplusplus/ make afl-tmin mv afl-tmin ../exercise-3 # run cp -r solutions/queue/* queue_for_cmin AFL_MAP_SIZE=86217 ASAN_OPTIONS=abort_on_error=1 ./optimin -f -i queue_for_cmin -o cminnified ./build/sbin/tcpdump -vr @@ 覆盖率观察：afl-cov 然而这种常规优化还是没能有突破，原作者决定观察一下那些代码还没有被覆盖。安装覆盖率工具afl-cov相对比较繁琐：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 export HOME=/fuzzing-101-solutions/exercise-3/ cd $home # 安装afl-cov sudo apt install lcov git clone https://github.com/vanhauser-thc/afl-cov.git # 移动源代码 mkdir exercise-3-gcov exercise-3-gcov/build cp -r exercise-3/libpcap exercise-3-gcov cp -r exercise-3/tcpdump exercise-3-gcov cp -r exercise-3/solutions exercise-3-gcov # 清理lock文件 cd exercise-3-gcov/solutions/queue find * -empty -delete # lcov 需要文件名仅为6位 ## 原博客用的python脚本，👴直接请教 new bing for i in *; do mv -v \u0026#34;$i\u0026#34; \u0026#34;${i: -6}\u0026#34; done # 编译带 cov 的 libpcap cd $home/exercise-3-gcov/libpcap make clean /opt/afl-cov/afl-cov-build.sh -c ./configure --prefix=$(pwd)/../build; make make install # 编译带 cov 的 tcpdump cd $home/exercise-3-gcov/tcpdump make clean CFLAGS=-I$(pwd)/../build/include/ LDFLAGS=-L$(pwd)/../build/lib/ /opt/afl-cov/afl-cov-build.sh -c ./configure --prefix=$(pwd)/../build ; make make install sudo setcap cap_sys_admin+epi ../build/sbin/tcpdump # 执行 /opt/afl-cov/afl-cov.sh -c solutions \u0026#34;./build/sbin/tcpdump -vr @@\u0026#34; 观察到根本运行不到目标CVE所在的文件。\n固定输入 最后原作者决定改 Libafl 源码，在变异之前往里塞固定了的 BOOTY 头。但是👴的 LibAFL 源代码和原博客中有些微区别，虽然版本号一样：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ///libafl/src/executors/forkserver.rs:438 if self.executor.uses_shmem_testcase() { let shmem = unsafe { self.executor.shmem_mut().as_mut().unwrap_unchecked() }; let target_bytes = input.target_bytes(); let size = target_bytes.as_slice().len(); let size_in_bytes = size.to_ne_bytes(); // The first four bytes tells the size of the shmem. shmem.as_mut_slice()[..4].copy_from_slice(\u0026amp;size_in_bytes[..4]); shmem.as_mut_slice()[SHMEM_FUZZ_HDR_SIZE..(SHMEM_FUZZ_HDR_SIZE + size)] .copy_from_slice(target_bytes.as_slice()); } else { self.executor .input_file_mut() .write_buf(input.target_bytes().as_slice())?; } 不过还是找到了对应的位置，向write_buf()插入固定的头部即可。\n👴觉得这样不够优雅，于是寻思能否进行一个类重写。\n【To be continue】\n","date":"2023-08-02T02:00:36+08:00","permalink":"https://lonelyuan.github.io/p/libafl-fuzzing101-3/","title":"libAFL速通Fuzzing101 (3)"},{"content":" 本系列是学习《Fuzzing101 with LibAFL》系列博客（后文统称：原博客）的笔记分享，在学习介绍 LibAFL 用法的同时总结 Rust 知识点。\n前置知识： fuzz基本概念、AFL基本使用 本篇要点：\nLibAFL Inprocess模式 Harness 编译器wrapper LLPM，多核并行 漏洞分类：AFLTriage Rust 函数、闭包 match 模式识别 Option、Result Execise-1.5 Execise-1 中编写的fuzzer十分甚至九分的简陋，距离实际应用还相差甚远。原博客在1.5集中列举了三种优化方法：\n使用afl-clang-lto 代替 afl-clang-fast—— fast 1.1x afl-clang-lto(link time optimization): 实现无碰撞插桩 使用 共享内存 干掉 文件I/O —— fast 3x patch源代码，加入__AFL_FUZZ_INIT();宏 使用InProcessExecutor 换掉 ForkserverExecutor—— fast 10x patch源代码，编写harness function和compiler wraper 由于 Execise-1 的目标xpdf是命令行程序，不是库，故需要做一定修改使其支持静态链接。其操作较为繁琐，涉及make迁移到cmake等，建议有需求时自行研究。\n而 Execise-2 的目标libexif本身是一个库，不如借助 Execise-2 学习harness。\n所以什么是harness？ Harness v. 控制并利用；（把动物）拴在一起（或拴到某物上）；给（马）套上挽具；连接，串联 n. （马的）挽具，马具；系带，吊带；日常工作\n在面对一个库时，并没有现成的入口点，因此需要写一个函数来调用它，这个函数就是 harness。此时，harness成为了与fuzzer直接交互的目标。 也就是说，fuzzer是横冲直撞的野马，target是一望无际的草原，harness则是指引方向的缰绳。\n使用harness时，fuzzer的所有工作将在一个进程中完成，即InProcess。这对性能有以下好处：\n可以直接通过harness的编写促使fuzzer探索我们感兴趣的部分 与fork-server不同，进程内执行免去了进程管理的负担，这一点显著提升了性能 单进程模式天然支持多核，（一个fuzzer实例一个cpu核心）对现代多核处理器友好 那么代价是什么？由于harness将在一个进程中被反复执行，harness应满足以下要求：\n不能有内存泄漏，否则将会对fuzzer本身造成破坏。 不要执行exit()。这会结束当前进程，应该发送abort以供fuzzer重启 避免高算法复杂度，避免大量内存占用，避免日志输出等拖慢速度的行为 是不是摩拳擦掌了呢？让我们重新加入战斗吧！\nExecise-2 libexif source \u0026amp; corpus 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # libexif的依赖 apt-get install autopoint libtool gettext libpopt-dev # 下载源码 wget https://github.com/libexif/libexif/archive/refs/tags/libexif-0_6_14-release.tar.gz tar -xf libexif-0_6_14-release.tar.gz mv libexif-libexif-0_6_14-release libexif # 准备corpus mkdir corpus solutions cd corpus git clone --no-checkout --filter=blob:none https://github.com/libexif/libexif.git cd libexif ## 只留图片 git checkout master -- test/testdata mv test/testdata/*.jpg ../ cd .. rm -rvf libexif Cargo.toml 在InProcess模式中，需要编译器把fuzzer，target，harness全部链接到一起。故以库的形式创建项目：\ncargo new --lib exercise-2 同时，本篇也用到了Libafl的全部组件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # execise-2/Cargo.toml [package] name = \u0026#34;exercise-2\u0026#34; version = \u0026#34;0.1.0\u0026#34; edition = \u0026#34;2021\u0026#34; [dependencies] libafl = { version = \u0026#34;0.10.1\u0026#34; } # libafl core libafl_cc = { version = \u0026#34;0.10.1\u0026#34; } # compiler wrapper libafl_targets = { version = \u0026#34;0.10.1\u0026#34;, features = [ \u0026#34;libfuzzer\u0026#34;, \u0026#34;sancov_pcguard_hitcounts\u0026#34;, \u0026#34;sancov_cmplog\u0026#34;, ] } # common code for targets instrumentation [lib] name = \u0026#34;exercisetwo\u0026#34; crate-type = [\u0026#34;staticlib\u0026#34;] # 生成 libexercisetwo.a cargo-make 使用build.rs能够增加自动化程度，但用rust写shell依旧略显繁琐。于是原博客引入了 cargo-make 工具，在cargo原本的Cargo.toml基础上加入了Makefile.toml，用以自定义配置，构建自动化工作流。 类似于Makefile，又有点像docker-compose.yml。\n安装：cargo install --force cargo-make 如下所示，既可以执行cargo make build一句话跑通全部，也可单独执行cargo make build-libexif，十分灵活。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # execise-2/Makefile.toml [tasks.build] dependencies = [\u0026#34;clean\u0026#34;, \u0026#34;build-compilers\u0026#34;, \u0026#34;copy-project-to-build\u0026#34;, \u0026#34;build-libexif\u0026#34;, \u0026#34;build-fuzzer\u0026#34;] [tasks.build-compilers] command = \u0026#34;cargo\u0026#34; args = [\u0026#34;build\u0026#34;, \u0026#34;--release\u0026#34;] [tasks.copy-project-to-build] script = \u0026#34;\u0026#34;\u0026#34; mkdir -p build/ cp ${CARGO_MAKE_WORKING_DIRECTORY}/../target/release/ex2_compiler build/ cp ${CARGO_MAKE_WORKING_DIRECTORY}/../target/release/libexercisetwo.a build/ \u0026#34;\u0026#34;\u0026#34; [tasks.build-fuzzer] cwd = \u0026#34;build\u0026#34; command = \u0026#34;./ex2_compiler\u0026#34; args = [\u0026#34;-I\u0026#34;, \u0026#34;../libexif/libexif\u0026#34;, \u0026#34;-I\u0026#34;, \u0026#34;../libexif\u0026#34;, \u0026#34;-o\u0026#34;, \u0026#34;fuzzer\u0026#34;, \u0026#34;../harness.c\u0026#34;, \u0026#34;lib/libexif.a\u0026#34;] # -Idir 增加dir为头文件的搜索路径 [tasks.build-libexif] cwd = \u0026#34;libexif\u0026#34; env = { \u0026#34;CC\u0026#34; = \u0026#34;/fuzzing101/exercise-2/build/ex2_compiler\u0026#34;, \u0026#34;LLVM_CONFIG\u0026#34; = \u0026#34;llvm-config-15\u0026#34;} script = \u0026#34;\u0026#34;\u0026#34; autoreconf -fi ./configure --enable-shared=no --prefix=\u0026#34;${CARGO_MAKE_WORKING_DIRECTORY}/../build/\u0026#34; make -i make install -i \u0026#34;\u0026#34;\u0026#34; 看起来清爽多了（此时👴还没有意识到问题的严重性）。\n补充：Linux开发工具链 ./configure 配置: 根据Makefile.in模板和系统信息生成Makefile make 编译：根据Makefile将源代码编译成可执行文件 make install 安装：将可执行文件复制到正确的地方\nautoreconf：属于 autotools 工具链，也是生成makefile的自动化工具。后逐渐被cmake取代。（现在流行的是Ant？） harness \u0026amp; compiler harness.c harness的核心，也就是被fuzzer调用的位置，是LLVMFuzzerTestOneInput()函数。 其输入是一个字节数组和其尺寸。主流fuzzer都接受这个函数声明，或许是因为他们后端都用的LLVM的Libfuzzer吧。\n在Libexif的test目录下有test-fuzzer-persistent.c，是一个适用于AFL持久模式的harness。稍加改造即可：\n删除 AFL 宏 删除任何打印/日志语句 将 main() 重命名为 LLVMFuzzerTestOneInput() 修复其他版本问题 compiler.rs 显然，这部分并没有让我们写一个编译器，而是一个套壳，一层包装(wrapper)。 这里将target与fuzzer静态链接在一起，并加入-fsanitize=address参数以使用ASAN。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // exercise-2/src/bin/ex2_compiler.rs pub fn main() { let cwd = env::current_dir().unwrap(); let args: Vec\u0026lt;String\u0026gt; = env::args().collect(); let mut cc = ClangWrapper::new(); if let Some(code) = cc .cpp(false) .silence(true) .parse_args(\u0026amp;args) .expect(\u0026#34;Failed to parse the command line\u0026#34;) .link_staticlib(\u0026amp;cwd, \u0026#34;exercisetwo\u0026#34;) .add_arg(\u0026#34;-fsanitize-coverage=trace-pc-guard\u0026#34;) .add_arg(\u0026#34;-fsanitize=address\u0026#34;) .run() .expect(\u0026#34;Failed to run the wrapped compiler\u0026#34;) { std::process::exit(code); } } 开始编写fuzzer之前，根据项目的文件结构梳理一下编译逻辑：\nbuild-compilers: 生成自己的编译器：编译时链接fuzzer库。 build-libexif：用自己的编译器编译target build-fuzzer：用自己的编译器编译harness，并链接target库 1 2 3 4 5 6 7 8 9 10 |-- Cargo.toml |-- Makefile.toml |-- corpus |-- harness.c |-- libexif |-- solutions `-- src |-- bin | `-- ex2_compiler.rs `-- lib.rs Libafl: Inprocess模式 组件：Observer \u0026amp; Feedback 由于我们使用的不再是afl-clang-fast，而是使用自己的编译器wrapper。故__AFL_SHM_ID已经不好使了。好在libafl_targets提供了EDGES_MAP：std_edges_map_observer。\n1 2 let edges_observer = HitcountsMapObserver::new(unsafe{std_edges_map_observer(\u0026#34;edges\u0026#34;)}); 此外，简单的超时反馈也改为了真正的崩溃反馈：CrashFeedback。\n1 2 let mut objective = feedback_and_fast!(CrashFeedback::new(), MaxMapFeedback::new(\u0026amp;edges_observer)); 组件：Monitor \u0026amp; EventManager \u0026amp; Status EventManager 在 Inprocess 模式中才真正发挥功用。对于多实例环境，通信问题必须解决。LibAFL设计了一套低级消息传递协议(LLMP)，使用C-S架构，第一个执行的fuzzer作为代理(Broker)，后续执行的均作为客户端(Client)。Client负责不断执行，将信息汇总与Broker综合展示。\n此外， Inprocess 模式还必须设定进程的重启，setup_restarting_mgr_std第一次执行中返回(None, LlmpRestartingEventManager)，后续则返回上一个进程留下的状态，以此实现状态的永续。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 let monitor = MultiMonitor::new(|s| { println!(\u0026#34;{}\u0026#34;, s); }); // MultiMonitor: 同时支持Broker模式或Client模式 let (state, mut mgr) = match setup_restarting_mgr_std(monitor, 1337, EventConfig::AlwaysUnique){ Ok(res) =\u0026gt; res, Err(err) =\u0026gt; match err { Error::ShuttingDown =\u0026gt; { return Ok(()); } _ =\u0026gt; { panic!(\u0026#34;Failed to setup the restarting manager: {}\u0026#34;, err); } }, }; let mut state = state.unwrap_or_else(|| { StdState::new( StdRand::with_seed(current_nanos()), input_corpus, solutions_corpus, \u0026amp;mut feedback, \u0026amp;mut objective, ).unwrap() }); Rust 基础之函数返回值、模式匹配与错误处理 本例中的mgr是一个经典的match用法，用match处理函数的返回值。下面把概念和符号捋一遍：\n函数 Rust 的函数体由一系列语句组成，最后由表达式结尾。必须严格分别表达式和语句。因为表达式代表一个返回值，而语句不返回。\n1 2 3 4 fn FUNC(PARAM: TYPE, PARAM: TYPE, ...) -\u0026gt; RETURN_TYPE { STATEMANT; EXPRESSION } ;: 标识一条语句。表达式没有分号。 !: 标识发散函数(diverge function)，没有返回值。如println!(\u0026quot;{}\u0026quot;, s)，panic!() panic!(): 线程恐慌。单线程程序即报错退出。 (): 空元组，不占用内存。无返回值时的返回值。 模式匹配 match相当于switch的加强版：\n1 2 3 4 5 match VALUE { PATTERN =\u0026gt; EXPRESSION, PATTERN =\u0026gt; EXPRESSION, ... } _: 表示剩余情况的PATTERN。 exhaustive特性：变量的所有可能性必须全部被覆盖。 错误处理 函数返回值常用两类泛型枚举进行包装：\n1 2 3 4 5 6 7 8 pub enum Option\u0026lt;T\u0026gt; { // 可选值 None, // 可以没有值。适用于许多情况：初始值，可选参数，错误(不会panic!) Some(T), // 必须有值 } enum Result\u0026lt;T, E\u0026gt; { // 返回值 Ok(T), Err(E), // Err可以不panic! } Rust对Result实现了许多方便的方法，详情请参阅文档。\nunwrap()：解包Result，才能获取值 对None执行则panic! ?：语法糖，将Err对象传播出来，进一步使代码简洁。 1 2 3 4 5 let result = match FUNC() { Err(e) =\u0026gt; return Err(e), Ok(f) =\u0026gt; f, }; let result = FUNC()?; //等价写法 参考文档：\nhttps://rustwiki.org/zh-CN/std/option/index.html https://rustwiki.org/zh-CN/std/result/index.html 组件：Harness \u0026amp; Executor 在fuzzer侧，LLVMFuzzerTestOneInput()对应libfuzzer_test_one_input()函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 let mut harness = |input: \u0026amp;BytesInput| { let target = input.target_bytes(); let buffer = target.as_slice(); libfuzzer_test_one_input(buffer); ExitKind::Ok }; let in_proc_executor = InProcessExecutor::new( \u0026amp;mut harness, tuple_list!(edges_observer, time_observer), \u0026amp;mut fuzzer, \u0026amp;mut state, \u0026amp;mut mgr, ).unwrap(); fuzzer写完了，善！\nRust 基础之闭包 闭包(closure)，一般语言的闭包就是 lambda 表达式或匿名函数，在Rust中还要加上捕获外部环境中的变量的能力。\n闭包捕获变量的方式分为三类：按顺序捕获\nFn：表示捕获方式为通过不可变引用（\u0026amp;T）的闭包 FnMut：表示捕获方式为通过可变引用（\u0026amp;mut T）的闭包 FnOnce：表示捕获方式为通过值（T）的闭包 实际上，闭包就是这三种Trait的语法糖。关于Trait目前大致理解成某种规定泛型对象的行为的东西。如上面的三类函数，不同程度上约束了泛型。深度内容留待后文学习。\n究竟何为“捕获”？Rust是没有垃圾回收的语言，取而代之的是生命周期。引用时，会自动分析变量生命周期，以决定使用哪个Trait。\n还可以使用关键字move强制转移所有权到闭包中\n参考文档：https://rustwiki.org/zh-CN/rust-by-example/fn/closures/capture.html\n跑🏃‍ 使用ASAN很快就发现了崩溃：\n1 2 3 4 5 6 7 8 [AFL++ ae703a5ce157] /fuzzing101/exercise-2 # taskset -c 4 ./build/fuzzer [Broker #0] (GLOBAL) run time: 0h-0m-57s, clients: 0, corpus: 0, objectives: 0, executions: 0, exec/sec: 0.000 (CLIENT) corpus: 0, objectives: 0, executions: 0, exec/sec: 0.000 -------------8\u0026lt;------------- [Stats #3] (GLOBAL) run time: 0h-1m-0s, clients: 4, corpus: 3, objectives: 0, executions: 6, exec/sec: 0.000 (CLIENT) corpus: 3, objectives: 0, executions: 6, exec/sec: 0.000, edges: 9/10 (90%) [Testcase #3] (GLOBAL) run time: 0h-1m-0s, clients: 4, corpus: 4, objectives: 0, executions: 8, exec/sec: 0.000 (CLIENT) corpus: 4, objectives: 0, executions: 8, exec/sec: 0.000, edges: 9/10 (90%) Debug：我log去哪了 但结果并不让人满意，起因是cargo make build执行并未成功，上述结果是手动编译得到。报错如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [cargo-make] INFO - Running Task: build-libexif -------------8\u0026lt;------------- checking for a BSD-compatible install... /usr/bin/install -c checking whether build environment is sane... yes checking for a race-free mkdir -p... /usr/bin/mkdir -p checking for gawk... no checking for mawk... mawk checking whether make sets $(MAKE)... yes checking whether make supports nested variables... yes checking for POSIX sh $() command substitution... yes checking for gcc... /fuzzing101/exercise-2/build/ex2_compiler checking whether the C compiler works... no configure: error: in `/fuzzing101/exercise-2/libexif\u0026#39;: configure: error: C compiler cannot create executables See `config.log\u0026#39; for more details [cargo-make] ERROR - Error while executing command, exit code: 77 [cargo-make] WARN - Build Failed. 它提示我，我的编译器不大好使。但是较为离谱的是手动执行编译却没问题。 那么我们看看config.log吧，然后就有个问题，config.log到底藏哪了。\n👴：你根本不在工作目录，你躲哪去了 cargo make: 我不到啊\n这个幽灵问题折磨了我许久，直到我意识到Makefile.toml里面的clean选项。。。\n1 2 3 4 5 ... rest of stderr output deleted ... configure:3778: $? = 0 configure:3767: /fuzzing101/exercise-2/build/ex2_compiler -V \u0026gt;\u0026amp;5 clang: error: unsupported option \u0026#39;-V -g\u0026#39; clang: error: no such file or directory: \u0026#39;/fuzzing101/exercise-2/libexif/libexercisetwo.a\u0026#39; 虽然还是不理解为什么，但是照猫画虎把libexercisetwo.a放入就编译成功了。\nDebug：内存爆了！ 尽管很快跑出crash，但fuzzer经常崩溃退出，导致并没有crash保存。报错如下：\n1 2 3 4 thread \u0026#39;\u0026lt;unnamed\u0026gt;\u0026#39; panicked at \u0026#39;Fuzzer-respawner: Storing state in crashed fuzzer instance did not work, no point to spawn the next client! This can happen if the child calls `exit()`, in that case make sure it uses `abort()`, if it got killed unrecoverable (OOM), or if there is a bug in the fuzzer itself. (Child exited with: 9)\u0026#39;, /root/.cargo/registry/src/index.crates.io-6f17d22bba15001f/libafl-0.10.1/src/events/llmp.rs:1071:21 note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace fatal runtime error: failed to initiate panic, error 5 Aborted 报错告诉我们可能有以下原因：\nchild calls exit()：我跑的确实是ASAN_OPTIONS=abort_on_error=1 taskset -c 6 ./build/fuzzer fuzzer有bug：我可以不相信我自己，但我不能不相信 Rust。 OOM：内存溢出。观察下任务管理器，可以发现fuzzer执行后内存占用迅速飙升，在达到90%后fuzzer稳定崩溃退出。 那么基本确认是内存溢出的问题。👴的16G属实不堪大用，这下不得不买内存条了。\n那么基本确认问题无解了吗？👴开始怀疑问题出在Docker上。于是👴回到宿主机 WSL2 上重新配环境。还是在执行cp build/libexercisetwo.a libexif之后成功编译。\n这次能够稳定运行一段时间了，并且成功获得objective。👴就是个睿智。\n👴宣布实验2完成。\n成果落地 好吧还有最后一步。在诸多crash中可能有大量假阳性，大量重复漏洞，为了获得最终的CVE编号，还需要费时费力的辨别。AFLTriage 就是解决这个问题的自动化工具，它使用 GDB 并行的执行漏洞分类、 ASAN 解析和 crash 去重等工作。\nAFLTriage 的工作流程十分简单：将crash依次丢进target执行，并解读执行报告。 因此，首先要为harness添加一个main函数，使其调用一次LLVMFuzzerTestOneInput()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // harness.c #ifdef TRIAGE_TESTER int main(int argc, char* argv[]) { struct stat st; char *filename = argv[1]; stat(filename, \u0026amp;st); FILE *fd = fopen(filename, \u0026#34;rb\u0026#34;); char *buffer = (char *)malloc(sizeof(char) * (st.st_size)); fread(buffer, sizeof(char), st.st_size, fd); LLVMFuzzerTestOneInput(buffer, st.st_size); free(buffer); fclose(fd); } #endif 这里通过#ifdef宏指令和build选项对应，执行cargo make build-triager即可进入分类流程。\n1 2 3 4 [tasks.build-triager] cwd = \u0026#34;build\u0026#34; command = \u0026#34;./ex2_compiler\u0026#34; args = [\u0026#34;-D\u0026#34;, \u0026#34;TRIAGE_TESTER\u0026#34;, \u0026#34;-I\u0026#34;, \u0026#34;../libexif/libexif\u0026#34;, \u0026#34;-I\u0026#34;, \u0026#34;../libexif\u0026#34;, \u0026#34;-o\u0026#34;, \u0026#34;triager\u0026#34;, \u0026#34;../harness.c\u0026#34;, \u0026#34;lib/libexif.a\u0026#34;] 最后执行AFLTriage：../AFLTriage/target/release/afltriage -i ./solutions/ -o ./reports/ ./build/triager @@\n得到3个report：\n1 2 3 afltriage_ASAN_heap-buffer-overflow_READ_exif_entry_get_value_f8a5a368646cf8484298dd0549da6e12.txt afltriage_ASAN_unknown-crash_WRITE_exif_mnote_data_olympus_save_1e4a69a1a4d7585d8ae1e143a3b5eb94.txt afltriage_SIGSEGV___memmove_sse2_unaligned_erms_b1cfe4f5c38c4991e7c55dccdfb06372.txt 👴还有点怀疑ASAN的输出好像都是fuzzer里面的bug，但是阅读报告之后发现确实是target里面的。只是原博客的ASAN能够指出Target源代码的行号，👴的只能拿到二进制地址。\n1 2 3 4 5 6 7 8 9 10 11 12 Summary: ASAN detected heap-buffer-overflow in exif_entry_get_value after a READ leading to SIGABRT (si_signo=6) / SI_TKILL (si_code=-6) -------------8\u0026lt;------------- #10 0x0000555555695c85 in exif_entry_get_value (/home/czy/fuzzing-101-solutions/exercise-2/build/triager) 542: const exif_entry_get_value(e = (ExifEntry *)0x604000000350, val = (char *)\u0026lt;optimized out\u0026gt;, maxlen = (unsigned int)1999) { |||: |||: /* Local reference: ExifEntry * e = 0x604000000350; */ 682: */ 683: if (e-\u0026gt;size \u0026amp;\u0026amp; e-\u0026gt;data \u0026amp;\u0026amp; 684: (strspn ((char *)e-\u0026gt;data, \u0026#34; \u0026#34;) != strlen ((char *) e-\u0026gt;data))) |||: ---: } at exif-entry.c:684 只能说👴的环境还是有点毛病， WSL2 里面跑比 WSL2+Docker 里面跑，稳定运行时间长，但也不超过三分钟。👴只能手动断断续续的重新跑，这样fuzzer的状态其实是丢失了的。后面的实验还是别折腾我这个破本子了。\n而且跑出来的crash👴看着也不像预期要挖的那俩CVE。但是这些都不影响👴再次宣布实验2完成。\n","date":"2023-07-30T02:45:31+08:00","image":"https://lonelyuan.github.io/p/libafl%E9%80%9F%E9%80%9Afuzzing101-2/final_hu189931506a8648410d5552fb49660c91_955953_120x120_fill_box_smart1_3.png","permalink":"https://lonelyuan.github.io/p/libafl%E9%80%9F%E9%80%9Afuzzing101-2/","title":"libAFL速通Fuzzing101 (2)"},{"content":" 本系列是学习《Fuzzing101 with LibAFL》系列博客（后文统称：原博客）的笔记分享，在学习介绍 LibAFL 用法的同时总结 Rust 知识点。\n前置知识： fuzz基本概念、AFL基本使用 本篇要点：\nLibAFL 9大组件 Forkserver模式：简单组装 Rust Cargo 基本使用 变量所有权： 转移(move) 和 拷贝(copy) 引用(reference) 和 借用(borrowing) 是不是搞fuzz的都在搞rust Fuzzing101是大名鼎鼎的 Fuzzing 入门教程。👴之前搞过一点，故这次整点花活。看到有个叫epi052的大佬用 LibAFL 做 Fuzzing101，于是👴也跟着学一波rust。\nLibAFL是用 Rust 写的 Fuzzing 框架，主要贡献在于给出了一套 Fuzzer 的标准化定义，以此试图改善当今 Fuzzing 研究界成果倍出但互不兼容，经常重复造轮子的现象。\nLibAFL 隶属于 AFL++ 项目组，故需要先配置 AFL++ 。而 AFL++ 的官方 Docker 镜像就包含了 Rust 环境，所以使用 Docker 配 LibAFL 环境就只需一句话：\n1 2 docker pull aflplusplus/aflplusplus docker run -ti -v ./Fuzzing101:/fuzzing101 aflplusplus/aflplusplus Execise-1 xpdf 练习一主要是熟悉基本流程。使用AFL主要有以下步骤：\n目标编译插桩。如： 1 2 3 4 export LLVM_CONFIG=llvm-config-15 CC=afl-clang-fast CXX=afl-clang-fast++ ./configure --prefix=./install make make install 语料库准备 执行afl-fuzz Let\u0026rsquo;s see 如何用Rust完成上述步骤。\nRust 基础之cargo 在 Rust 中，可以用rustc编译单个文件，更常见的是使用包管理器cargo。\nCargo.toml 运行cargo new创建一个 package ，其中必有Cargo.toml，描述 package 如何构建。\n1 2 3 4 5 6 7 8 9 # execise-1/Cargo.toml [package] name = \u0026#34;exercise-1\u0026#34; version = \u0026#34;0.1.0\u0026#34; edition = \u0026#34;2021\u0026#34; build = \u0026#34;build.rs\u0026#34; [dependencies] libafl = \u0026#34;0.10.1\u0026#34; 本项目首先规定了构建脚本为build.rs，然后引入了 libafl 依赖。 运行cargo build时，Cargo 会自动处理依赖。(包括 crates.io 下载安装，我觉得这就是现代语言的一种自信)\nbuild.rs 构建脚本是为了方便 Rust 项目与第三方工具的集成。比如上文中目标编译的几条指令，就可以用 Rust std 库中的Command类来执行。\n1 2 3 4 5 6 // make clean; Command::new(\u0026#34;make\u0026#34;) .arg(\u0026#34;clean\u0026#34;) .current_dir(xpdf_dir.clone()) .status() .expect(\u0026#34;Couldn\u0026#39;t clean xpdf directory\u0026#34;); 使用构建脚本还有许多好处，可以利用 Cargo 采取更灵活的构建策略。构建脚本的输出可以被 Cargo 解释，只需打印以cargo: 开头的指令。如下面两行输出向 Cargo 表明仅在这两个文件发生改动时执行构建脚本。\n1 2 println!(\u0026#34;cargo:rerun-if-changed=build.rs\u0026#34;); println!(\u0026#34;cargo:rerun-if-changed=src/main.rs\u0026#34;); LibAFL 组装 上述还是甜点，下面进入正菜环节。 LibAFL 将 Fuzzer 定义为9个组件，分别是：\n摘自这篇博客。\nInput：程序的输入。 重点是格式，最常见的就是 byte array，也有AST等。 Corpus：输入和其附属元数据的存储。 存储有位于内存和位于硬盘两种，后者更广泛。输入也可分为有助于进化的 interesting testcase 和最终触发 crash 的 solution。 Scheduler：从 corpus 中选取 testcase 的调度策略。 最朴素的即先进先出或随机选择，也可引入优先级算法。 Stage：定义对 testcase 进行的操作（action）。 往往会进行多阶段的操作。如 AFL 中的 random havoc stage。 Observer：提供一次执行目标程序的信息。 常用的 coverage map 就是一种 observer。 Executor：用 fuzzer 的输入来执行目标程序。 不同 fuzzer 在这方面区别很大。 Feedback：将程序执行的结果分类以决定是否将其加入 corpus。 feedback 通常处理一个或多个 observer 报告的信息来判断 execution 是否 “interesting”，是否是满足条件的 solution，比如可观测的 crash。 Mutator：从一个或多个输入生成新的 testcase。 通常是最常改动的，不同 mutator 可以组合，往往还和特定的输入类型绑定。 Generator：凭空产生新的输入。 有随机生成的，也有 Nautilus 这种基于语法的。 除此之外，在 LibAFL 实现中还有若干重要组件：\nAPI文档 请 参阅\nState: 包含了运行时的所有元数据，包括 Corpus、RNG 等。 Bolts: 工具库，实现了诸如共享内存的支持。 Monitor: 向用户打印log之类。 Events: 组件之间通信 Fuzzer: 顶层组件，把一切组织起来 因原博客的讲解很详细，且提供了完整代码。故本文试图切换视角，从自顶向下的角度拆解代码：\n组件：Fuzzer 1 2 3 4 5 6 7 8 let monitor = SimpleMonitor::new(|s| println!(\u0026#34;{s}\u0026#34;)); let mut mgr = SimpleEventManager::new(monitor); let scheduler = IndexesLenTimeMinimizerScheduler::new(QueueScheduler::new()); let mutator = StdScheduledMutator::new(havoc_mutations()); let mut stages = tuple_list!(StdMutationalStage::new(mutator)); -------------8\u0026lt;------------- let mut fuzzer = StdFuzzer::new(scheduler, feedback, objective); fuzzer.fuzz_loop(\u0026amp;mut stages, \u0026amp;mut executor, \u0026amp;mut state, \u0026amp;mut mgr)?; 可以看到 StdFuzzer 串联起了全部组件。mgr、scheduler、mutator、stages 都是使用库自带的类，固省略之，下面详述复杂些的组件。\n组件：State 1 2 3 4 5 6 7 let mut state = StdState::new( StdRand::with_seed(current_nanos()), input_corpus, timeouts_corpus, \u0026amp;mut feedback, \u0026amp;mut objective, )?; 查阅文档可知StdState的成员含义，这些成员就是Fuzzer的全部状态了。一个可能的疑惑是为什么会有feedback、objective两种 Feedback，让我们继续向上检阅代码。\n1 2 3 4 5 6 7 8 9 10 pub fn new\u0026lt;F, O\u0026gt;( rand: R, corpus: C, solutions: SC, feedback: \u0026amp;mut F, objective: \u0026amp;mut O ) -\u0026gt; Result\u0026lt;Self, Error\u0026gt; where F: Feedback\u0026lt;Self\u0026gt;, O: Feedback\u0026lt;Self\u0026gt;, Rust 基础之所有权 所有权，是 Rust 特有的设计，在无GC的前提下实现内存安全与高性能。基本规则：\nRust 中每一个值都被一个变量所拥有，该变量被称为值的所有者 一个值同时只能被一个变量所拥有，或者说一个值只能拥有一个所有者 当所有者(变量)离开作用域范围时，这个值将被丢弃(drop) 基于这些原则，当一个值被另一个变量使用时，会发生所有权的转移，先前的变量便不能访问该值。\n1 2 3 let s1 = String::from(\u0026#34;hello\u0026#34;); let s2 = s1; println!(\u0026#34;{}, world!\u0026#34;, s1); // 报错！ 1 2 3 let s1 = String::from(\u0026#34;hello\u0026#34;); let s2 = s1.clone(); println!(\u0026#34;{}, world!\u0026#34;, s1); // 不报错 1 2 3 let x = 5; let y = x; println!(\u0026#34;x = {}, y = {}\u0026#34;, x, y); // 不报错 转移(move) 和 拷贝(copy) let s2 = s1;在 Rust 中被称为变量绑定，代表s1被移动到了s2。\n如果想要访问相同值，需要对变量进行拷贝。在上面的例子中，int类型没有拷贝也不报错，这是因为基本类型的大小是已知的，且分配在栈上，对他的拷贝比较简单，故 Rust 自动实现了拷贝。而String是复杂类型，必须显式的拷贝。\n引用(reference) 和 借用(borrowing) 将值在变量之间传来传去确实比较麻烦。 Rust实现了2种引用：\n\u0026amp;: 不可变引用，允许使用值但不获取所有权。可以有多个。 \u0026amp;mut: 可变引用。仅能存在一个。 可变引用与不可变引用不能同时存在。 获取变量的引用，就称为借用。显然，在离开作用域后所有权将被归还。引用的作用域从创建一直持续到它最后一次使用，而变量的作用域从创建持续到某一个花括号}。\n对引用有效性的检查是 Rust 解决数据竞争，悬垂指针等安全问题的重要机制。\n在本项目中，需要feedback和objective随着state更新而不断积累，因此使用可变引用。而其他成员和state相关，故直接将所有权移交给state。\n参考文档：https://course.rs/basic/ownership/ownership.html\n组件：Observer \u0026amp; Feedback 1 2 3 4 5 6 7 8 9 10 11 12 13 let time_observer = TimeObserver::new(\u0026#34;time\u0026#34;); let edges_observer = unsafe { HitcountsMapObserver::new(StdMapObserver::new(\u0026#34;shared_mem\u0026#34;, shmem_buf)) }; let mut feedback = feedback_or!( MaxMapFeedback::tracking(\u0026amp;edges_observer, true, false), TimeFeedback::with_observer(\u0026amp;time_observer) ); let mut objective = feedback_and_fast!( TimeoutFeedback::new(), MaxMapFeedback::new(\u0026amp;edges_observer) ); 如定义所言，Observer 仅提供信息，Feedback 将观察到的信息进行判断。 在本例中，首先定义的两个Observer分别提供了代码运行时间和便覆盖率的信息。 然后分布对他们进行了不同的反馈判断。feedback_or和feedback_and_fast是逻辑判断宏。因此可以解读他们的逻辑：\nfeedback的条件是覆盖了新的分支 或 “运行时间反馈”。故反馈的是有趣的样例(interesting testcase) 实际上，“运行时间反馈”永远不会真的反馈，需要配合其他反馈使用。这里仅作示例。 objective的条件是覆盖了新的分支 且 运行超时。故反馈的是能触发无限递归漏洞的样例，即我们想要的结果（solution） 组件：Executor 1 2 3 4 5 6 7 let fork_server = ForkserverExecutor::builder() .program(\u0026#34;./xpdf/install/bin/pdftotext\u0026#34;) .parse_afl_cmdline([\u0026#34;@@\u0026#34;]) .coverage_map_size(MAP_SIZE) .build(tuple_list!(time_observer, edges_observer))?; let timeout = Duration::from_secs(5); let mut executor = TimeoutForkserverExecutor::new(fork_server, timeout)?; 我们的 Executor 还是采用经典的 forkserver 架构，构建 Executor 时，首先加入了两个 Observer ，然后指定了超时时间，有助于增加fuzz吞吐量。\n跑🏃‍ 总之借助 LibAFL 的框架，写一个 Fuzzer 还是很清晰的。（或许若干年后的 Fuzzing 学习者就不用啃AFL的1000行源码了😭）\n最后跑出来一个死循环。👴宣布实验一完成。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 [AFL++ 798a8ebfa8a4] /fuzzing101/exercise-1 # ./xpdf/install/bin/pdftotext ./timeouts/c497979e26a808e9 Error: PDF file is damaged - attempting to reconstruct xref table... Error (2459): Dictionary key must be a name object Error (2465): Illegal character \u0026#39;\u0026gt;\u0026#39; Error (2468): Dictionary key must be a name object Error (2471): Dictionary key must be a name object Error (2486): Dictionary key must be a name object Error (2488): Illegal character \u0026lt;2f\u0026gt; in hex string Error (2489): Illegal character \u0026lt;78\u0026gt; in hex string Error (2490): Illegal character \u0026lt;6d\u0026gt; in hex string Error (2491): Illegal character \u0026lt;70\u0026gt; in hex string Error (2492): Illegal character \u0026lt;3a\u0026gt; in hex string Error (2493): Illegal character \u0026lt;4d\u0026gt; in hex string Error (2494): Illegal character \u0026lt;6f\u0026gt; in hex string Error (2496): Illegal character \u0026lt;69\u0026gt; in hex string Error (2498): Illegal character \u0026lt;79\u0026gt; in hex string Error (2501): Illegal character \u0026lt;74\u0026gt; in hex string Error (2503): Dictionary key must be a name object -------------8\u0026lt;------------- ","date":"2023-07-26T02:54:55+08:00","image":"https://lonelyuan.github.io/p/libafl%E9%80%9F%E9%80%9Afuzzing101-1/exe1_hu040a15c83346252047b5ebf7d9d42a76_312292_120x120_fill_box_smart1_3.png","permalink":"https://lonelyuan.github.io/p/libafl%E9%80%9F%E9%80%9Afuzzing101-1/","title":"libAFL速通Fuzzing101 (1)"},{"content":"这个《伊万·弗拉特里克的安全博客》啊，确实是个好博客。这篇《所以你想做安保工作?》啊，确实是篇好文章。那么我一个新世纪理工科战士，怎么开始写读后感了呢？老板的任务罢了。\n伊万老哥是谷歌的安全研究员，代表作有winafl等。能上大厂当研究员，已经是我对职业生涯的理想了。文章说，对大部分人来说，安全首先是一个爱好然后才是工作。诚然，没有纯粹的爱好是无法提供长时间坐冷板凳的自驱力的。但或许大部分人并没有对某一件事的狂热爱好，在褪去光鲜外表后，大部分人都是三分钟热度。人们常说“兴趣大于天赋”，或许浓厚的兴趣本身就是一种稀有的天赋。\nDon’t look now but getting started is more difficult now than it was 10 years ago\n安全研究的入门难度比十年前更高。而本文发布于2018年，那时我正值高考，国内CTF形势方兴未艾，现在网络上随处可见的入门知识，都是当时的热门考点。文章说CTF是很好的入门方式，可以减缓学习曲线的陡峭程度。而现在，又过去了半个十年，我也紧赶慢赶步入研究生阶段。这个结论能否适用于当下的入门者，恐怕难以下定论。（仅限于中国大陆）（只是因为作者没有去过其他国家，没有说中国大陆不好的意思）。\n当然我也不是输出负能量，面对越来越卷的市场，面对全球经济发展下行的环境，面对没有原始资本的自己，唯一能做的就是尽可能学习免费的知识和技能，静观其变。作者最后说，搞安全需要长时间坐电脑，并且\u0026quot;quite intellectually challenging\u0026quot;，经常\u0026quot;mentally exhausting\u0026quot;。此言诚然，要做好长时间得不到回报的觉悟，寻找和培养正反馈；同时也要加强锻炼，身体健康和精神健康两手抓。\n","date":"2023-07-07T20:29:12+08:00","permalink":"https://lonelyuan.github.io/p/%E6%89%80%E4%BB%A5%E4%BD%A0%E6%83%B3%E5%81%9A%E5%AE%89%E4%BF%9D%E5%B7%A5%E4%BD%9C%E8%AF%BB%E5%90%8E%E6%84%9F/","title":"《所以你想做安保工作?》读后感"},{"content":"历史篇 你们 CLI 确实比 GUI 有点素质 要论计算机人的典中典，还得是n年不更新只有寥寥几篇文章的 Hexo 博客。它代表着命令行初学者的兴奋，第一次配 node 环境成功后的喜悦，以及一个月之后的疑问：\n这点屁事我为什么不发秋秋空间/微博？ 只有我看我为什么不记 Onenote/Notion ？ 想要流量我为什么不发知乎/简书/西埃斯弟恩……？ 尽管从现在看仿佛是前朝遗老，个人博客依旧是不存在于中文互联网中的极少数高质量中文内容。它代表着 RSS ，代表着永远不用担心跑路和审查，是 geek 们的精神自留地。\n但是👴还是觉得发一篇博客敲好几条命令麻烦的要死。大概是👴不再年轻了，👴开始追求简单安逸，像挨了锤的牛一样。于是👴最终选用 Gridea ，一个博客客户端，可一键推送到 Github Page。这玩意有些不太趁手的地方，等👴闲来无事的时候搞一搞二次开发……\n然而，👴还没等到闲来无事的时候，发觉Gridea作者弃坑了。。。其客户端（electron害人不浅）编辑体验差，git更新老出毛病。作者现在只更新web端，托管到他的云服务下面。👴还是更相信github不会跑路，所以👴还是赶紧跑路吧。于是：\n你们 JS 确实比 Go 有点素质 于是👴最终选用 Hugo 做博客，因为与 Hexo 相比 Hugo 的运行速度和空间占用都十分轻量。最重要的是，作为 Go 开发的项目，可以直接下载可执行文件，不需要恼人的配环境环节。👴看中了 Stack 主题，但是这个主题用的人不少，有些千篇一律的尴尬。为此👴决定深耕换皮之道……\n原理篇 Hugo 项目结构 1 2 3 4 5 6 7 8 9 ├── archetypes # .md 模板 │ └── default.md ├── config.toml # 配置文件 ├── content # 在这写东西 ├── data # 更多配置文件 ├── layouts # .html 模板 ├── public # 渲染好的网站 ├── static # 静态文件，hugo会全部复制 └── themes # 博客主题 content 这里是 Hugo 的输入，存放.md格式的文章。使用hugo new命令时，会尝试从archetypes目录寻找对应的模板，模板通常仅包含front matter，定义了文章的元属性。语法如下：\nhugo new \u0026lt;SECTIONNAME\u0026gt;/\u0026lt;FILENAME\u0026gt;.\u0026lt;FORMAT\u0026gt;\ncontent中的子文件夹称为 sections ，它们是网站内容的基本分块。分块的目的是分配不同的处理方式，如post需要展示文章列表，page仅展示单独页面等。配置中的permalinks项就是以分块为单位分配URL。\npublic 这里是 Hugo 的输出，存放完整的 HTML 静态网页。使用hugo命令时，会尝试从layouts目录寻找对应的模板， HTML 模板均以 GO 模板语法编写。在写文章时也可使用模板来避免写 HTML 的繁杂，如 Hugo 提供的各种 shortcode 。\n以 Github Page 为例，部署时仅需将这个文件夹同步至 github.io 仓库即可。\nHugo 设计理念 【To be continued】翻译翻译官方文档\n开发篇 如何优雅的二次开发？ 观察theme的内容，会发现除了没有content目录之外和网站根目录结构完全一致。由此猜测，所谓theme也是一个 site，使用theme就是用其模板覆盖我们的网站。\n那么，直接修改theme目录里的内容自然可行，但如果需要升级主题，则会产生许多讨厌的merge问题。如何实现数据和配置的解耦？实际上，上述关于覆盖顺序的猜想并不准确，实际顺序是：本地模板→主题模板→默认模板。故而，在本地模板中添加相同路径下的同名模板文件，即可覆盖掉主题模板的配置。\n以 Stack 主题为例，其在许多位置都存在着诸如hugo-theme-stack\\assets\\scss\\custom.scss的空白文件，只需要在根目录新建\\assets\\scss\\custom.scss即可添加对 CSS 的改动。\n一般来说，仿照主题提供的demo网站即可满足一般的二次开发需求。关于模板查找顺序还有诸多细节，请参阅官方文档：Template lookup order。\narticle元信息：lastmod，wordcount Hugo 本身为每篇文章都统计了相关变量，但 Stack 主题没有展示。从F12定位到相关元素，其模板在：\\themes\\hugo-theme-stack\\layouts\\partials\\article\\components\\details.html\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026lt;footer class=\u0026#34;article-time\u0026#34;\u0026gt; {{ if $showDate }} \u0026lt;div\u0026gt; {{ partial \u0026#34;helper/icon\u0026#34; \u0026#34;date\u0026#34; }} \u0026lt;time class=\u0026#34;article-time--published\u0026#34;\u0026gt; {{- .Date.Format (\u0026#34;2006-1-1\u0026#34;) -}} \u0026amp;nbsp;published \u0026lt;/time\u0026gt; {{- if ne .Lastmod .Date -}} \u0026lt;time class=\u0026#34;article-time--published\u0026#34;\u0026gt; {{- .Lastmod.Format (\u0026#34;2006-1-1\u0026#34;) -}} \u0026amp;nbsp;last modified {{- end -}} \u0026lt;/time\u0026gt; \u0026lt;/div\u0026gt; {{ end }} {{ if $showReadingTime }} \u0026lt;div\u0026gt; {{ partial \u0026#34;helper/icon\u0026#34; \u0026#34;clock\u0026#34; }} \u0026lt;time class=\u0026#34;article-time--reading\u0026#34;\u0026gt; {{ T \u0026#34;article.readingTime\u0026#34; .ReadingTime }} \u0026lt;span class=\u0026#34;post-word-count\u0026#34;\u0026gt;, {{ .WordCount }} words\u0026lt;/span\u0026gt; \u0026lt;/time\u0026gt; \u0026lt;/div\u0026gt; {{ end }} 代码块：行号，突出行 hugo框架本身就支持：（为避免转解析加了空格）\n1 2 3 4 5 { {\u0026lt; highlight go-html-template \u0026#34;lineNos=inline, lineNoStart=42, hl_Lines=1\u0026#34; \u0026gt;}} {{ range .Pages }} \u0026lt;h2\u0026gt;\u0026lt;a href=\u0026#34;{{ .RelPermalink }}\u0026#34;\u0026gt;{{ .LinkTitle }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt; {{ end }} { {\u0026lt; /highlight \u0026gt;}} 预览：\n42{{ range .Pages }} 43 \u0026lt;h2\u0026gt;\u0026lt;a href=\u0026#34;{{ .RelPermalink }}\u0026#34;\u0026gt;{{ .LinkTitle }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt; 44{{ end }} 默认代码高亮是真够吧丑，赶紧改改css。\n配色，字体 【To be continued】\n标题跳转 这slack主题居然标签旁边没有跳转的小链接我也是没想到的。\n【To be continued】\n信息块 slack主题里也没有，那没事了。\n1 2 3 4 {{\\\u0026lt;note info \u0026gt;}} 书写表达的信息 支持 Markdown 语法 {{\\\u0026lt; /note \u0026gt;}} 【To be continued】\n版权块 【To be continued】\n富文本 【To be continued】\n导图 词云 你这静态网站不是很静态啊 评论系统 Stack主题支持的评论系统：\nhttps://stack.jimmycai.com/config/comments 👴作为白嫖怪，既然选择了Github Pages当然要选择同生态的方案。目前有两种方案：\nGitalk：基于issue，和仓库绑定 Giscus：基于GitHub Discussions gitalk对每个文章需要管理员新建issue才能评论实在8太好使。Giucus配置起来更方便：\n首先创建一个公开仓库(直接用page仓库也可，或许)，按官网说的打开Discussion功能，并安装Giscus app 然后把仓库路径填进官网，后面全默认或选第一个，就得到了一串配置信息。 把里面的配置加入hugo配置文件即可（删掉配置变量的data-前缀） 网站统计 教程一大把，搞定科学上网就没问题。\n然后你就会发现并没有人来访问。\n统计平台：\nhttps://analytics.google.com/ https://www.cloudflare.com/zh-cn/web-analytics/ 工作流篇 这一节介绍从撰写到部署踩坑过的工具/环境\nIDE：vscode天下第一 IDE最重要的是避免重复劳动，包括写作，多媒体管理，保存，部署等等。 由于vscode跟github现在都姓了微软了，他们简直亲如一家。\n具体来说，使用vscode写博客的姿势be like：\nGUI丝滑git同步 终端一键预览，发布（甚至可以写配置加一个绿色小三角） markdown支持：图片复制自动插入正文并复制到同路径下 还可以进一步丝滑的需求比如模板文件等\nvscode插件 Front Matter：这不CMS吗 这个插件乍一看挺厉害，实则一拖四。提供了一个类似CMS的界面，可以自动化配置一些些Front Matter，比如日期。但是用了一会其作用不说如虎添翼吧也可以算得上聊胜于无。\nobsdian 使用obsdian比vscode强的地方在于原生支持front matter丝滑管理。 另一个原因是，敲代码已经打开一个vscode图标了容易混淆。 但是在markdown渲染方面有些割裂。希望未来有合适插件出现。\nGithub Pages + Github Action 自动部署 https://gohugo.io/hosting-and-deployment/hosting-on-github/ 部署之后却发现总是带有项目名作为子路径（即xxx.github.io/xxx）。这就很让人不爽了。纵观全网的博客大多都带着这个尾巴，表示怀疑这些人究竟是不是一直这么用的。\nhugo官方给出的workflow中，最后一步是这样的\n1 2 3 4 5 6 7 8 9 10 11 # Deployment job deploy: environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} runs-on: ubuntu-latest needs: build steps: - name: Deploy to GitHub Pages id: deployment uses: actions/deploy-pages@v2 👴直接🐏url，但是${{ steps.deployment.outputs.page_url }}是个用来输出的东西，改它没用。应该是actions/deploy-pages@v2这个action本身的问题。\n于是👴参考了22年的几篇博客：\nhttps://client.sspai.com/post/73512#! 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 - name: Build with Hugo env: # ... run: | hugo \\ --minify \\ --baseURL \u0026#34;https://lonelyuan.github.io/\u0026#34; # fxxk $ ... - name: Deploy Web uses: peaceiris/actions-gh-pages@v3 with: PERSONAL_TOKEN: ${{ secrets.PERSONAL_TOKEN }} EXTERNAL_REPOSITORY: pseudoyu/pseudoyu.github.io PUBLISH_BRANCH: master PUBLISH_DIR: ./public commit_message: ${{ github.event.head_commit.message }} 这种方法涉及两个仓库，因此需要额外配置token。按照博客的方法替换成peaceiris/actions-gh-pages@v3后，可以成功在主域名更新了。\n虽然但是，目前的操作从写博客→hugo→git push变成了写博客→hugo server(总得预览一下吧)→git push，似乎并没有什么简化，，，虽然可以依靠编辑器的自动git commit的插件，但是👴还是不想每次保存都commit。\nGithub Action 收集 lastmodify 使用 Github 的 CI/CD 管线可以在更新时绑定到commit号，但是👴觉得没太大用。改一个字就更新lastmod过于粗粒度，遂还是采用手动展示👴想展示的日期。\n","date":"2021-11-07T14:19:11Z","permalink":"https://lonelyuan.github.io/p/%E9%97%B2%E6%9D%A5%E6%97%A0%E4%BA%8B%E5%80%92%E8%85%BE%E5%8D%9A%E5%AE%A2/","title":"闲来无事，倒腾博客"},{"content":"由于👴觉得👴学校的操作系统讲了个🔨，慕名而来学习上交的 MOSPI 课程。银杏书看完之后👴发现👴学校的OS确实讲了个🔨。我直接当场来一段圣经吟唱：\n那个额西电操作系统嗷，不会写教材可以不写，害特么在弄你那个管程，来我教你啊，看好了啊。首先 M.A.L.H. 原则，看懂了吗，然后开讲虚拟内存，哎我就不虚拟，我就讲那个空闲链表。哎，再扎个多线程，看到没，线程上下文切换了。我特么直接三段系统调度（短期，中期，长期），然后我直接~就一个多核调度，我就调度到IPC，进程现在已经可以通信了啊！别怪我没有教好你，进程通信了之后干什么，憋特么讲你那破几把处理机了。看好啊，讲出锁（嬉皮笑脸），讲出信号量直接就扔到互斥资源身上，就疯狂的进入他的临界区。然后我再一个，文件系统！加三段系统虚拟化（CPU虚拟化、内存虚拟化、IO虚拟化），全部吃满，完成强杀，你唛璧你懂个der，讲寄吧OS，我爱你。\n圣经原文：拖更云的鹰佐教学\n本系列为 ChCore lab 实验报告。 Lab源码：https://gitee.com/ipads-lab/chcore-lab MOSPI在线网站：https://ipads.se.sjtu.edu.cn/mospi/\n实验环境 需要docker和qemu，docker不赘述。linux下安装qemu： sudo apt-get install qemu-system-arm 安装完成之后查看版本号：\n1 2 3 $ qemu-system-aarch64 --version QEMU emulator version 4.2.0 Copyright (c) 2003-2019 Fabrice Bellard and the QEMU Project developers 5个实验在源码仓库分别以5个分支存在。 git clone -b即可。\n内核构建和调试：\n用docker交叉编译内核：make build 启动qemu：make qemu 这里遇到报错： Unable to init server: Could not connect: Connection refused gtk initialization failed 解决方法：修改 Makefile ，在QEMUOPTS参数后加-nographic 启动qemu：make qemu-gdb 将监听1234端口以供gdb远程调用 退出：ctrl+a，然后按x。 如果意外退出，要杀死进程：kill $(ps -ef | grep qemu | grep 1234 | awk '{print $2}') 在另一个终端启动gdb调试：make gdb 这里可能需要安装gdb-multiarch：sudo apt-get install gdb-multiarch 可以看到，本项目中 Makefile 主要是封装了一些命令。\nLab1 练习3-加载入口定义 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 root@lastyear:~/chcore-lab# readelf -S build/kernel.img There are 9 section headers, starting at offset 0x20cd8: Section Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align [ 0] NULL 0000000000000000 00000000 0000000000000000 0000000000000000 0 0 0 [ 1] init PROGBITS 0000000000080000 00010000 000000000000b5b0 0000000000000008 WAX 0 0 4096 [ 2] .text PROGBITS ffffff000008c000 0001c000 00000000000011dc 0000000000000000 AX 0 0 8 [ 3] .rodata PROGBITS ffffff0000090000 00020000 00000000000000f8 0000000000000001 AMS 0 0 8 [ 4] .bss NOBITS ffffff0000090100 000200f8 0000000000008000 0000000000000000 WA 0 0 16 [ 5] .comment PROGBITS 0000000000000000 000200f8 0000000000000032 0000000000000001 MS 0 0 1 [ 6] .symtab SYMTAB 0000000000000000 00020130 0000000000000858 0000000000000018 7 46 8 [ 7] .strtab STRTAB 0000000000000000 00020988 000000000000030f 0000000000000000 0 0 1 [ 8] .shstrtab STRTAB 0000000000000000 00020c97 000000000000003c 0000000000000000 0 0 1 看到init段的起始地址是0x80000，和readelf -h中的 Entry point address 一致，也和 GDB 刚进入时where的输出一致。\n1 2 3 0x0000000000080000 in ?? () (gdb) where #0 0x0000000000080000 in _start () 下面寻找_start的定义，在CMakeLists.txt中找到_start，\n1 2 3 4 5 6 7 set_property( TARGET kernel.img APPEND_STRING PROPERTY LINK_FLAGS \u0026#34;-T ${CMAKE_CURRENT_BINARY_DIR}/${link_script} -e _start\u0026#34; ) 这里为kernel.img指定了链接器脚本(-T)和入口函数(-e)。\n于是跟随link_script：\n1 2 set(link_script \u0026#34;linker.lds\u0026#34;) configure_file(\u0026#34;./scripts/linker-aarch64.lds.in\u0026#34; \u0026#34;linker.lds.S\u0026#34;) 进入脚本linker-aarch64.lds.in：\n1 2 3 4 5 6 7 8 9 10 #include \u0026#34;../boot/image.h\u0026#34; SECTIONS { . = TEXT_OFFSET; img_start = .; init : { ${init_object} } // ... 其中init段指定了加载init_object，它表示bootloader的所有目标文件集合。其定义回到CmakeLists.txt：\n1 2 3 4 5 6 7 set(init_object \u0026#34;${BINARY_KERNEL_IMG_PATH}/${BOOTLOADER_PATH}/start.S.o ${BINARY_KERNEL_IMG_PATH}/${BOOTLOADER_PATH}/mmu.c.o ${BINARY_KERNEL_IMG_PATH}/${BOOTLOADER_PATH}/tools.S.o ${BINARY_KERNEL_IMG_PATH}/${BOOTLOADER_PATH}/init_c.c.o ${BINARY_KERNEL_IMG_PATH}/${BOOTLOADER_PATH}/uart.c.o\u0026#34; ) 可发现/boot/start.S定义了_start。\n下面继续寻找地址，在链接器脚本引用了image.h，其中有TEXT_OFFSET的定义：\n1 2 3 4 5 6 7 #pragma once #define SZ_16K 0x4000 #define SZ_64K 0x10000 #define KERNEL_VADDR 0xffffff0000000000 #define TEXT_OFFSET 0x80000 一切终于串起来了：\nCMakeLists.txt：是CMake的脚本文件。 CMake 是跨平台的C/C++建构工具。 作用： 指定源文件集合init_object 定义链接器脚本link_script 指定入口函数_start并指定链接器脚本 最终生成kernel.img //最近看到的挺好的CMake教程：https://www.bilibili.com/video/BV1rR4y1E7n9 linker-aarch64.lds.in：lds是链接器脚本文件，负责控制输出的ELF文件的细节。 作用：指定了起始地址0x80000 练习3-多处理器挂起 start.S中注释的很明白了，通过检查mpidr_el1寄存器来判断 cpuid ，如果不是0则进入死循环。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 BEGIN_FUNC(_start) mrs x8, mpidr_el1 and x8, x8, #0xFF cbz x8, primary /* hang all secondary processors before we intorduce multi-processors */ secondary_hang: bl secondary_hang primary: /* Turn to el1 from other exception levels. */ bl arm64_elX_to_el1 /* Prepare stack pointer and jump to C. */ adr x0, boot_cpu_stack add x0, x0, #0x1000 mov sp, x0 bl init_c /* Should never be here */ b . END_FUNC(_start) 练习4-LMA和VMA 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 root@lastyear:~/chcore-lab# objdump -h build/kernel.img build/kernel.img: file format elf64-little Sections: Idx Name Size VMA LMA File off Algn 0 init 0000b5b0 0000000000080000 0000000000080000 00010000 2**12 CONTENTS, ALLOC, LOAD, CODE 1 .text 000011dc ffffff000008c000 000000000008c000 0001c000 2**3 CONTENTS, ALLOC, LOAD, READONLY, CODE 2 .rodata 000000f8 ffffff0000090000 0000000000090000 00020000 2**3 CONTENTS, ALLOC, LOAD, READONLY, DATA 3 .bss 00008000 ffffff0000090100 0000000000090100 000200f8 2**4 ALLOC 4 .comment 00000032 0000000000000000 0000000000000000 000200f8 2**0 CONTENTS, READONLY 可以发现只有init段的VMA和LMA相同。其赋值还是回到lds脚本：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 SECTIONS { . = TEXT_OFFSET; img_start = .; init : { //init段VMA==VMA ${init_object} } . = ALIGN(SZ_16K); // 对齐16k init_end = ABSOLUTE(.); // init段结束 // KERNEL_VADDR在image.h定义为0xffffff0000000000 .text KERNEL_VADDR + init_end : AT(init_end) { // AT指定LMA *(.text*) } // .text段：VMA = KERNEL_VADDR + init_end; LMA = init_end // 后面的段，全部按顺序对齐并递增，此时VMA和LMA已经不同，故后面的段也全都不同 . = ALIGN(SZ_64K); .data : { *(.data*) } . = ALIGN(SZ_64K); .rodata : { *(.rodata*) } _edata = . - KERNEL_VADDR; // 这些外部变量指的是LMA，则减去虚拟地址头 _bss_start = . - KERNEL_VADDR; .bss : { *(.bss*) } _bss_end = . - KERNEL_VADDR; . = ALIGN(SZ_64K); img_end = . - KERNEL_VADDR; } 回答问题：\n为什么LMA和VMA不同\nVMA是对应虚拟内存的地址，但在内核启动时还处于物理地址模式，VMA可能超出物理内存范围。所以只能先加载，再映射到虚拟地址。 为什么内核段的VMA要映射到高位，应该是一种惯例。 为什么bootloader不用VMA，因为他负责初始化页表，他不能用，也没有必要。 LMA到VMA在何时转换\n由上一问可知，页表初始化之后便可转换为VMA。 练习5-c语言进制转换 从后往前取余即可。\n练习6-函数栈 start.S中赋值了sp：\n1 2 3 4 /* Prepare stack pointer and jump to C. */ adr x0, boot_cpu_stack add x0, x0, #0x1000 mov sp, x0 /* sp = boot_cpu_stack + 0x1000 */ boot_cpu_stack在init.c\n1 2 #define INIT_STACK_SIZE 0x1000 char boot_cpu_stack[PLAT_CPU_NUMBER][INIT_STACK_SIZE] ALIGN(16); 由于PLAT_CPU_NUMBER被定义为4，故boot_cpu_stack大小为4*4096，可供四个CPU使用。sp初始化后指向第一个4069，也就是第一个cpu内核栈的最高位。初始化时，fp=sp。\n但这是bootloader的栈。后续进入内核后，会重新分配内核栈，参见head.S：\n1 2 3 4 5 6 7 8 BEGIN_FUNC(start_kernel) mov x3, #0 msr TPIDR_EL1, x3 ldr x2, =kernel_stack add x2, x2, KERNEL_STACK_SIZE mov sp, x2 bl main END_FUNC(start_kernel) 于是内核栈的定义在start_kernel函数。\n有关内核栈的位置，因为kernel_stack是全局数组，且未初始化，因而位于.bss。同时没有其他未初始化变量，因此首地址在.bss + KERNEL_STACK_SIZE。\n通过readelf得到.bss的VMA为0xffffff0000090100，KERNEL_STACK_SIZE为0x2000，进入gdb调试可以验证\n1 2 gef➤ x/g $sp 0xffffff0000092100 \u0026lt;kernel_stack+8192\u0026gt;: 0x0 练习7-调用惯例 先看stack_test函数。这里gdb安装了gef插件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 gef➤ b stack_test Breakpoint 1 at 0xffffff000008c020 gef➤ disas Dump of assembler code for function stack_test: =\u0026gt; 0xffffff000008c020 \u0026lt;+0\u0026gt;: stp x29, x30, [sp, #-32]! /* FP、LR 入栈 */ 0xffffff000008c024 \u0026lt;+4\u0026gt;: mov x29, sp 0xffffff000008c028 \u0026lt;+8\u0026gt;: str x19, [sp, #16] /* x 入栈 */ 0xffffff000008c02c \u0026lt;+12\u0026gt;: mov x19, x0 0xffffff000008c030 \u0026lt;+16\u0026gt;: mov x1, x0 0xffffff000008c034 \u0026lt;+20\u0026gt;: adrp x0, 0xffffff0000090000 # 计算偏移 0xffffff000008c038 \u0026lt;+24\u0026gt;: add x0, x0, #0x0 0xffffff000008c03c \u0026lt;+28\u0026gt;: bl 0xffffff000008c620 \u0026lt;printk\u0026gt; 0xffffff000008c040 \u0026lt;+32\u0026gt;: cmp x19, #0x0 0xffffff000008c044 \u0026lt;+36\u0026gt;: b.gt 0xffffff000008c068 \u0026lt;stack_test+72\u0026gt; # greater than /* 递归 */ 0xffffff000008c048 \u0026lt;+40\u0026gt;: bl 0xffffff000008c0dc \u0026lt;stack_backtrace\u0026gt; 0xffffff000008c04c \u0026lt;+44\u0026gt;: mov x1, x19 0xffffff000008c050 \u0026lt;+48\u0026gt;: adrp x0, 0xffffff0000090000 0xffffff000008c054 \u0026lt;+52\u0026gt;: add x0, x0, #0x20 0xffffff000008c058 \u0026lt;+56\u0026gt;: bl 0xffffff000008c620 \u0026lt;printk\u0026gt; 0xffffff000008c05c \u0026lt;+60\u0026gt;: ldr x19, [sp, #16] # x19 = sp + 16 /* x 出栈 */ 0xffffff000008c060 \u0026lt;+64\u0026gt;: ldp x29, x30, [sp], #32 # load pair /* FP、LR 出栈 */ 0xffffff000008c064 \u0026lt;+68\u0026gt;: ret 0xffffff000008c068 \u0026lt;+72\u0026gt;: sub x0, x19, #0x1 0xffffff000008c06c \u0026lt;+76\u0026gt;: bl 0xffffff000008c020 \u0026lt;stack_test\u0026gt; 0xffffff000008c070 \u0026lt;+80\u0026gt;: mov x1, x19 0xffffff000008c074 \u0026lt;+84\u0026gt;: adrp x0, 0xffffff0000090000 0xffffff000008c078 \u0026lt;+88\u0026gt;: add x0, x0, #0x20 0xffffff000008c07c \u0026lt;+92\u0026gt;: bl 0xffffff000008c620 \u0026lt;printk\u0026gt; 0xffffff000008c080 \u0026lt;+96\u0026gt;: ldr x19, [sp, #16] 0xffffff000008c084 \u0026lt;+100\u0026gt;: ldp x29, x30, [sp], #32 0xffffff000008c088 \u0026lt;+104\u0026gt;: ret End of assembler dump. 运行，观察栈的变化，这里省略部分输出：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 gef➤ c ───────────────────────────────────────── registers ──── $x0 : 0x0000000000000005 # 这一层函数的输入值 $x19 : 0x0000000000000000 # 上一层函数的返回值 $x29 : 0xffffff00000920f0 # FP $x30 : 0xffffff000008c0d4 → \u0026lt;main+72\u0026gt; # LR $sp : 0xffffff00000920f0 ───────────────────────────────────────────── stack ──── 0xffffff00000920f0│+0x0000: 0x0000000000000000 0xffffff00000920f8│+0x0008: 0xffffff000008c018 # 栈头，可能是栈初始化的数据结构 ──────────────────────────────────────────── trace ──── [#0] 0xffffff000008c020 → stack_test() [#1] 0xffffff000008c0d4 → main() ─────────────────────────────────────────────────────── gef➤ c ───────────────────────────────────────── registers ──── $x0 : 0x0000000000000004 $x19 : 0x0000000000000005 $x29 : 0xffffff00000920d0 $x30 : 0xffffff000008c070 #→ \u0026lt;stack_test+80\u0026gt; $sp : 0xffffff00000920d0 → 0xffffff00000920f0 ───────────────────────────────────────────── stack ──── 0xffffff00000920d0│+0x0000: 0xffffff00000920f0 ─┐ # FP 0xffffff00000920d8│+0x0008: 0xffffff000008c0d4 │ # LR 0xffffff00000920e0│+0x0010: 0x0000000000000000 │ 0xffffff00000920e8│+0x0018: 0x00000000ffffffc0 │ 0xffffff00000920f0│+0x0020: 0x0000000000000000 ◄┘ 0xffffff00000920f8│+0x0028: 0xffffff000008c018 ───────────────────────────────────────────── trace ──── [#0] 0xffffff000008c020 → stack_test() [#1] 0xffffff000008c070 → stack_test() [#2] 0xffffff000008c0d4 → main() ──────────────────────────────────────────────────────── gef➤ c ───────────────────────────────────────── registers ──── $x0 : 0x0000000000000003 $x19 : 0x0000000000000004 $x29 : 0xffffff00000920b0 → 0xffffff00000920d0 → 0xffffff00000920f0 $x30 : 0xffffff000008c070 $sp : 0xffffff00000920b0 → 0xffffff00000920d0 → 0xffffff00000920f0 ──────────────────────────────────────────── stack ──── 0xffffff00000920b0│+0x0000: 0xffffff00000920d0 ─┐ # [#1] 0xffffff00000920b8│+0x0008: 0xffffff000008c070 │ 0xffffff00000920c0│+0x0010: 0x0000000000000005 │ 0xffffff00000920c8│+0x0018: 0x00000000ffffffc0 │ 0xffffff00000920d0│+0x0020: 0xffffff00000920f0 ◄┘ # [#2] 0xffffff00000920d8│+0x0028: 0xffffff000008c0d4 │ 0xffffff00000920e0│+0x0010: 0x0000000000000000 │ 0xffffff00000920e8│+0x0018: 0x00000000ffffffc0 │ 0xffffff00000920f0│+0x0020: 0x0000000000000000 ◄┘ # [#3] 0xffffff00000920f8│+0x0028: 0xffffff000008c018 ─────────────────────────────────────────── trace ──── [#0] 0xffffff000008c020 → stack_test() [#1] 0xffffff000008c070 → stack_test() [#2] 0xffffff000008c070 → stack_test() [#3] 0xffffff000008c0d4 → main() ────────────────────────────────────────────────────── 可以看到每次递归调用压栈4个64位字，分别是：上一层FP，LR，参数x和0x00000000ffffffc0。最后一个64位字用途未知。\n练习9-backtrace 提供read_fp()接口，我们知道fp永远指向父函数的fp，故递归调用即可。\n1 2 3 4 5 u64* fp = (u64*) *((u64*)read_fp()); // 双层指针，因为第一层是本函数 while(fp != 0) { printk(\u0026#34;LR %lx FP %lx Args %d %d %d %d %d\\n\u0026#34;, *(fp + 1), fp, *(fp - 2), *(fp - 1), *(fp), *(fp + 1), *(fp + 2)); //为什么5个参数是fp-2到fp+2？样例只包括一个参数，只要出现fp+2就能测试通过 fp = (u64*) *fp; //下一层 } 满分通过，懒得贴图了。\n看到大佬写的，瞬间不想写了，寄。 https://www.cnblogs.com/kangyupl/p/chcore_lab1.html\n","date":"2021-10-29T17:03:14Z","permalink":"https://lonelyuan.github.io/p/mospi-chcore-lab-1/","title":"MOSPI-ChCore lab (1)"},{"content":"众所周知，计网被评为最困的计算机专业课，俗称计算机中的语文。👴看了《计算机网络－自顶向下方法》（后文简称CNTDA）之后，觉得翻译就像汤姆叔叔的烂苹果派一样糟糕，上帝啊，我发誓会狠狠踢他的屁股。建议带🔥去看英文原版。\n但是👴最近接触的许多实验还是很好玩的，于是本文试图通过全程动手实操学习计网。\n主要工具：\nwireshark是坠nb的网络封包分析软件。就是用来抓包的。 下载：https://www.wireshark.org/download.html 教程：https://www.javatpoint.com/wireshark\nscapy库是python的网络编程库，可以让你细致入微的操纵网络流量。就是用来发包的。 //不要和爬虫库scrapy混淆 scapy文档：https://scapy.readthedocs.io/en/latest/ 中文版：https://www.osgeo.cn/scapy/introduction.html //有些翻译错误\n计网基本概念 💣包(package) 等等，啥是“抓包”？啥是“发包”？啥是“包”？\n当然，包不仅仅是一个 CSGO 术语，在计算机网络中，包(package)有多个近义词，包括：报文/数据报(Datagram)，分组/封包(Packet)……根据语境不同而区分，但大致指的是同一件事情：即网络中真正流动着的东西，我们希望网络来传递的东西。只不过“包”是最通俗的叫法，那么抓包和发包就不难理解了。\n你还想问，包到底长什么样？众所周知，快递由包装和里面的东西组成，其实网络上的封包也差不多，也大致都有两部分：\n包头，学名首部(Header)——快递包装上的标签，写着目的地址，联系电话，快递号等信息 包体，学名载荷(Payload)——快递要运输的货物本身。某些语境下也喜欢称为报文。 当然，网络封包归根结底还是线性的比特序列，于是我们需要包头来识别这个封包的相关信息，就像看快递先看标签一样。\n另外，一个协议的封包也可以成为另一个协议的载荷，后面你会看到诸如pkt.payload.payload.payload.payload的套娃用法，要理解这种套娃，还需要知道分层思想。\n🍰分层(layering) CNTDA 中用邮政系统类比计算机网络，这是最常用的例子，这里我们用快递物流网来举例。随便打开你的网购记录，你会发现快递物流大概经过以下过程：\n客户发货：把货物和地址交给快递点 快递网点揽件：包装货物而变成包裹；包裹被送往最近的中转中心 中转中心运输：根据包裹目的地不同，分拣并装车运输给不同的中转中心；若收到本片区的包裹，卸车并分拣给不同的网点 快递网点派送：按包裹的地址，快递员送货上门 客户取件：拆箱，拿到货物，确认无误签收 你知道发一个快递要经历怎样的困难吗？你不知道，你只关心你自己。这里的重点是，客户不需要关心中转中心如何指挥重型货车或飞机，网点也只需要关心如何包装好客户的货物。快递网络明显的呈现出三层的分层架构，每一层之间只需要关心自己的工作，并和相邻的层交互。这就是应对复杂系统的组织方法——分层。\n课本上会提到OSI七层模型或者TCP/IP五层模型，这里的模型全称是协议分层模型，又来新词了，别急，后面还有：\n协议(Protocol)：同一层级内的交互规则。//横向 服务(Service)：不同层级间的交互规则。//纵向 每一层的工作，就是调用下层的接口，并为上层提供服务。接口(Interface)和服务的区别是，服务作为实体，由本层负责实现，暴露出接口供上层调用；而接口则是抽象的，本层并不知道下一层的可靠性。\n由此你能否看出分层思想的优越性？每一层只关注自己的实现，于是大问题被分解成了小问题。好比一个总工作量100的问题，不了解分层思想的你只能10+10+10+……=100；而分层思想提供了乘法法则，于是你可以通过10*10=100，只需要完成20工作量。//个中思想也体现了OOP中的解耦。\n上述类比中标注了一些对应关系：\n封包(Packaging)：包装，货物→包裹。信息在层次间传递的过程就是封包/解封的过程。 路由(Routing)：分拣。根据包裹上的标签，决定包装的去向。 可以看到，每一层都有自己的“货物”，比如中转中心的载荷是满载包裹的长途货车而不是单个包裹。报文在每一层都被封装并交给下一层，要想得到原始报文只能一层一层解开，操作模式类似栈。由此协议分层模型也被简称为协议栈(Protocol stack)。\n最后简单解释五层模型每一层的分工，自底向上顺序：\n物理层：对接物理介质，运输比特 提供基于比特的通信路径 链路层：将路径串联成链 提供基于链路的接入、交付、和传输服务 网络层：将链路编织成网 提供任意两主机之间的通信 运输层：将主机的通信分解为进程的通信 提供进程间的逻辑通信 应用层：实现用户需求 向用户提供透明可靠的网络服务 偶剋！你已经了解了分层思想，下面来设计互联网吧！（迫真）\n⌚️开始实验 有关计网的学习顺序自古就有自顶向下还是自底向上的分歧，余以为只要理解了分层思想，顺序便不算很重要。本系列实验将遵从浅入深出的原则，从应用层逐步深入到链路层再返回应用层，同时难度不断加大。\n实验来源：\n👴自己：0x10, 0x20 SEEDLab，雪城大学的信息安全课配套实验，网络安全部分。国内知名度不高所以值得一做。官方网站 CNTDA 实验：GIthub上抄的作业 实验代码仓库：lonelyuan/ComputerNetwork-exp (github.com)\n实验编号规则：0xabn\na：层级：1 - 应用层；2 - 传输层；3 - 网络层；4 - 链路层；5 - 物理层 b：难度：0 - ⭐；1 - ⭐⭐；2 - ⭐⭐⭐；3 - ⭐⭐⭐⭐；4 - ⭐⭐⭐⭐⭐； n：重复难度则再加一位编号 //【想看哪个没更新的可以催👴】\n0x10 应用层: Server | ⭐ Intro 目标：用scapy/socket做一个静态服务器。\n实际上，python3已经自带了一个简易http服务器：\n1 2 3 $ python3 -m http.server Serving HTTP on 0.0.0.0 port 8000 (http://0.0.0.0:8000/) ... 127.0.0.1 - - [10/Nov/2021 14:51:57] \u0026#34;GET / HTTP/1.1\u0026#34; 200 - 浏览器访问：localhost:8000，如果当前目录下有index.html文件，浏览器即可显示该html文档。\n该http服务器也是基于另一个python标准库socket编写的，本实验我们直接用socket实现一个更简单的http服务器。\n前置：\n术语：\nC/S架构(client-server)：互联网的基本模型。通信的双方通常分成两个角色：\n发起的一方称为客户端(C)，即前端。 接收的一方称为服务端(C)，即后端。为了保证随时接收请求，服务端需要持久监听某通信端口 URL：统一资源标识符。也就是互联网上的地址，网址。\n完整语法：[协议名]://[用户名]:[密码]@[服务器地址]:[服务器端口号]/[路径]?[查询字符串]#[片段] HTTP协议：应用层最普遍的文本协议之一。文本协议表示其所有内容都是可读的，其主要格式如下：\n1 2 3 4 5 GET / HTTP/1.1\\r\\n /* 一个状态行 */ Host: localhost\\r\\n /* 多个首部行 */ ... Connection: close\\r\\n\\r\\n /* 以两个CRLF(回车换行，编程时用\\r\\n表示)隔断 */ \u0026lt;html\u0026gt;... \u0026lt;/html\u0026gt; /* payload */ HTML：标记语言，用\u0026lt;\u0026gt;组织起网页的骨架。浏览器会把HTML源码渲染成好看的网页。\nsocket：逻辑通信的端点。\nsocket是逻辑通信的接口。上文提到网络层为运输层和应用层提供了点到点的逻辑通信服务，该服务的基本接口就是socket。 socket是通信端点的抽象。它将进程/应用和(主机host,端口port) 二元组绑定，于是通过 (host,port) 即可标记网络上的进程。 一个主机有一个地址和多个端口。地址和端口的关系，就像房子和窗户的关系。 socket由操作系统提供。本实验用到的是python对socket的封装，但不管换什么语言本质上都是系统调用。 //其翻译“套接字”非常具有误导性，建议直接用英文单词。 建议花5分钟通读《图解HTTP》前6章（或者《CNTDA》2.1-2.2节），以理解上述术语\nGuidelines Socket通信 要使用socket通信，通信双方都需要持有一个socket对象，其主要方法和生命周期如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 SERVER CLIENT socket() socket() │ │ ▼ │ bind((host,port)) │ │ │ ▼ │ listen(num) │ │ │ ▼ ▼ accept() connect((host,port)) │ │ ├──►send()──►recv()◄──┤ │ │ ├──►recv()◄──send()◄──┤ │ │ ▼ ▼ close() close() 于是我们可以建立起服务器代码的框架：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 import socket s = socket.socket() s.bind((\u0026#39;0.0.0.0\u0026#39;, 8000)) # 绑定地址和端口 s.listen(5) # 开始监听，num表示最大连接数量 while True: c, addr = s.accept() # c是客户端socket print(\u0026#39;[+] accepted:\u0026#39;, addr) req = c.recv(1024) print(\u0026#39;[+] recieved:\u0026#39;, req.decode(\u0026#39;utf-8\u0026#39;)) # 接收类型为字节对象bytes，要打印则应当编码为字符串 res = http_handler(req) # 解析请求，返回响应 c.send(res) c.close() It\u0026rsquo;s worth noting that，服务端socket并没有发送任何数据！accept()方法将返回一个客户端socket对象，由这个socket执行数据的收发。这样做的原因是为了实现多路复用，即让服务器支持多个连接同时通信。 于是我们可以看到，对每个TCP连接，都有一对socket存在于通信的两端。而服务端socket仅仅做了管理连接的工作，他们放在一个类里，是出于简化代码的考虑。（当然实现多路复用的方式不只有一种。 现在，你可以自己尝试编写socket客户端跟该服务器进行明文的通信。不过我们的目标是HTTP服务器，先复习一下HTTP协议格式，状态码，首部等知识吧。\nHTTP解析 如果编程能力尚可，你可以自己写HTTP类来把报文解析成对象。这里还是用现成的，scapy库提供的HTTPRequest和HTTPResponse类。\n1 2 3 4 5 6 7 8 9 10 11 12 13 from scapy.layers.http import * from scapy.all import * def http_handler(req_str): req = HTTPRequest() req.do_dissect(req_str) # 解析请求 print(\u0026#39;[+] req: \u0026#39;, req.summary()) # body = route(req.Path.decode()) # 路由函数 body = \u0026#34;\u0026lt;h1\u0026gt;Hello~~~\u0026lt;/h1\u0026gt;\u0026#34; res = HTTPResponse() res = HTTP() / res / body print(\u0026#39;[+] res: \u0026#39;, res.summary()) return raw(res) do_dissect()方法将字符串解析为对象\nHTTP()/res/body：scapy核心语法/，表示协议栈的堆叠，可以链式调用。\n这里的类型为：HTTP / HTTPResponse / Raw，之所以要这样三层表示，是因为HTTPResponse/HTTPRequest类仅仅是一个中间层，如果没有HTTP层，scapy会报warning。\nraw()方法返回封包的字节数组，可以看到在socket之上，我们先把报文转化为对象，解析之后再返回报文。\n观察封包的常用方法还有：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 In [2]: a = Ether()/IP(dst=\u0026#34;www.wsnd.com\u0026#34;)/TCP() In [3]: a Out[3]: \u0026lt;Ether type=IPv4 |\u0026lt;IP frag=0 proto=tcp dst=Net(\u0026#34;www.wsnd.com/32\u0026#34;) |\u0026lt;TCP |\u0026gt;\u0026gt;\u0026gt; In [4]: a.summary() Out[4]: \u0026#39;Ether / IP / TCP 0.0.0.0:ftp_data \u0026gt; Net(\u0026#34;www.wsnd.com/32\u0026#34;):http S\u0026#39; In [5]: a.show() ###[ Ethernet ]### dst = ff:ff:ff:ff:ff:ff src = 00:00:00:00:00:00 type = IPv4 ###[ IP ]### version = 4 ... proto = tcp chksum = None src = 0.0.0.0 dst = Net(\u0026#34;www.wsnd.com/32\u0026#34;) \\options \\ ###[ TCP ]### sport = ftp_data dport = http ... In [6]: ls(a) dst : DestMACField = \u0026#39;ff:ff:ff:ff:ff:ff\u0026#39; (\u0026#39;None\u0026#39;) src : SourceMACField = \u0026#39;00:00:00:00:00:00\u0026#39; (\u0026#39;None\u0026#39;) type : XShortEnumField = 2048 (\u0026#39;36864\u0026#39;) ... In [7]: raw(a) Out[7]: b\u0026#39;\\xff\\xff\\xff\\xff\\xff\\xff\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00E\\x00\\x00(\\x00\\x01\\x00\\x00@\\x06\\xc9\\xa8\\x00\\x00\\x00\\x00H\\ti\\x1e\\x00\\x14\\x00P\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00P\\x02 \\x00\\xdeW\\x00\\x00\u0026#39; In [8]: hexdump(a) 0000 FF FF FF FF FF FF 00 00 00 00 00 00 08 00 45 00 ..............E. 0010 00 28 00 01 00 00 40 06 C9 A8 00 00 00 00 48 09 .(....@.......H. 0020 69 1E 00 14 00 50 00 00 00 00 00 00 00 00 50 02 i....P........P. 0030 20 00 DE 57 00 00 ..W.. 现在运行服务器，用浏览器访问localhost:8000，你可以看到大大的“Hello”了！\nTask 下面的任务交给你，目标是尽量接近python自带http服务器的表现。\n为了实现静态服务器，你需要根据访问的路径返回对应的内容。为此，请完善route()函数：\n访问根路径/将返回index.html 使用os模块读取文件，注意文本文件和二进制文件（如图片）的处理 用HTTP响应码进行错误处理，比如404 NOT FOUND，302 REDIRECT 最后，在根目录(你在哪里运行你的服务器脚本，那里就是你的根目录)下放入任意文件，浏览器都可以访问其内容，如果不存在则会返回404。\nExpand 抓包观察访问你的网站和访问正常网站有什么区别。你会发现，本实验几乎没有讲解HTTP首部的细节，请自行了解诸如Content-Type:，Content-Length:，Transfer-Encoding:等首部，看看传输图片/压缩文件时的标准做法，以及在遇到大文件时如何实现分段运输。（尽管我们的实现很简陋，浏览器还是能正常工作，说明HTTP是相当健壮的协议） 你的服务器是否有安全问题？你可以访问根目录之外的文件吗？如： /../../../../etc/passwd（linux下） 服务器概念辨析：Web初学者容易对服务器概念感到迷惑。软件语境下，服务器指对外提供服务的程序，常用服务器如apache、nginx，tomcat等；硬件语境下则指运行着服务器软件的机器。 我们实现的是静态网站，你可能疑惑是不是还有动态网站。当然有，区分动态和静态并不是网页会不会自己动，而是服务器上的数据是否可以动态的改变，而我们的服务器只能被动的显示文件，客户端无法做出任何更改。现代web框架诸如Springboot，Django之类当然是动态网站框架。 实际上，计网并不关心应用层以上的东西，让我们向下看，探究socket背后的原理吧。\n0x20 传输层：Socket | ⭐ Intro 目标：用 scapy 实现TCP协议，以尽可能替换上一个实验使用的socket模块 // 你可能猜到了，下一个实验是不是要自己实现IP协议呀？恭喜你猜错了。 前置： 术语 TCP/UDP TCP报文格式 有限状态机 完成本实验仅涉及《CNTDA》3.4-3.5节，如果理解有困难，建议先完成Wireshark 实验：TCP观察 在上一个实验中，我们了解到socket是操作系统提供的系统调用，例如 Linux 中，创建socket对象返回的sock_fd本质上就是一个文件描述符，即建立连接后可以直接像文件一样读写，绑定端口后操作系统会保护该端口不被其他进程占用。而本实验关注运输层原理，所以绕过了操作系统，使用更底层的接口实现TCP。当然，是最简陋的一种实现。 Guidelines Socket实现原理 那么，socket里面到底有什么？首先，要保存地址端口等信息；其次，要有收发的两个缓冲区，这里可以用队列；然后，为了实现可靠运输，需要用到计时器来触发重传，需要变量标记滑动窗口；我们还用自动机思想来管理连接状态。Socket底层模型如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 ┌─────Socket──────┐ ┌─────┐ │ ────────────┐ │ ┌────┐ │ ├──┼─► SendQ ├──┼─►│ │ │ │ │ ────────────┘ │ │ │ │ App │ │ Buffers │ │ IP │ │ │ │ ┌──────────── │ │ │ │ │◄─┼──┤ RecvQ ◄─┼──┤ │ └─────┘ │ └──────────── │ └────┘ ├────Variables────┤ │ Status │ │ Timer │ │ SendBase │ │ NextSeq │ └─────────────────┘ 这里就需要面向对象上场了\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 class Socket: def __init__(): self.SendQ = Queue() self.RecvQ = Queue() self.Status = Status.CLOSED self.Timer = Timer() self.SendBase = 0 self.NextSeq = 0 # SERVER def bind(addr): self.addr = addr pass def listen(num): pass def accept(): #return c, addr pass # CLIENT def connect(addr): pass # BOTH def recv(length): #return data pass def send(data): pass def close(): pass 下面逐个实现socket接口。\n定制TCP报文\n连接管理\n了解了三次握手，就可以实现connect函数了\nTask 多路复用 目前的实现只能支持一个TCP连接，请实现listen(num)函数，调用时创建 num 对读写缓冲区，响应的为\n完善TCP功能： RTT 可靠运输 流量控制 阻塞控制 拓展UDP到你的socket Expand 0x30 网络层: 路由追踪 | ⭐ Intro 术语：\nIP层：IP协议，ICMP协议，路由协议 路由追踪：请求某地址经过了那些路由器？ Guidelines scapy实现了路由追踪函数，你可以钻研一下源码（很短），下面写一个自己的traceroute。\nTask 下面用Ipython演示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 In [1]: from scapy.all import * In [2]: target=\u0026#34;www.amazon.com\u0026#34; In [3]: ans, unans = sr(IP(dst=target,ttl=(1,30))/TCP(flags=0x2)) Begin emission: Finished sending 30 packets. .*****..**********..........................................................................^C Received 92 packets, got 15 answers, remaining 15 packets In [4]: for snd, rcv in ans: ...: print(snd.ttl, rcv.src, isinstance(rcv.payload, TCP)) ...: 1 11.206.119.46 False 2 11.110.80.173 False 3 10.102.15.74 False 4 11.73.2.241 False 5 124.160.189.101 False 6 219.158.97.2 False 7 219.158.34.190 False 8 69.192.14.38 True 9 219.158.24.134 False 10 219.158.10.30 False 11 69.192.14.38 True 12 69.192.14.38 True 13 69.192.14.38 True 14 69.192.14.38 True 下面讲解核心代码：\nans,unans=sr(IP(dst=target,ttl=(1,30),id=RandShort())/TCP(flags=0x2))\nsr()：send and receive，返回的两个参数分别是得到应答的数据包列表和未应答的包列表。 ttl=(4,30)：ttl参数在IP层表示ICMP包的转发次数（跳数）。此外，传入tuple表示一个范围，sr函数将会为这个范围内的每个值生成一个发包。（如果有多个tuple参数，则会按笛卡尔积规则生成发包列表） TCP(flags=0x2)：在TCP头部设定flag字段的值，0x2对应ACK，即确认收到包。 综合起来，这条代码将发送30个包，其ttl从1到30。并筛选返回ACK的包。 这样根据IP层路由算法，到达ttl的包无论是否找到目标都会返回，直到找到目标，TCP层返回ACK。遍历ttl形成的列表即是经过的所有路由。 Expand 0x301 网络层: 欺骗ping | ⭐ | TODO Intro 来源：https://seedsecuritylabs.org/Labs_20.04/Files/ICMP_Redirect/ICMP_Redirect.pdf 术语： Guidelines Task Expand 0x41 链路层: ARP缓存投毒 | ⭐⭐ | TODO https://seedsecuritylabs.org/Labs_20.04/Files/ARP_Attack/ARP_Attack.pdf\n0x21 传输层: TCP攻击 | ⭐⭐ | TODO https://seedsecuritylabs.org/Labs_20.04/Files/TCP_Attacks/TCP_Attacks.pdf\nTCP协议 SYN泛洪 TCP reset TCP session hijacking反弹shell （重点）\n0x31 网络层: NAT，DHCP和虚拟机 | ⭐⭐ | TODO 相信折腾过虚拟机的同学都绕不过这个问题：我的虚拟机怎么连不上网？本实验基于wmware虚拟机平台，讲解几种虚拟机网络模式及其原理。\n0x13 应用层: DNS本地攻击 | ⭐⭐⭐ | TODO https://seedsecuritylabs.org/Labs_20.04/Files/DNS_Local/DNS_Local.pdf\n0x14 应用层: SSL协议和HTTPS | ⭐⭐⭐⭐ | TODO 0x15 应用层: 多线程Web代理服务器 | ⭐⭐⭐⭐⭐ | TODO 0x151 应用层: VPN | ⭐⭐⭐⭐⭐ | TODO 探究VPN原理\n0x152 应用层: V2Ray协议学习 | ？？？ | TODO 有生之年研究一下Vmess等协议\n","date":"2021-10-22T23:55:54Z","permalink":"https://lonelyuan.github.io/p/%E4%BB%8Escapy%E5%92%8Cwireshark%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","title":"从scapy和wireshark学计算机网络"},{"content":" 上回书说到，网站初具雏形，但经高人指点，还是有很多不足。 本文将大胆扩充网站结构，目标是将网站拓展成一个 CMS 。 所以，不要停下来啊！👆（指开发\n0x00 蓝图与重构 与之前相比，网站将增加以下功能：\n图库：文件上传模块 评论：楼中楼功能 后台：权限模块，后台模块 优化：更健壮的数据库接口，更细致的权限控制 plus功能：用 redis 实现热搜 在开发这些功能之前，首先重整项目结构。如：\n完全蓝图化。参考 模板也放入独立子目录里，蓝图注册时使用template_folder参数，不过这样容易产生bug，flask 官方推荐使用硬编码，汗。 清理依赖，不使用维护状态差的库。 开发新功能的时候，去哪里找最佳实践，找好用的库呢？有一个 Github 搜索小技巧，名为 \u0026ldquo;awesome-xxx\u0026rdquo; 的仓库通常是某技术的优质资源列表。如：https://github.com/humiaozuzu/awesome-flask 0x01 文件系统 本部分参考了李辉大佬的系列文章， https://zhuanlan.zhihu.com/p/23731819?refer=flask\n头像，照片……文件上传是绕不开的话题。在上一篇参考的教程中，头像的实现是由托管网站生成随机的图片。遗憾的是并没有像 ORM 一样方便数据库处理的文件处理框架可供使用，还是自己把他啃下来吧。\n注意踩坑！大部份资料推荐使用Flask_uploads插件，然而使用该插件时出现如下报错：\n1 ImportError: cannot import name \u0026#39;secure_filename\u0026#39; from \u0026#39;werkzeug\u0026#39; 查阅Stackoverflow得知是PYPI源上的Flask_uploads插件不再维护了，于是和 werkzeug 库的api不兼容，是插件内在的bug。网上的解决方法有二：\n一是修改库源码 二是换另一个库，维护良好且可无缝迁移，名为Flask-Reuploaded 前者不利于后续部署，本人倾向于后者。然而，使用新库也遇到了诸多麻烦，使用UploadSet.url()方法时，报错如下：\n1 werkzeug.routing.BuildError: Could not build url for endpoint \u0026#39;_uploads.uploaded_file\u0026#39; with values [\u0026#39;filename\u0026#39;, \u0026#39;setname\u0026#39;]. UploadSet.url()方法返回对应文件的可访问url，返回的url默认带有_upload/前缀，这是 Flask-Uploads 自带的路由，也被称为 autoserve 。 然而官方文档里有这样一句话\nautoserve of uploaded images now has been deactivated; this was a poorly documented “feature”, which even could have lead to unwanted data disclosure; if you want to activate the feature again, you need to set UPLOADS_AUTOSERVE=True\n看来 Flask-Reuploaded 的作者似乎认为文件读取功能与我无瓜。好吧，这部分我们自己实现。\n// 浪费了一晚上debug，结果只是因为文档没看明白，再次证明读文档的重要性。\nFlask-Reuploaded: 文件上传 插件将上传的一类文件抽象成集合UploadSet。对每个 Set 有如下操作：\n配置文件类型：photos = UploadSet('photos', IMAGES) //类型包括：IMAGES、TEXT、AUDIO…… 配置存贮路径：app.config['UPLOADED_PHOTOS_DEST'] // Photos 为 Set 的变量名 保存文件：filename = photos.save(request.files['photo']) 返回链接：photos.url(filename) 最后，注册 Set 和插件注册类似：configure_uploads(app, [avatars, photos]) //可一次性全部注册\n实现头像上传的步骤如下：\n模型层： User 添加 avatar 字段，储存头像的文件名。原avatar()方法作为默认头像。 表单层： edit_profile 表单增加FileField字段 视图层： 储存文件，向数据库提交文件名。 模板层： 改用硬路由获取url。// 最终 .url() 还是有bug，再次说明不要乱用不知名的插件 图库模块 本模块包括如下路由：\n/index：主页显示瀑布流 /upload：上传接口：参考头像上传 /detail：详情，显示评论 /delete：删除接口：同时删除文件 由于本项目前端框架是 Bootstrap ，👴不想写Jquery，所以直接刷新页面，也不弄无限滚动了，按钮了事。另外为了不同列长度尽量均匀，故采用取巧的方法，平均分配。根据大数定理，只要随机图片足够多肯定会差不多均匀。。。。\n0x02 评论系统 数据库设计 评论包含了两个一对多关系，既是评论和文章的一对多关系，也是评论和用户的一对多。为此，只需要给User和Post添加关系即可。 然而，我们希望设计统一的Comment模型，评论的对象既可以是文章，也可以是图片，也可以是其他评论。为此，添加一个枚举类型的字段指示评论类型，从而采用不同的处理逻辑。\n楼中楼 而主流网站不光支持对文章评论，还支持楼中楼。对楼中楼的实现有以下几种方案：\n按时间平铺：以原百度贴吧为例 添加 reply_id 字段，指示要回复的人 套娃式缩进：以某些老式bbs为例 添加 parent_id 字段，指示父评论（顶层评论则为本身id），在实体类中保存子评论列表 弹窗式查看：以知乎，b站为例 在按时间平铺的基础上，若 reply_id存在添加“查看对话”按钮，递归的构建对话并弹窗。 其中，第一种实现简单，用户不友好；第二种实现复杂，对多层级对话无法胜任；第三种是最主流的实现方式。\n通过以reply_id作为指针，所有评论连接成了一棵树，在任意一个节点进行“查看对话”操作，就是执行树的寻根。“查看对话”函数如下：\n1 2 3 4 5 6 7 8 9 @staticmethod def view_dialogue(c_id): dialogue = [c_id] while Comment.query.get(c_id).type == \u0026#39;comment\u0026#39;: c_id = Comment.query.get(c_id).reply_id if Comment.query.get(c_id) is None: break dialogue.append(c_id) return dialogue 0x03 网站后台 网站的后台通常给管理员提供统一监管数据库的界面。有以下插件帮助实现：\nFlask-admin：一键生成后台页面，并可以自定义视图和模型。 Flask-Security： 比admin层次更高，封装了常用视图和模板。但是文档少，且很多功能我们已经实现了，再使用它就要推翻重做。遂弃用。 本教程中使用了 RBAC（Role-Based Access Control) 基于角色的访问控制，简单说就是设计一个角色表，用户表和角色表用关联表实现多对多关联。这样做的好处是，针对角色的权限分配，修改权限时无需修改每个用户。\n0x04 热搜 本节再加入一个重量级内容，利用 redis 实现浏览量排行榜，也就是热搜。当然，真正的热搜榜单排名规则更加复杂，这里只通过简单的浏览量计数来练习 redis 的使用。\n【👴有时间再做】\n不要让开发停下来 可以加的功能还有很多：时间线，emoji支持，多媒体，前后端分离(Vue)，，\n除了功能，当面对更高量级的流量时，网站性能便更加重要，这时候消息队列，PRC，微服务/分布式，，，更让人头秃。\nWeb开发之路，道阻且长。但是，只要开发不停下来，道路就会不断延申。。。（希望之花.mp3）\n","date":"2021-09-16T12:43:23Z","permalink":"https://lonelyuan.github.io/p/%E5%B9%B4%E8%BD%BB%E4%BA%BA%E7%9A%84%E7%AC%AC%E4%BA%8C%E4%B8%AA%E7%BD%91%E7%AB%99%E4%BA%8C-flask-supreme-tutorial/","title":"年轻人的第二个网站（二） - flask-supreme-tutorial"},{"content":" 本文为 Flask 框架学习笔记，主要参考了 The-Flask-Mega-Tutorial 和 《Flask Web开发：基于Python的Web应用开发实战》两本书，并在原项目的基础上拓展。（下文统称这两个资源为“本教程”） 不熟悉 Flask 框架请先阅读快速上手 - flask 中文文档 。\n这两本书的作者是同一个人，就内容上说后者算是前者的豪华版。本教程的优点是内容全面，从入门到部署一站式服务；缺点是不够深入，且有些过时，书中举例的诸多插件均为作者为了此书而开发的，已经许久不再维护，导致很难在其示例项目上拓展。一看扉页，2015年出版，那没事了。 至于第一个网站？参见#TODO:年轻人的第一个网站\n0x00 大型项目结构 在大部分面向初学者的 demo 中，应用以简单的项目结构甚至单文件表示。在大型项目中，网站的不同功能被拆分成独立的模块，以方便拓展和维护。一个更通用的 Flask 项目代码架构如下：（仅考虑业务代码）\n1 2 3 4 5 6 7 8 9 10 microblog/ # 根目录 app/ # 项目源码 __init__.py # 项目初始化，当该包被import，首先执行__init__.py routes.py forms.py ... main.py # 框架入口 config.py # Config配置类 .flaskenv ... 根目录下的文件有：\napp/所有网站源代码统一归到app目录下。 在app/内部，不同的功能可进一步划分成独立模块，详见[模块化应用](#0x05 模块化应用：功能解耦)一章。 main.py: 入口脚本，通过该文件引入app中的代码并生成应用实例（命名随意） .flaskenv: flask环境变量，以配合flask命令。入口脚本被定义为FLASK_APP，执行flask run时将启动该脚本。 config.py: 配置脚本，整个项目的配置信息都写在Config类里。与环境变量的区别在于，因为是python脚本，功能更强大，可被任何地方的代码引用。 0x01 Hello world：模板和视图 最基本的 web 功能，无非接受请求、返回数据。其中，路由 (route) 用来区分不同的请求，模板 (templates) 用来生成不同的数据。\n路由/视图 在非前后端分离的项目中，视图函数直接返回渲染好的网页，由@app.route()修饰后，视图和路由便绑定在一起。 在mvc模型中更像controller控制器的角色，然而在flask生态中更喜欢称为视图函数。\nurl_for() 使用URL到视图函数的内部映射关系来生成URL，用来替换硬链接。在业务功能解耦后必须使用这种方式。 NOTE：当路由和视图函数名不一致，访问该路由可以正确响应，但是使用url_for()调用该视图时会报错 {% extends \u0026quot;base.html\u0026quot; %} and {% include \u0026quot;_post.html\u0026quot; %} 使用子模板来实现网页公用的部分。如：页眉，页脚，列表项等。 模板和 Python 代码的关系有些类似与 JSP 和 Java 代码的关系，但模板语法并不是完整的脚本语言，相较而言限制更多，安全性更好。 表单 几乎所有成功的框架都有丰富的插件生态。下面引入新功能时，大多借助插件来方便的实现。大多数Flask插件使用flask_\u0026lt;name\u0026gt; 命名约定。\nFlask-WTF插件提供了对Web表单的抽象，只需定义表单类以及设置类属性即可。\n模板语法：\n{{ form.\u0026lt;name\u0026gt;.label }}渲染标签 {{ form.\u0026lt;name\u0026gt;() }}获取属性值 form.hidden_tag()模板参数生成了一个隐藏字段，其中包含一个用于保护表单免受CSRF攻击的token 将表单引入模板\n1 2 form = LoginForm() # 生成了一个实例传入模板 return render_template(\u0026#39;login.html\u0026#39;, title=\u0026#39;Sign In\u0026#39;, form=form) flash 闪现消息 flash 通过 session 储存，用于显示只出现一次的提示消息。用法：\n在路由中使用flash()，触发时消息便写入 session 中的 message 列表 在模板中使用get_flashed_messages()，从 session 中读取 0x02 数据库 ORM 很久很久以前，web网站和数据库交互还需要写很多很硬的 SQL 语句，效率低且容易出现注入漏洞(SQLi)。现代web开发都使用 ORM 框架简化数据库交互，且基本杜绝了 SQLi 漏洞。\n本项目使用如下插件打通数据库：\nFlask-SQLAlchemy: Python生态最知名的ORM框架 Flask-Migrate: 本教程作者编写的数据库迁移框架 插件首先要注册。统一流程: 初始化app实例，传入插件类作为插件实例的参数\n1 2 3 4 5 # app/__init__.py app = Flask(__name__) # flask基类 app.config.from_object(Config) db = SQLAlchemy(app) migrate = Migrate(app, db) SQLalchemy：model层 模型定义 使用类和类属性代表 table 和 colunm ，便可轻松编写数据模型。SQLalchemy 的概念抽象如下图： Flask-SQLAlchemy 自动设置类名为小写来作为对应表的名称，也可以用__tablename__类属性来定义。\n1 2 3 class Post(db.Model): # 表 id = db.Column(db.Integer, primary_key=True) # 列 .... CURD基本操作 ORM 框架通常集成了常用操作，但也支持更底层的数据库接口。\n在 Springboot Jpa 中，根据方法名的拼写来写自定义查询，而在 SQLalchemy 中，提供的接口通过链式调用拼接。\n在 SQLalchemy 中，基本操作大都有基于事务 (session) 的和基于查询 (query) 的两种方式。\n查\n1 session.query(User) query方法只有构造一个查询，只有在Query.get()、Query.all()、Query.one()等结束符之后才会执行查询\n增：\n1 2 db.session.add(user) db.session.commit() 删\n1 2 3 4 session.query(User).delete() # or session.delete(session.query(User).get(1)) session.commit() 改\n1 2 3 4 5 6 7 8 9 query = (session .query(User) .filter_by(id=1) .update({\u0026#34;username\u0026#34;: User.username + \u0026#34;a\u0026#34;}, synchronize_session=False) ) # or user = (session.query(User).get(1)) user.password = \u0026#34;zxcv\u0026#34; session.commit() Flask-Migrate: 数据库迁移 配置数据库的初始数据框架，一般写成SQL脚本形式。 migrate 框架直接根据 model 层生成迁移脚本，可以方便的跟踪数据模型的修改和数据库的切换。（这个框架还是本教程作者自己开发的，强）\nflask db子命令\nflask db init：初始化，生成migrations目录 flask db migrate：生成迁移脚本，修改model后使其生效 flask db migrate -m \u0026quot;posts table\u0026quot; flask db upgrade：应用数据库修改（开发阶段默认使用sqlite数据库 flask db downgrade：回滚上次的迁移 0x03 开发范式：用户系统 mixin：混入，多重继承的一种形式\n表单和数据库支持分别解决了前端和后端的基本需求，下面可以上线一个基本功能了，用户登录。 所需插件：Flask-Login。\nUserMixin类 UserMixin类集成了login插件要求的用户模型属性，将其混入到 User 模型中，即可用@login_required 实现权限控制。\n1 2 @app.route(\u0026#39;/result/\u0026#39;, methods=[\u0026#39;POST\u0026#39;]) # NOTE：有顺序关系，反之则不生效 @login_required 用户系统，包括登录、登出、注册几个功能。编写这些功能的步骤其实很类似：\n设计数据库，在model.py中 设计表单对象，在form.py中 设计页面，在模板.html中 设计视图函数，在routes.py中 也对应了mvc框架的设计理念，比如设计表单就有些像 javaweb 中的 DAO 层。但也有区别， Flask 框架更希望业务逻辑写在数据库模型中，而视图函数尽量保持简洁，以方便单元测试。\nPRG 模式 即为 Post/Redirect/Get，其格式大概如下：\n1 2 3 4 5 6 7 8 9 @bp.route(\u0026#39;/some_form\u0026#39;, methods=[\u0026#39;GET\u0026#39;, \u0026#39;POST\u0026#39;]) def some_form(): # prepare forms if form.validate_on_submit(): # submit modification return redirect(url_for(\u0026#39;main.some_form\u0026#39;)) elif request.method == \u0026#39;GET\u0026#39;: # GET data return render_template(\u0026#39;some_form.html\u0026#39;, form=form) 默认情况，提交 POST 请求后，如果直接刷新浏览器，会重新在 POST 一次。使用PRG模式即可解决重复提交表单的问题。\n0x04 深入数据库：粉丝机制 数据库关系 要关注别人，就要让数据库记住我关注的人的名字，当然，只记住名字肯定不够，万一改名了呢。因此每个用户都需要有唯一有效的标识（其实更重要的是性能因素）。正因如此，数据库中每个表都要有一个唯一的列，称为主键(primary key)。当不同表之间存在关系，一个表要通过主键寻找其他表项，其他表的主键储存在本表中，称为外键(foreign key)。外键关联既可以表示一对一的关系，也可以一对多(1-\u0026gt;n)。\nSQLalchemy 对关系的定义如下：\n外键：db.ForeignKey('user.id') 关系：db.relationship('Post', backref='author', lazy='dynamic') 参数1：所关联的表(n in 1-\u0026gt;n)，这里是模型的变量名 参数2：由 \u0026ldquo;n\u0026rdquo; 回调 \u0026ldquo;1\u0026rdquo; 的虚拟字段，用法：post.author 粉丝机制 然而，粉丝机制包括关注和被关注。这是一种多对多的关系，于是需要用含有两个外键的关联表表示。又因为关注者和被关注者在一个表里（User），这种关系又称为自引用。\n模型 关联表只有引用类型，故不需要派生模型类\n1 2 3 4 5 followers = db.Table( \u0026#39;followers\u0026#39;, db.Column(\u0026#39;follower_id\u0026#39;, db.Integer, db.ForeignKey(\u0026#39;user.id\u0026#39;)), db.Column(\u0026#39;followed_id\u0026#39;, db.Integer, db.ForeignKey(\u0026#39;user.id\u0026#39;)) ) 为User添加关系\n1 2 3 4 5 followed = db.relationship(\u0026#39;User\u0026#39;, # 右侧实体 secondary=followers, # 指定关联表 primaryjoin=(followers.c.follower_id == id), # 指定左关系 secondaryjoin=(followers.c.followed_id == id), # 指定右关系 backref=db.backref(\u0026#39;followers\u0026#39;, lazy=\u0026#39;dynamic\u0026#39;), lazy=\u0026#39;dynamic\u0026#39;) # 指定回调 复杂查询 查询粉丝列表\nSQL 语句：SELECT * FROM user, followers WHERE followers.follower_id = 3 AND followers.followed_id = user.id\nSQLalchemy 接口：user.followers.all()\n实际执行的 SQL 语句：（打印 query 对象得到）\n1 2 SELECT ,,, FROM user, followers WHERE followers.followed_id = ? AND followers.follower_id = user.id NOTE：如果方法集成在model里，方法名不要和字段名相同，自己定义的方法会覆盖该字段。\n查看已关注用户的动态\nSQL 语句：SELECT * FROM post JOIN followers on followers.followed_id = post.user_id where followers.follower_id = 2\nSQLalchemy 接口：\n1 2 3 4 Post.query.join( followers, (followers.c.followed_id == Post.user_id)).filter( followers.c.follower_id == self.id).order_by( Post.timestamp.desc()) 实际执行的SQL语句：\n1 2 3 4 5 6 7 8 9 SELECT ,,, FROM (SELECT ,,, FROM post JOIN followers ON followers.followed_id = post.user_id WHERE followers.follower_id = ? UNION SELECT * FROM post WHERE post.user_id = ? ) AS anon_1 ORDER BY anon_1.post_timestamp DESC 由于python的弱类型特征，有时候很难明白函数之间传递的是什么对象。我们从上往下梳理一遍：\n请求到达路由函数，开始执行查询Post.query.....，此时只是在构造查询，并未取得数据，此时的对象类型：\u0026lt;class 'sqlalchemy.orm.query.Query'\u0026gt; 直到get(),all(),paginate().items结束符等出现，查询才被执行，返回数据类型实例，如User。 数据类实例传入模板，并由__str__等方法参与渲染。 0x05 网站美化 本教程提供的flask-bootstrap插件，较为简陋，且该插件年久失修，遂替换之。在此之前，先搞明白目前项目前端的架构\n1 2 3 4 5 6 7 /templates auth/ errors/ base.html _posts.html index.html ... 所有模板都有一个父模版：base.html，其结构如下：\n1 2 3 4 5 6 7 8 9 {% extends \u0026#39;bootstrap/base.html\u0026#39; %} {% block title %}Hallo Wolrd{% endblock %} {% block head %} ... {% endblock %} {% block scripts %} ... {% endblock %} {% block navbar %} ... {% endblock %} {% block content %} ... {% block app_content %}{% endblock %} {% endblock %} app_content留空，即其余模板均在app_content内填充。\n进一步追溯bootstrap/base.html的源码，发现其它 block 诸如navbar也都留空或仅仅配置了 Bootstrap 的 cdn。 由此，只需将base.html迁移即可。\n在网上寻找新的UI模板，不要在中文互联网搜索，basically garbage。找到一个 Meterial 模板 还算顺眼，遂用之。\n不熟悉 Bootstrap 布局的可以使用可视化工具来设计前端，如：http://www.ibootstrap.cn/\n对照模板，将base.html掏空，效果如下：\n遇到的bug有：\n下拉菜单失效：查询得知有可能是bootstrap版本冲突 //结果并不是，只是忘记引入js文件而已，我是傻逼。 文件上传按钮消失：本教程中，表单渲染采用wtf.quick_form()，这玩意还是来自bootstrap/wtf.html 最后决定整个🐏了 Flask-Bootstrap 插件。\n富文本编辑器 在《Flask Web开发：基于Python的Web应用开发实战》中提到了markdown编辑器的实现。\n需要的包：\nPageDown: JS 版 Markdown 渲染器，用于客户端预览。 Flask-PageDown: flask 集成插件。该插件需要注册 Markdown: Python 版 Markdown 渲染器，用于服务端渲染。 Bleach: HTML 清理器，保证安全性 为了兼顾安全和效率，做法是同时保存 markdown 源文本和 HTML 文件。步骤如下：\n表单改为 PageDownField 模板引入 PageDown 宏，以实现即时预览 为 Post 模型增加字段，并添加 markdown 渲染方法，该方法为类方法，需要@staticmethod修饰 在模型外部监听数据库事件，仅当 markdown 文本出现变动时调用渲染方法。 修改模板以显示服务端返回的 html 文本 然而预览器过于简陋，也很难修改。在github仓库上发现该插件也是本教程作者写的，已经很久没有维护。顿时对本书作者有些不满。\n0x06 模块化应用：功能解耦 保持 app 作为全局变量的模式，可能会给后续引入新功能和单元测试带来麻烦。 要适应大型项目需求，需要把网站功能拆分成独立的模块。\nBlueprint化 要实现解耦，一种功能的相关代码可以借助Blueprint归类到一个包里。其文件结构大致如下：\n1 2 3 4 5 6 7 app/ some_fuction/ \u0026lt;-- blueprint package __init__.py \u0026lt;-- blueprint creation ... other code ... templates/ some_fuction/ \u0026lt;-- templates __init__.py \u0026lt;-- blueprint registration 创建blueprint与创建应用非常相似。\n1 2 3 from flask import Blueprint bp = Blueprint(\u0026#39;func\u0026#39;, __name__) from app.func import Func 而消灭了app，蓝图内部的引用统一变成了蓝图名。而外部诸如url_for的参数则需要加上包名.做前缀。\n应用工厂模式 工厂函数是一个外部函数，在这个函数内部执行插件注册和配置工作，并通过他返回应用实例。\n1 2 3 4 5 6 7 8 # app/__init__.py db = SQLAlchemy() # ... def create_app(config_class=Config): app = Flask(__name__) app.config.from_object(config_class) db.init_app(app) # ... 返回后，flask提供的上下文对象current_app将指向应用实例。详见官方文档：应用上下文\n多线程 current_app是线程绑定的，若要在诸如邮件服务的位于其他线程的功能调用他，则会发现没有赋值。 需要使用current_app._get_current_object()表达式。\nPython概念辨析：包，库，插件 包 (package) 是指一种代码结构，只要有文件夹和 __init__.py 都是包。 库 (library) 和插件 (plugin) 都是从外部引入的包，区别在于，插件要集成进应用，所以需要注册等步骤；而库更独立，可以随时随地调用\n0x07 开发帮手 本节讲解一些杂项。\n调试 flask shell命令：为避免每次调试都要重新import app，使用上下文调用解释器，用@app.shell_context_processor装饰上下文函数 单元测试 unittest 库，详见下一篇。\n记录日志到文件 logger 库\n1 2 3 4 5 6 7 8 9 10 11 12 if not app.debug: if not os.path.exists(\u0026#39;logs\u0026#39;): os.mkdir(\u0026#39;logs\u0026#39;) file_handler = RotatingFileHandler(\u0026#39;logs/microblog.log\u0026#39;, maxBytes=10240, backupCount=10) file_handler.setFormatter(logging.Formatter( \u0026#39;%(asctime)s %(levelname)s: %(message)s [in %(pathname)s:%(lineno)d]\u0026#39;)) file_handler.setLevel(logging.INFO) app.logger.addHandler(file_handler) app.logger.setLevel(logging.INFO) app.logger.info(\u0026#39;Microblog startup\u0026#39;) requirement.txt 装的库太多怎么办？只需要两条命令：\n1 2 pip freeze \u0026gt; requirements.txt pip install -r requirements.txt 0x08 网站上线 最后简单列出几种网站部署的方法，详情参考本教程或自行搜索。\nnative模式 买主机 连主机：ssh 买域名 配域名 配环境 数据库 服务器 其他依赖 持续运维 容器化技术：docker 写dockerfile docker-compose up \u0026ndash;build -d 云技术：PaaS 注册云平台账户 写Procfile git push ","date":"2021-09-09T20:18:56Z","permalink":"https://lonelyuan.github.io/p/%E5%B9%B4%E8%BD%BB%E4%BA%BA%E7%9A%84%E7%AC%AC%E4%BA%8C%E4%B8%AA%E7%BD%91%E7%AB%99-the-flask-mega-tutorial/","title":"年轻人的第二个网站 - The Flask Mega Tutorial"},{"content":"🛁 这是👴第一次打高达80支队伍的大型AWD，👴此行的目标就是称霸酒店的游泳池。后来发现游泳池要钱，👴只能遗憾败北。（后来发现情报出了问题，根本不要钱，血亏）总的来说，酒店浴缸很带，主办方态度很好，赛场很清真，参赛体验很爽，赚了。\n“终端越炫，嗨客越带；嗨客越带，帽子越带”\n🐐AWD复盘 首先根据参赛手册，进行一个规则的复制：\n1 2 3 4 5 6 7 8 9 10 11 1、 采用线下赛的方式，参赛团队通过有线连接到局域网，并进行网络连通性的测试。请自备连接网络所需要的设备如usb转RJ45转换器等工具。 2、 攻防赛部署若干道赛题，初始分值为10500分。 3、 使用xctf用户通过ssh连接GameBox，GameBox的ip地址和登录密码通过赛事页面下载获取。 4、 比赛10分钟/回合，每个回合会更新GameBox上的flag。 5、 每个回合内，一个战队的一个服务被渗透攻击成功（被获取到flag并提交），则扣除10分，攻击成功的战队平分这些分数。 6、 每个回合内，服务宕机或无法通过check则会被扣除10分，服务正常的战队平分这些分数。 7、 参赛战队在修复漏洞时，请保持服务的正常功能和打印字符、界面样式，否则将无法通过系统check。 8、 每个回合内，服务异常和被拿flag可以同时发生，即战队在一个回合内单个服务可能会被扣除两者叠加的分数，最多扣除20分。 。。。 7、 请参赛战队在比赛开始时对所有服务进行备份，主办方仅提供2次重置机会，2次机会使用后不予重置。申请重置时请提供战队名称。 8、 禁止使用通用防御方法如waf等工具，违规者第一次被发现扣除当前分值的10%，第二次被发现扣除当前分值的50%，第三次被发现取消参赛资格并向其学校发文进行通报批评。 比赛全程收手机，断外网，不能用waf，不准用不死马，大家都很清真，找回了ctf最初的快乐。 然后按照AWD开局的任务清单，进行一个盘的复：\n准备阶段 ssh连接： 主办方提供了ssh密钥，和靶机ip 于是省略 ssh-copy-id -i ~/.ssh/id_rsa.pub root@xx.xx.xx.xx环节。 但是万能的Windows Terminal连不上去（依然不知道为啥），👴只能用图形化ssh客户端添加私钥连接。 IP扫描： 共有7道题，3道web，4道pwn，每道题目一个独立靶机，有独立的ip地址。不同靶机d段不同，不同队伍c段不同，按初赛排名分配。平台上告知了全部的ip列表。 于是省略nmap -sn xx.xx.xx.0/24环节。 选手机和靶机池在一个局域网内。不同队伍c段不同，一个队伍内的不同电脑d段不同。 流量监控： 主办方贴心的提供了被打流量(但是只有下行流量)，直接在~/package目录下给出.pcap文件。 于是省略tcpdump tcp -i eth0 -t -s 0 and dst port ! 22 and src net 192.168.1.0/24 -w ./target.cap环节。 (不过用户名叫xctf，权限卡的很死。不给流量的话估计也只能在站里上流量监控脚本) 更新速度很快，被打之后几乎可以立刻找到流量。于是手速很重要。 开局阶段 备份源码：tar -zcvf w.tar.gz /var/www/html 结果\u0026gt; Permission Denied，遂跳过 扫马删马：D盾 👴直接在图形化shell里下载代码，然后崩屎了几次，手速慢了。 每个web题都有一个不明小文件，显然是小马，删除之。 备份数据库：mysqldump -uctf -p --databases [dbname] \u0026gt; /tmp/db.sql 结果\u0026gt; Permission Denied，遂跳过 改数据库密码：mysql\u0026gt;SET PASSWORD FOR ctf@localhost=PASSWORD('newpass'); 结果\u0026gt; Permission Denied，(╯▔皿▔)╯玩nm 然后开始源码审计(❌) 然后等待被打之后翻流量(✔️) 攻防阶段 👴只看得懂web题目。三道web题全是cms，是经典lamp环境。可是👴看不懂cms，👴是five。\nweb1：safecms 比赛一开始，啪的一下很快啊，全场被打，翻流量抓到payload，是一个模板文件的任意读漏洞。直接批量拿flag。 定位到路由，注释之，不好使，还是被打；删除这个.class.php，不好使；👴怀疑是运行时缓存不更新，直接service restart apache2 结果\u0026gt;Permission Denied，👴佛了 就这样被打了好一会，才发现直接修改index.php，能直接生效，血亏。 web2：eyou 这道题被打的很少，被宕机的很多。抓流量，发现很多混淆流量。（日志写shell？） 👴跟着流量尝试用过滤的方法修复，但是还是被宕。 若干轮后，👴没办法，只好申请重置，并在下一轮被宕。 若干轮后，👴没办法，只好申请重置，并在这一轮被宕。 若干轮后，👴没办法，只好白给，并在某一轮恢复正常并坚持到最后。我？？？ 该不会是某队或者裁判看我们太可怜帮我们重置了吧，世界上还有这么温柔的人，我真的哭死 这道题无了。（赛后才知道，有队伍找到sqli并登录后台，在后台关闭了站点并羊了管理员账号。修nm。 web3：lol 这道题是最后三小时放的，👴这时候已经自闭了几个小时。于是👴痛定思痛，开局直接把admin.php羊了，然后奇迹般的守到了最后。坏了，好起来了。 全场被打，翻流量找到payload，某路径下有白给shell，直接删马并反打。 某队使用了在网页输出中塞随机字符串的防御方法，但是没破坏flag，且填充的字符是固定的，被我肉眼识破，我直接进行一个if ip == xx: flag = flag[12:]。虽然没什么卵用，但是很快乐。 pwn： 一看到4个pwn👴直接傻掉。👴觉得👴不会做，因此也没去看，但听大佬说，直接抓流量进行一个转发就能拿分，👴下次一定准备好pwntools。\n🔒自动化攻防框架 AWD中，手交flag实在是很浪费时间的行为。虽然有时候自动化不太好写只能手交，像这次十分钟一轮，有72支队伍，就算你手速惊奇，也没有时间审计源码了。因此打AWD重点就在一个自动化。网上能找到各种框架，但是用的时候总是不顺手，遇到bug也不会修。只有自己写的才最好用。\n先说说用处最大的工具，就是批量攻击框架/自动化攻击脚本。这个框架主要有以下要素：\n输入： 待攻击ip列表：通常写在ip.txt里 攻击函数：即封装好的payload请求 交flag函数：根据平台接口封装 输出： 批量攻击，输出攻击结果 攻击成功则提交 反馈得分结果 框架的核心无非以下逻辑：\n1 2 3 4 5 6 7 8 while True: for j in challenge_list: # 攻击函数索引 for i in ip_list: # 首先生成ip列表 flag = get_flag(i,j) # 根据j找到相应攻击函数 if flag!=\u0026#39;Attacked failed\u0026#39;: submit_flag(flag) print_result(j) time.sleep(round) 比赛时，找到漏洞或者抓到流量，立刻写好相应的攻击函数，重启脚本即可。\n为了提高稳定性和易用性，这套框架可以写的很复杂。比如：\n加入多线程，让框架非阻塞的持续运行 加入面向对象，写成类库 自带一些trick，比如流量混淆器等。 当然，还可以写一个网站来可视化管理 这里就涉及框架编程了，能深挖的地方还有很多。\n除了批量攻击脚本，用到的脚本还有：\n权限维持/批量shell脚本：用于管理多个shell 但是不死马被禁用，因此本次比赛中shell出现的不是很多。 （👴还准备了拿到白给shell之后持久化的脚本，结果一个shell都没拿到，准备个🔨。 文件监控脚本：用于监控flag等重要文件被读取和修改的准确时间，可以帮助确定payload 再牛逼一点还可以提供系统备份和回复功能。 上述都是系统脚本，大多在本机用python写的。下面说几种网页脚本，即直接用require/include包含的php脚本\n流量监控脚本：区别于系统级流量监控，用于监控敏感流量以抓取payload 通防脚本：也就是waf，可以进行很充分的过滤 本次比赛中被禁用，因为确实破坏游戏体验 这些脚本，用好了才是趁手的兵器。这次比赛中👴的手速远不够快，延误了很多战机。\n🌊快进到《考试周破防》 回顾整场比赛，相比正经的漏洞挖掘，随机应变的能力对分数也有很大影响。总结几个因素：\nawd的得分是随时间积累的，因此要掌控全局，时刻盯紧每道题有无薄弱环节和突破口。本次比赛题目数量多达7道，👴队有大佬没来，还带了一个萌新，约等于二打四，出现了看不过来题的情况。\n还有就是手速，由于流量很及时，payload一被抓到，甚至可以在一轮check之内丢进批量攻击脚本，直接和首先挖掘到漏洞的队伍平分分数。这要求自动化脚本的熟练运用，尽量避免手交flag。\n最后还有一点策略问题。分析三种题目状态，列个表定性分析一波最优解：\n能反打 不能反打 场上大多数Attacked 先反打再修洞 不能修洞则down自己 场上大多数CheckDown 打他喵的 尽量别down 出现漏洞大部分人会被打，这时如果你不能立刻修补而能立刻反打，相当程度上是不亏的。如果你修不好也可以选择宕机，因为这样分摊了丢掉的分数。 尽量避免被打+被宕，扣双倍分数属实是血亏。如果决定宕机，先摸清check的时间和结算的时间，最好在新一轮结算后立即删站down自己。 当然，如果您能挖到洞，宁就是垂直上分的👴。 从8点半到6点半，打10个小时的AWD，要全程保持敏感和机智，确实对身体素质有些要求。👴坐高铁到合肥坐了6小时，打比赛坐了10小时，好悬没给我痔疮坐出来。晚上回到青岛并进行最后一次夜店，快进到《考试周破防》。\n","date":"2021-06-16T16:54:30Z","image":"https://lonelyuan.github.io/p/ciscn2021%E5%8D%8E%E4%B8%9C%E7%99%BE%E8%B5%9B%E5%8C%BA%E5%88%86%E5%8C%BA%E9%80%89%E6%8B%94%E8%B5%9Bawd%E5%A4%8D%E7%9B%98/awd-da-pian_hub2213acc3516fead069948e4c2b6c9af_78570_120x120_fill_q75_box_smart1.jfif","permalink":"https://lonelyuan.github.io/p/ciscn2021%E5%8D%8E%E4%B8%9C%E7%99%BE%E8%B5%9B%E5%8C%BA%E5%88%86%E5%8C%BA%E9%80%89%E6%8B%94%E8%B5%9Bawd%E5%A4%8D%E7%9B%98/","title":"CISCN2021华东百赛区分区选拔赛AWD复盘"},{"content":" 本文所述为计算机组成原理课拓展实验的相关记录，基于“龙芯体系结构与CPU设计教学实验系统” 项目官网： http://www.loongson.cn/business/general/teach/356.html； 相关资料代码：#TODO:: github仓库 PS：标题可简记为《基于基于的一种基于的一种实现》\n🤓吐槽时间 快考试了，👴发觉👴计组学了个🔨，👴去年也学了个🔨，但是去年可以归因于晦气的晦气，今年只能说自己晦气。难道还要重蹈去年的晦气吗？👴本应该回去背课本，刷考研题，但是👴一看ppt就想起我们敬爱的《计算机组成原理》课的任课老师，丐哥反复强调的至理名言：“听不懂的举手（无停顿）都没举手，都听懂了，非常好。”本人十分钦佩丐哥老师对幽默感的独特理解。\n（但是特此声明：本人不了解、不认同其关于\u0026quot;5G是个几把\u0026quot;，\u0026ldquo;高晓松很nb这个人\u0026rdquo;，\u0026ldquo;钱=浪漫\u0026quot;等议题的看法）\n而且👴这人很怪，课本上的重点，不好玩；选做的实验，好玩！哎就是玩，怪不得卷不过别人，你也配卷？滚去考研吧。\n众所周知，计算机学生的本科生涯，如果能做到在自己设计的CPU上运行自己写的操作系统并用自己写的编译器跑代码，那就非常成功了。👴差不多，👴能在自己搜的代码上写自己的注释并用自己的电脑截图，都是三个\u0026quot;自己\u0026rdquo;。那么今天给大家爆个啥捏，流水线奥。\n🔧 “用”计算机→“造”计算机 上回书说到（#TODO:: CSAPP大篇），汇编器(as)让我们得到了机器能看懂的比特流，最后一步只需要连接器(ld)将其和其他调用一起载入内存。这回答了程序如何在CPU这个平台上运行的问题，然而一个更基本的问题是，这个现有的平台是如何实现的？一个粗略的认识是，我们知道这些足以实现CPU的复杂的逻辑，其最小单元总对应到简单的诸如逻辑门上面，但是落实到真正的物理实现之上，如何使效率最高？功耗最小？这些问题所跨越的复杂度的量级依然是一片巨大的迷雾。照亮这片迷雾的知识，大概隶属于IC学科。\nHowever，作为CS专业而不是IC专业，我们的目标仅在于理解所谓“组成原理”。在IC产业的复杂度规模数轴上，向下是专有芯片（又称嵌入式？），功能专用，规模较小；向上是通用芯片，即手机电脑等的核心，其难度不言而喻。位于中间的FPGA则既兼顾了自由度也考虑了速度，因此，这玩意能满足CS本科教学的需要（主要是便宜耐操）。\n🔮高贵的IC工程师都用啥轮子 Vivado是一个FPGA集成设计平台（也算一个EDA？），他主界面左侧的工作流窗口很好的概括了利用FPGA开发的基本流程。即\n编写设计源码(Source)：使用Verilog语言编写逻辑或引入IP 设计仿真模拟(Simulation)：通过观察仿真波形图和编写testbench来对设计进行debug 综合(Systhesis)门级网表：从RTL级描述降维到门级网表 生成(Implementation)布局布线：根据管脚约束，将依然是虚拟的门级连线落实为实际的线路 进行硬件编程(program)：生成比特流并写入目标设备 名词解释： IC：集成电路 FPGA：现场可编程门阵列 Verilog：一种硬件描述语言，语法涵盖了自顶向下五个抽象层面：系统级、算法级、RTL级、门级、开关级。 RTL：寄存器传输级。一般使用最多的就是RTL级。 IP：Intellectual Property内核模块，可以理解为将代码封装为函数。分为，软IP内核(soft IP core)，固IP内核(firm IP core)和硬IP内核(hard IP core)3个层次，相当于集成电路的毛坯、半成品和成品。 SoC：片上系统，大概是芯片及其装载的第一层软件接口的集合，很宽泛的概念。 EDA：电子设计自动化。\n由此，我们可以大致探清了这片迷雾，CPU的设计如何从高抽象层次的逻辑，梳理成最底层的逻辑门，再实现为小小的芯片。那么我们有了轮子，要造一个CPU，还要确定目标指令集。由于本项目由龙芯公司赞助，那必然要选MIPS了。\n📌MIPS指令集格式 啥叫指令集呢，学过几种语言就不难理解。高级程序语言规定每个ascii码的组合所对应的含义，指令集规定0和1的组合所对应的寄存器，ALU的各种信号。MIPS指令集从属于RISC系列，最基本的指令有31条。\n//讲到这里本应该打个表展示31条指令，但是👴懒得打了。\nVivado中，.coe文件用于初始化IP核，本实验给出的.coe文件中存放了几条指令，不过是16进制数字，写个小脚本打印成可读的形式。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 # mips_dump.py with open(path,\u0026#39;r\u0026#39;) as f: hex_list = f.read().split(\u0026#39;\\n\u0026#39;) bin_list = list(map(lambda x:bin(int(x,16)),hex_list)) # bin_code_list = [\u0026#34;{:0\u0026gt;32}\u0026#34;.format(i[2:],\u0026#39;b\u0026#39;) for i in bin_list] bin_code_list = [i[2:].zfill(32) for i in bin_list] IType_op_dict = { \u0026#39;001000\u0026#39;:\u0026#39;addi\u0026#39;, \u0026#39;001001\u0026#39;:\u0026#39;addiu\u0026#39;, \u0026#39;001100\u0026#39;:\u0026#39;ori\u0026#39;, \u0026#39;001101\u0026#39;:\u0026#39;xori\u0026#39;, \u0026#39;001111\u0026#39;:\u0026#39;lui\u0026#39;, \u0026#39;100011\u0026#39;:\u0026#39;lw\u0026#39;, \u0026#39;101011\u0026#39;:\u0026#39;sw\u0026#39;, \u0026#39;000100\u0026#39;:\u0026#39;beq\u0026#39;, \u0026#39;000101\u0026#39;:\u0026#39;bne\u0026#39;, \u0026#39;001010\u0026#39;:\u0026#39;slti\u0026#39;, \u0026#39;001011\u0026#39;:\u0026#39;sltiu\u0026#39; } RType_func_dict = { \u0026#39;100000\u0026#39;:\u0026#39;add\u0026#39;, \u0026#39;100001\u0026#39;:\u0026#39;addu\u0026#39;, \u0026#39;100010\u0026#39;:\u0026#39;sub\u0026#39;, \u0026#39;100011\u0026#39;:\u0026#39;subu\u0026#39;, \u0026#39;100100\u0026#39;:\u0026#39;and\u0026#39;, \u0026#39;100101\u0026#39;:\u0026#39;or\u0026#39;, \u0026#39;100110\u0026#39;:\u0026#39;xor\u0026#39;, \u0026#39;100111\u0026#39;:\u0026#39;nor\u0026#39;, \u0026#39;101010\u0026#39;:\u0026#39;slt\u0026#39;, \u0026#39;101011\u0026#39;:\u0026#39;sltu\u0026#39;, \u0026#39;000000\u0026#39;:\u0026#39;sll\u0026#39;, \u0026#39;000010\u0026#39;:\u0026#39;srl\u0026#39;, \u0026#39;000011\u0026#39;:\u0026#39;sra\u0026#39;, \u0026#39;000100\u0026#39;:\u0026#39;sllv\u0026#39;, \u0026#39;000110\u0026#39;:\u0026#39;srlv\u0026#39;, \u0026#39;000111\u0026#39;:\u0026#39;srav\u0026#39;, \u0026#39;001000\u0026#39;:\u0026#39;jr\u0026#39;, } def f_hex(ori, width): # bin-\u0026gt;hex return \u0026#34;0x\u0026#34;+hex(int(ori,2))[2:].zfill(width) def f_reg(ori): # print register num return \u0026#34;$\u0026#34;+str(int(ori,2)).zfill(2) def code_dump(type:str,inst:str,params:list): if type == \u0026#39;R\u0026#39;: s = inst.ljust(6) + \u0026#34;, \u0026#34;.join([f_reg(params[0]),f_reg(params[1]),f_reg(params[2]),f_hex(params[3],2)]) elif type == \u0026#39;I\u0026#39;: s = inst.ljust(6) + \u0026#34;, \u0026#34;.join([f_reg(params[0]),f_reg(params[1]),f_hex(params[2],8)]) else: s = inst.ljust(6) +\u0026#39;0x\u0026#39;+ hex(int(params[0],2))[2:].zfill(8) return s assembly_list = [] for _ in bin_code_list: op = _[:6] # public field try: if op == \u0026#39;000000\u0026#39;: # R-Type rs = _[6:11] rt = _[11:16] rd = _[16:21] shamt = _[21:26] func = _[26:] assembly_list.append(code_dump(\u0026#39;R\u0026#39;,RType_func_dict[func],[rs,rt,rd,shamt])) elif op in [\u0026#39;000010\u0026#39;, \u0026#39;000011\u0026#39;]: # J-Type target = _[6:] assembly_list.append(code_dump(\u0026#39;J\u0026#39;,\u0026#39;j\u0026#39;,[target])) else: # I-Type rs = _[6:12] rt = _[12:18] imm = _[18:] assembly_list.append(code_dump(\u0026#39;I\u0026#39;,IType_op_dict[op],[rs, rt, imm])) except Exception as e: assembly_list.append(\u0026#34;***** decode error! *****\u0026#34;) head = \u0026#34;+---hexdump----|--------- assembly ---------+\u0026#34; print(head) addr = 0 for i in range(len(bin_code_list)): print(\u0026#34;|\u0026#34;+ f_hex(bin(addr),2) +\u0026#34; \u0026#34;+ hex_list[i] +\u0026#34; | \u0026#34;+ assembly_list[i].ljust(26) + \u0026#34; |\u0026#34;) addr += 4 tail = \u0026#34;+\u0026#34;+\u0026#34;-\u0026#34;*43+\u0026#34;+\u0026#34; print(tail) 打印出来👴傻了，怎么还有不在31条范围里的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 +---hexdump----|--------- assembly ---------+ |0x00 24010001 | addiu $00, $04, 0x00000001 | |0x04 00011100 | sll $00, $01, $02, 0x04 | |0x08 00411821 | addu $02, $01, $03, 0x00 | |0x0c 00022082 | srl $00, $02, $04, 0x02 | |0x10 28990005 | slti $09, $36, 0x00000005 | |0x14 07210010 | ***** decode error! ***** | |0x18 00642823 | subu $03, $04, $05, 0x00 | |0x1c AC050014 | sw $00, $20, 0x00000014 | |0x20 00A23027 | nor $05, $02, $06, 0x00 | |0x24 00C33825 | or $06, $03, $07, 0x00 | |0x28 00E64026 | xor $07, $06, $08, 0x00 | |0x2c AC08001C | sw $00, $32, 0x0000001c | |0x30 11030002 | beq $16, $12, 0x00000002 | |0x34 00C7482A | slt $06, $07, $09, 0x00 | |0x38 24010008 | addiu $00, $04, 0x00000008 | |0x3c 8C2A0014 | lw $02, $40, 0x00000014 | |0x40 15450004 | bne $20, $20, 0x00000004 | |0x44 00415824 | and $02, $01, $11, 0x00 | |0x48 AC2B001C | sw $02, $44, 0x0000001c | |0x4c AC240010 | sw $02, $16, 0x00000010 | |0x50 0C000019 | j 0x00000019 | |0x54 3C0C000C | lui $00, $48, 0x0000000c | |0x58 004CD007 | srav $02, $12, $26, 0x00 | |0x5c 003AD804 | sllv $01, $26, $27, 0x00 | |0x60 0360F809 | ***** decode error! ***** | |0x64 A07A0005 | ***** decode error! ***** | |0x68 0063682B | sltu $03, $03, $13, 0x00 | |0x6c 1DA00003 | ***** decode error! ***** | |0x70 00867004 | sllv $04, $06, $14, 0x00 | |0x74 000E7883 | sra $00, $14, $15, 0x02 | |0x78 002F8006 | srlv $01, $15, $16, 0x00 | |0x7c 1A000008 | ***** decode error! ***** | |0x80 002F8007 | srav $01, $15, $16, 0x00 | |0x84 240B008C | addiu $00, $44, 0x0000008c | |0x88 06000006 | ***** decode error! ***** | |0x8c 8D5C0003 | lw $21, $48, 0x00000003 | |0x90 179D0007 | bne $57, $52, 0x00000007 | |0x94 A0AF0008 | ***** decode error! ***** | |0x98 80B20008 | ***** decode error! ***** | |0x9c 90B30008 | ***** decode error! ***** | |0xa0 2DF8FFFF | sltiu $31, $35, 0x00003fff | |0xa4 0185E825 | or $12, $05, $29, 0x00 | |0xa8 01600008 | jr $11, $00, $00, 0x00 | |0xac 31F4FFFF | ori $31, $19, 0x00003fff | |0xb0 35F5FFFF | xori $31, $23, 0x00003fff | |0xb4 39F6FFFF | ***** decode error! ***** | |0xb8 08000000 | j 0x00000000 | +-------------------------------------------+ 总之，代码都给你了，下面给出一个vivado实验的完整流程，不全面，但是都是踩坑经验。\n🆒Vivado使用 本流程环境：Vivado 2020.2\n开发板型号：LS-CPU-EXB-1\n创建项目 下一步，下一步，下一步，，，确认。 这一步只需要注意选器件，一定要选对。否则有可能在Implementation遇到“端口电平不匹配”“端口数量不足”等硬件问题。当然，有可能型号相近的性能规格也差不多，这属于玄学问题了。实验书上选择的的型号应该是“xc7a200tfbg676-2”，但是👴用的是“xc7a200tfbv676-2”也能成功写入比特流。\n编写代码并仿真 本实验的代码大多来自“2016-04-14”，那就是龙芯公司给的源代码。在该系列代码中有一处bug，位于“单周期CPU实验”的single_cycle_cpu.v中。214行，resetn应该为{4{resetn}}，写使能位宽应为为4。 下面讲解一下项目结构，所有实验都是类似的： 三个顶层文件夹分别对应Add Source里的三类源文件：添加设计，添加仿真，添加约束。如果不需要上板，只完成仿真，那么只需要添加设计（几个.v），添加仿真（testbench.v/tb.v）就足够了，xxx_display.v也是上板需要的故而可以忽略。（实际上，图中我用箭头标记的都用不到）。\n编写tb，无非是给tb里声明为input的信号赋值，还可以使用#xx，让tb等待一段时间。\n点击Run Simulation，等一会就能看到波形图。波形图有三种颜色：\n绿色代表信号正常正常； 红色的X代表信号不确定； 蓝色的Z代表信号休眠。 一般遇到红X，都是未初始化问题。蓝Z大概是没有模块调用这些信号。Vivado波形图的操作极其难用，这里介绍一个相对好用的操作：左键从左向右水平划，会直接缩放到鼠标滑过的这一段。右键选择进制等操作略。\n仿真需要注意的问题：\n如果文件没问题，模块调用层次会被自动解析从而呈现成一棵树，而不是好几个顶层文件。 注意set as top，应该设为根部模块（调用其他模块的）和tb //如果设错了可能在Implementation会出现“端口未赋初值”的报错。 中文乱码是经典字符集问题，有可能在换行处导致语法错误。建议统一换成utf-8。 简单解决方法：从vscode里复制。 引入IP核 对于流水线CPU，data_ram和inst_rom需要同步写，自己实现比较复杂，故直接实例化封装好的内存块IP。如何引入？首先说明几种文件格式：\n.dcp 原意为checkpoints文件，是一种加密压缩文件。用于封装模块方便调用，但对版本要求极其敏感。 .xci/.xcix IP核配置文件，本质是一个xml。是Vivado在新版本提倡使用xci而不是dcp。 .xdc 管脚约束文件。在Implementation用到，此处按下不表。 这几种文件格式都是可以直接Add Source添加进来的。实验老师同时提供dcp和xci文件，添加dcp崩屎了，原因估计如上。添加xci之后，提示我将IP更新为core cointainer的形式\n更新就完了。然后需要等一会，IP还要执行一步synth，这段时间里IP属于锁住的状态，不能修改配置。\n注意更换器件后，IP核都会锁住。这表示IP的配置和当前环境不匹配。对所有IP锁住的问题，只需要点击菜单栏Reports→Reports IP Status，然后点upgrade即可解除锁定。\n我直接上板 直接点生成比特流，会一步步的按工作流向下运行，等待几分钟就能愉快的收获你的报错了！\n在把上文提到的坑都踩过一遍之后，终于没有critical warning，泪目。\n但是此时实验课已经结束了，👴偷溜到没人的实验室，并留下以下珍贵画面\n然后👴发现data_ram写入失败。但是👴没时间搞了，👴还是滚去复习课本吧。\n🗿多周期流水线CPU原理 最后，继续复习计组。\n","date":"2021-06-09T17:14:19Z","image":"https://lonelyuan.github.io/p/%E5%9F%BA%E4%BA%8Evivado%E7%9A%84%E5%9F%BA%E4%BA%8Efpga%E7%9A%84%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8Emips%E7%9A%84%E4%B8%80%E7%A7%8D%E4%BA%94%E7%BA%A7%E6%B5%81%E6%B0%B4%E7%BA%BFcpu%E5%AE%9E%E7%8E%B0%E7%9A%84%E6%B3%A8%E9%87%8A/mips_pipeline_cpu_hu41671eab994e10b990ecc8a898c73896_308650_120x120_fill_q75_box_smart1.jfif","permalink":"https://lonelyuan.github.io/p/%E5%9F%BA%E4%BA%8Evivado%E7%9A%84%E5%9F%BA%E4%BA%8Efpga%E7%9A%84%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8Emips%E7%9A%84%E4%B8%80%E7%A7%8D%E4%BA%94%E7%BA%A7%E6%B5%81%E6%B0%B4%E7%BA%BFcpu%E5%AE%9E%E7%8E%B0%E7%9A%84%E6%B3%A8%E9%87%8A/","title":"基于vivado的基于FPGA的一种基于MIPS的一种五级流水线CPU实现的注释"},{"content":"// 笑死，根本赢不了。受不鸟，直接投降~\n0x01 | 拖延症的生理基础\n0x02 | 对拖延症的方法论综述\n0x03 | 西西弗斯计划\n","date":"2021-04-15T23:01:29Z","image":"https://lonelyuan.github.io/p/%E6%88%91%E5%92%8C%E6%8B%96%E5%BB%B6%E7%97%87%E7%9A%84%E6%88%98%E4%BA%89/ProcrastinationWar_hu0b75bf0afc945e74174c5a743bf06a5b_26480_120x120_fill_q75_box_smart1.jfif","permalink":"https://lonelyuan.github.io/p/%E6%88%91%E5%92%8C%E6%8B%96%E5%BB%B6%E7%97%87%E7%9A%84%E6%88%98%E4%BA%89/","title":"我和拖延症的战争"},{"content":"CSAPP：Bomblab 逆向的传统艺能拆炸弹，👴的青春回来了。\n文件结构：\n1 2 3 4 bomb ├── README ├── bomb └── bomb.c 只有一个程序，给的源码基本没用，我们要用逆向工程的方法理解程序，找到正确的字符串。\n讲反汇编器的结果导出：objdump -d bomb \u0026gt; bomb.txt\n可以看到有6关，每一关接受一个字符串，若跳转到explode_bomb函数，则答案错误。\n第一关：字符串比较 1 2 3 4 0000000000400ee0 \u0026lt;phase_1\u0026gt;: 400ee0:\t48 83 ec 08 sub $0x8,%rsp 400ee4:\tbe 00 24 40 00 mov $0x402400,%esi 400ee9:\te8 4a 04 00 00 callq 401338 \u0026lt;strings_not_equal\u0026gt; 逻辑是直接比较字符串是否相等，不过$0x402400不是程序内地址，说明答案被藏在了我们看不到的内存位置。\n于是上GDB，在\u0026lt;phase_1\u0026gt;下断点，stepi单步执行到callq之前，查看寄存器:x\\s $esi，得到答案。（每台电脑的答案都不一样）\n第二关：循环 1 2 3 4 5 6 0000000000400efc \u0026lt;phase_2\u0026gt;: 400efc:\t55 push %rbp //压栈 400efd:\t53 push %rbx 400efe:\t48 83 ec 28 sub $0x28,%rsp //开辟栈帧 400f02:\t48 89 e6 mov %rsp,%rsi//栈顶地址→rsi参数二 400f05:\te8 52 05 00 00 callq 40145c \u0026lt;read_six_numbers\u0026gt; 如函数名所示，读6个数字，为什么是6呢，大概是因为存放参数的寄存器总共有6个吧。（然而并不）\n可以看到调用前开辟了0x28的栈上空间，足够存放6个整数。栈顶地址被存入%rsi，以此传递该地址。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 000000000040145c \u0026lt;read_six_numbers\u0026gt;: //%rsi:父进程\u0026lt;phase_2\u0026gt;的栈顶地址 40145c:\t48 83 ec 18 sub $0x18,%rsp //栈帧长24 401460:\t48 89 f2 mov %rsi,%rdx //rsi→参数三：num1 401463:\t48 8d 4e 04 lea 0x4(%rsi),%rcx //rsi+4→参数四：num2 401467:\t48 8d 46 14 lea 0x14(%rsi),%rax //rsi+20→rax 40146b:\t48 89 44 24 08 mov %rax,0x8(%rsp) //rax→栈顶+8：num6 401470:\t48 8d 46 10 lea 0x10(%rsi),%rax //rsi+16→rax 401474:\t48 89 04 24 mov %rax,(%rsp) //rax→栈顶：num5 401478:\t4c 8d 4e 0c lea 0xc(%rsi),%r9 //rsi+12→参数六：num4 40147c:\t4c 8d 46 08 lea 0x8(%rsi),%r8 //rsi+8→参数五：num3 401480:\tbe c3 25 40 00 mov $0x4025c3,%esi//0x4025c3:\u0026#34;%d %d %d %d %d %d\u0026#34; 401485:\tb8 00 00 00 00 mov $0x0,%eax //返回值赋0 40148a:\te8 61 f7 ff ff callq 400bf0 \u0026lt;__isoc99_sscanf@plt\u0026gt; //sscanf() 40148f:\t83 f8 05 cmp $0x5,%eax //返回值和5比较，即输入6个值才能通过 401492:\t7f 05 jg 401499 \u0026lt;read_six_numbers+0x3d\u0026gt; 401494:\te8 a1 ff ff ff callq 40143a \u0026lt;explode_bomb\u0026gt; 401499:\t48 83 c4 18 add $0x18,%rsp //出栈 40149d:\tc3 retq 看\u0026lt;read_six_numbers\u0026gt;，%rsi中的地址以4为步长被分别储存。猜测sscanf函数的返回值中，第一个表示输入参数的个数；程序要求6个输入，加上rsi被占用，于是多的两个存入栈中。且sscanf函数的返回值按参数寄存器（多的地址在栈上）存放的地址传输，即输入值被按顺序存入phase_2的栈帧中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 400f0a:\t83 3c 24 01 cmpl $0x1,(%rsp) //栈顶位置取双字和1比较 400f0e:\t74 20 je 400f30 \u0026lt;phase_2+0x34\u0026gt; 400f10:\te8 25 05 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 400f17:\t8b 43 fc mov -0x4(%rbx),%eax //循环头：num1→eax 400f1a:\t01 c0 add %eax,%eax // eax*2 400f1c:\t39 03 cmp %eax,(%rbx) //和num2比较 400f1e:\t74 05 je 400f25 \u0026lt;phase_2+0x29\u0026gt; //相等才通过 400f20:\te8 15 05 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 400f25:\t48 83 c3 04 add $0x4,%rbx //rbx增4 400f29:\t48 39 eb cmp %rbp,%rbx //rbx和rsp+24比较，相等则跳出 400f2c:\t75 e9 jne 400f17 \u0026lt;phase_2+0x1b\u0026gt; //循环尾，循环共6轮 400f2e:\teb 0c jmp 400f3c \u0026lt;phase_2+0x40\u0026gt; 400f30:\t48 8d 5c 24 04 lea 0x4(%rsp),%rbx //num2地址→rbx 400f35:\t48 8d 6c 24 18 lea 0x18(%rsp),%rbp//rbx地址→rbp 400f3a:\teb db jmp 400f17 \u0026lt;phase_2+0x1b\u0026gt; //开始循环 跳出\u0026lt;read_six_numbers\u0026gt;后，首先检查栈顶地址指向的值是否为1，即第一个数字是1。\n之后进入循环，循环体每次都会把当前数字*2和下一个数字比较，即每个数字都是前一个的二倍；%rbx作计数变量，共循环6次。答案呼之欲出。\n第三关：分支 1 2 3 4 5 6 7 8 9 10 11 12 13 14 0000000000400f43 \u0026lt;phase_3\u0026gt;: 400f43:\t48 83 ec 18 sub $0x18,%rsp 400f47:\t48 8d 4c 24 0c lea 0xc(%rsp),%rcx //rsp+12→rcx: mun2 400f4c:\t48 8d 54 24 08 lea 0x8(%rsp),%rdx //rsp+8→rdx: mun1 400f51:\tbe cf 25 40 00 mov $0x4025cf,%esi //0x4025cf: \u0026#34;%d %d\u0026#34; 400f56:\tb8 00 00 00 00 mov $0x0,%eax 400f5b:\te8 90 fc ff ff callq 400bf0 \u0026lt;__isoc99_sscanf@plt\u0026gt; 400f60:\t83 f8 01 cmp $0x1,%eax //不少于一个输入 400f63:\t7f 05 jg 400f6a \u0026lt;phase_3+0x27\u0026gt; 400f65:\te8 d0 04 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 400f6a:\t83 7c 24 08 07 cmpl $0x7,0x8(%rsp) // 400f6f:\t77 3c ja 400fad \u0026lt;phase_3+0x6a\u0026gt; //超过7则爆炸 400f71:\t8b 44 24 08 mov 0x8(%rsp),%eax //取num1 400f75:\tff 24 c5 70 24 40 00 jmpq *0x402470(,%rax,8) 此处*相当于c中的取地址符\u0026amp;，\n1 2 3 400f7c:\tb8 cf 00 00 00 mov $0xcf,%eax 400f81:\teb 3b jmp 400fbe \u0026lt;phase_3+0x7b\u0026gt; ······ 这里有7段形式重复的代码，结合第一个数字不能大于7，猜测这里是switch型结构。\n1 2 3 4 5 6 7 8 9 400fad:\te8 88 04 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 400fb2:\tb8 00 00 00 00 mov $0x0,%eax 400fb7:\teb 05 jmp 400fbe \u0026lt;phase_3+0x7b\u0026gt; 400fb9:\tb8 37 01 00 00 mov $0x137,%eax 400fbe:\t3b 44 24 0c cmp 0xc(%rsp),%eax //比较num2和eax 400fc2:\t74 05 je 400fc9 \u0026lt;phase_3+0x86\u0026gt; 400fc4:\te8 71 04 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 400fc9:\t48 83 c4 18 add $0x18,%rsp 400fcd:\tc3 retq 第二个数字是%eax的值，由第一个数决定。故答案有7个。\n第四关：递归 1 2 3 4 5 6 7 8 9 10 11 000000000040100c \u0026lt;phase_4\u0026gt;: ...... 401029:\t83 f8 02 cmp $0x2,%eax //只能有2参数 40102c:\t75 07 jne 401035 \u0026lt;phase_4+0x29\u0026gt; 40102e:\t83 7c 24 08 0e cmpl $0xe,0x8(%rsp) //0 \u0026lt;= num1 \u0026lt;= 14 401033:\t76 05 jbe 40103a \u0026lt;phase_4+0x2e\u0026gt; 401035:\te8 00 04 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 40103a:\tba 0e 00 00 00 mov $0xe,%edx 40103f:\tbe 00 00 00 00 mov $0x0,%esi 401044:\t8b 7c 24 08 mov 0x8(%rsp),%edi //num1→edi 401048:\te8 81 ff ff ff callq 400fce \u0026lt;func4\u0026gt; // 输入规则和上一关一样，第一个数需在0到14之间（cmpl只能用于无符号数？）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 0000000000400fce \u0026lt;func4\u0026gt;: //首次调用时：%eax:0x2 %ebx:0 %ecx:0 %edx:0xe %esi:0x0 %edi:num1 400fce:\t48 83 ec 08 sub $0x8,%rsp 400fd2:\t89 d0 mov %edx,%eax //eax:14 400fd4:\t29 f0 sub %esi,%eax //eax:14-0 400fd6:\t89 c1 mov %eax,%ecx //ecx:14 400fd8:\tc1 e9 1f shr $0x1f,%ecx //ecx:0 //逻辑右移31，即取符号位。 400fdb:\t01 c8 add %ecx,%eax //eax:14+0 400fdd:\td1 f8 sar %eax //算术右移1位？eax:14/2=7 400fdf:\t8d 0c 30 lea (%rax,%rsi,1),%ecx //ecx:7+0 400fe2:\t39 f9 cmp %edi,%ecx //比较num1和7 400fe4:\t7e 0c jle 400ff2 \u0026lt;func4+0x24\u0026gt; //不大于→r17 400fe6:\t8d 51 ff lea -0x1(%rcx),%edx //edx:ecx-1=6 400fe9:\te8 e0 ff ff ff callq 400fce \u0026lt;func4\u0026gt; //递归→r3 400fee:\t01 c0 add %eax,%eax 400ff0:\teb 15 jmp 401007 \u0026lt;func4+0x39\u0026gt; //跳出 400ff2:\tb8 00 00 00 00 mov $0x0,%eax 400ff7:\t39 f9 cmp %edi,%ecx //比较num1和7 400ff9:\t7d 0c jge 401007 \u0026lt;func4+0x39\u0026gt; //不小于 400ffb:\t8d 71 01 lea 0x1(%rcx),%esi //esi:ecx+1=8 400ffe:\te8 cb ff ff ff callq 400fce \u0026lt;func4\u0026gt; //递归→r3 401003:\t8d 44 00 01 lea 0x1(%rax,%rax,1),%eax //eax=2*eax+1 401007:\t48 83 c4 08 add $0x8,%rsp 40100b:\tc3 retq 前面一通算术操作，后面设计了递归。\n这里一步移位操作看起来像是取符号位，但是输入一定大于0，符号位是0，所以这个操作意义何在？\n人肉IDA走起：\n1 2 3 4 5 6 7 8 9 int fun4(int num1,int x,int y){ int s,a; s=(x-y)/2+y; if(num1\u0026gt;s)\treturn 2*fun4(num1,s-1,y); a=0; if(num1\u0026lt;s)\treturn 2*fun4(num1,x,s+1)+1; return a; } fun4(num1,14,0); 第一个数设为7可避免递归调用，但返回值不是0，不符合。\n1 2 3 4 5 6 7 40104d:\t85 c0 test %eax,%eax //eax=0 40104f:\t75 07 jne 401058 \u0026lt;phase_4+0x4c\u0026gt;//不等于0爆炸 401051:\t83 7c 24 0c 00 cmpl $0x0,0xc(%rsp) //mun2和0比较？ 401056:\t74 05 je 40105d \u0026lt;phase_4+0x51\u0026gt;//不等于0爆炸 401058:\te8 dd 03 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 40105d:\t48 83 c4 18 add $0x18,%rsp 401061:\tc3 retq 看到的返回值和num2皆需为0，则num2确定。\n大不了爆破呗，索性试了1次就成了。emm\n【后面三关施工中。。。】\n第五关 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 0000000000401062 \u0026lt;phase_5\u0026gt;: 401062:\t53 push %rbx 401063:\t48 83 ec 20 sub $0x20,%rsp 401067:\t48 89 fb mov %rdi,%rbx 40106a:\t64 48 8b 04 25 28 00 mov %fs:0x28,%rax //??? 401073:\t48 89 44 24 18 mov %rax,0x18(%rsp) 401078:\t31 c0 xor %eax,%eax //eax:0 40107a:\te8 9c 02 00 00 callq 40131b \u0026lt;string_length\u0026gt; 40107f:\t83 f8 06 cmp $0x6,%eax //输入长度为6 401082:\t74 4e je 4010d2 \u0026lt;phase_5+0x70\u0026gt; 401084:\te8 b1 03 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 401089:\teb 47 jmp 4010d2 \u0026lt;phase_5+0x70\u0026gt; 40108b:\t0f b6 0c 03 movzbl (%rbx,%rax,1),%ecx //循环头。新指令 40108f:\t88 0c 24 mov %cl,(%rsp) 401092:\t48 8b 14 24 mov (%rsp),%rdx 401096:\t83 e2 0f and $0xf,%edx 401099:\t0f b6 92 b0 24 40 00 movzbl 0x4024b0(%rdx),%edx //？？？ 4010a0:\t88 54 04 10 mov %dl,0x10(%rsp,%rax,1) 4010a4:\t48 83 c0 01 add $0x1,%rax //计数变量rax 4010a8:\t48 83 f8 06 cmp $0x6,%rax //循环6轮 4010ac:\t75 dd jne 40108b \u0026lt;phase_5+0x29\u0026gt; //循环尾 4010ae:\tc6 44 24 16 00 movb $0x0,0x16(%rsp) 4010b3:\tbe 5e 24 40 00 mov $0x40245e,%esi //？？ 4010b8:\t48 8d 7c 24 10 lea 0x10(%rsp),%rdi 4010bd:\te8 76 02 00 00 callq 401338 \u0026lt;strings_not_equal\u0026gt; 4010c2:\t85 c0 test %eax,%eax 4010c4:\t74 13 je 4010d9 \u0026lt;phase_5+0x77\u0026gt; 4010c6:\te8 6f 03 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 4010cb:\t0f 1f 44 00 00 nopl 0x0(%rax,%rax,1) //？？？ 4010d0:\teb 07 jmp 4010d9 \u0026lt;phase_5+0x77\u0026gt;//跳出 4010d2:\tb8 00 00 00 00 mov $0x0,%eax 4010d7:\teb b2 jmp 40108b \u0026lt;phase_5+0x29\u0026gt; 4010d9:\t48 8b 44 24 18 mov 0x18(%rsp),%rax 4010de:\t64 48 33 04 25 28 00 xor %fs:0x28,%rax //？？？ 4010e7:\t74 05 je 4010ee \u0026lt;phase_5+0x8c\u0026gt; 4010e9:\te8 42 fa ff ff callq 400b30 \u0026lt;__stack_chk_fail@plt\u0026gt; 4010ee:\t48 83 c4 20 add $0x20,%rsp 4010f2:\t5b pop %rbx 4010f3:\tc3 retq 第六关 隐藏关 隐藏关藏在每一关的后面，\nGDB使用： 基础：\n1 2 3 4 5 q : quit h : help file prog//加载程序，也可作为gdb命令的参数 r : run k : kill 断点：\n1 2 3 4 5 6 7 8 9 10 b : breakpoints break - func_name - *0x400522 - \u0026amp;var - main.c:100//源代码断点，运行前即可 - if con//条件断点 w : watch //观察对象变化时断点 d : delete - b n disable b n 执行：\n1 2 3 4 5 6 c : continue f : finish stepi n nexti set args ./a.txt //从文件读取输入 检查代码：\n1 2 3 4 5 6 disas //展示汇编 - funcname - 0x400000 - list edit 检查数据：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 x : examine p : print 格式控制：/[n][f][u] - n:内存单元个数 - f:显示格式： - x(hex) 按十六进制格式显示变量。 - d(decimal) 按十进制格式显示变量。 - u(unsigned decimal) 按十进制格式显示无符号整型。 - o(octal) 按八进制格式显示变量。 - t(binary) 按二进制格式显示变量。 - a(address) 按十六进制格式显示变量。 - c(char) 按字符格式显示变量。 - f(float) 按浮点数格式显示变量 - u:单元长度（按字节） i : info - r : registers - b [n] - $rsp 表达式：\n堆栈：\n1 bt : backtrace//显示堆栈 ","date":"2020-02-27T22:43:31Z","permalink":"https://lonelyuan.github.io/p/csapp-bomblab/","title":"CSAPP - Bomblab"},{"content":"第一个lab，关于位运算。通过受限制的c语言编程实现函数功能。这些函数都是非常基本的功能，正如书名《CS:APP》所示，启发我们从程序员视角理解计算机的深层更深层。\nREADME中说明了项目结构。直接读bits.c，只需要填充其中的函数。每次测试程序都要先make一下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 //1 /* * bitXor - x^y using only ~ and \u0026amp; * Example: bitXor(4, 5) = 1 * Legal ops: ~ \u0026amp; * Max ops: 14 * Rating: 1 */ int bitXor(int x, int y) { // x^y // = (~x\u0026amp;y)|(x\u0026amp;~y) // 异或公式 // = ~(~(~x\u0026amp;y)\u0026amp;~(x\u0026amp;~y)) // 德摩根律，ops: 8 // = ~((x|~y)\u0026amp;(~x|y)) // 德摩根律 // = ~(x\u0026amp;~x|x\u0026amp;y|y\u0026amp;~y|~x\u0026amp;~y) // 分配律 // = ~(x\u0026amp;y|~x\u0026amp;~y) // 吸收率 return ~(x\u0026amp;y)\u0026amp;~(~x\u0026amp;~y); // 德摩根律，ops: 7 } /* * tmin - return minimum two\u0026#39;s complement integer * Legal ops: ! ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 4 * Rating: 1 */ int tmin(void) { // For negative numbers: complement = inverse + 1 return 1 \u0026lt;\u0026lt; 31; // tmin=0x80, tmax=0x7f // 为什么是补码？ // 为了方便计算机处理，我们希望负数和其相反数相加之后自然的溢出得0。 // x+~x=1, 再加1则溢出得0。因此补码=反码+1。 // 同时符号位天然的蕴含在最高位上，这有许多好处。 // 其一是正数的表现和无符号整数一致。 // 其二是由于＋0和-0一致，相比显式符号位能多表示一个数字，范围是[-2^(n-1),2^(n-1)-1] } //2 /* * isTmax - returns 1 if x is the maximum, two\u0026#39;s complement number, * and 0 otherwise * Legal ops: ! ~ \u0026amp; ^ | + * Max ops: 10 * Rating: 1 */ int isTmax(int x) { // ! 逻辑取反，仅全0返回1，其余情况都返回0 // ~ 按位取反 // 补码相反数 = 反码 + 1 // 两个特例：~tmin+1=tmin; ~0+1=0. 相反数为自身 // 得到几个函数： // negate(x) (~x+1) // 取相反数 // iszero(x) (!!x) // 仅当!!0=0 // equal(x,y) !(x^y) // 判断相等 // ~tmax=tmin, 转换为筛选tmin和0xff // 因此答案为 equal(~x,negate(~x)) \u0026amp; iszero(~x) return !((x+1)^(~x)) \u0026amp; (!!~x); // ops: 8 } /* * allOddBits - return 1 if all odd-numbered bits in word set to 1 * where bits are numbered from 0 (least significant) to 31 (most significant) * Examples allOddBits(0xFFFFFFFD) = 0, allOddBits(0xAAAAAAAA) = 1 * Legal ops: ! ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 12 * Rating: 2 */ int allOddBits(int x) { // 掩码: x \u0026amp; 0b1111, 结果相当于只取了x的后4位 // 奇数位全为1，使用掩码0xAAAAAAAA提取奇数位，再使用equal(x,0xAAAAAAAA)判断即可 int mask = 0xAA; mask += mask \u0026lt;\u0026lt; 8; mask += mask \u0026lt;\u0026lt; 16; return !(x\u0026amp;mask ^ mask); // ops: 7 } /* * negate - return -x * Example: negate(1) = -1. * Legal ops: ! ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 5 * Rating: 2 */ int negate(int x) { return ~x+1; } //3 /* * isAsciiDigit - return 1 if 0x30 \u0026lt;= x \u0026lt;= 0x39 (ASCII codes for characters \u0026#39;0\u0026#39; to \u0026#39;9\u0026#39;) * Example: isAsciiDigit(0x35) = 1. * isAsciiDigit(0x3a) = 0. * isAsciiDigit(0x05) = 0. * Legal ops: ! ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 15 * Rating: 3 */ int isAsciiDigit(int x) { // x \u0026gt; y // =\u0026gt; x+(~y+1) \u0026gt; 0 // x+(-y)\u0026gt;0 // =\u0026gt; !(x+(~y+1) \u0026gt;\u0026gt; 31) // 使用符号位判断\u0026gt;0 // 得到比较函数： // gpos(x, y) !(x+(~y+1) \u0026gt;\u0026gt; 31) // 带入即可 !((0x39 + ~x+1)\u0026gt;\u0026gt;31) \u0026amp; !((x + ~0x30+1)\u0026gt;\u0026gt;31) // ops: 11 return !((~x+0x3A)\u0026gt;\u0026gt;31) \u0026amp; !((x + ~0x30+1)\u0026gt;\u0026gt;31); // ops: 10 } /* * conditional - same as x ? y : z * Example: conditional(2,4,5) = 4 * Legal ops: ! ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 16 * Rating: 3 */ int conditional(int x, int y, int z) { // 或运算两侧不同时为1即可构成条件判断，使用掩码控制输出内容 // 错误做法： // int mask = x \u0026gt;\u0026gt; 31; // 算数右移取符号位填充全部位 // x ? y : z 对x是逻辑判断不是算术判断 int mask= ~!x+1; // 仅0返回1 return (~mask\u0026amp;y)|(mask\u0026amp;z) ; // ops: 7 } /* * isLessOrEqual - if x \u0026lt;= y then return 1, else return 0 * Example: isLessOrEqual(4,5) = 1. * Legal ops: ! ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 24 * Rating: 3 */ int isLessOrEqual(int x, int y) { // gpos(x, y) 在跨符号的情况下失灵，增加两种情况判断: // 1. x=y：返回1 // 2. x和y不同符号：x为负时一定小于，返回1，x符号位也是1 // 因此答案为 equal(signx,signy) ? (gpos(y,x) | equal(x,y)) : signx int signx=!!(x\u0026gt;\u0026gt;31), signy=!!(y\u0026gt;\u0026gt;31); int mask = (signx^signy); return (!mask \u0026amp; (!(y+(~x+1)\u0026gt;\u0026gt;31)) | !((x)^(y))) | (mask\u0026amp;signx); // ops: 19 } //4 /* * logicalNeg - implement the ! operator, using all of * the legal operators except ! * Examples: logicalNeg(3) = 0, logicalNeg(0) = 1 * Legal ops: ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 12 * Rating: 4 */ int logicalNeg(int x) { // 仅0返回1，其余返回0 // 还是借助两个特例：~tmin+1=tmin; ~0+1=0. 相反数为自身 // 答案为 equal(x,~x+1) \u0026amp; !equal(x,tmin) // !(x^0) \u0026amp; !!(x^(1\u0026lt;\u0026lt;31)) return !((x^0) | !(x^(1\u0026lt;\u0026lt;31))); // ops: 6 } /* howManyBits - return the minimum number of bits required to represent x in * two\u0026#39;s complement * Examples: howManyBits(12) = 5 // [-16,15] * howManyBits(298) = 10 // [-512,511] * howManyBits(-5) = 4 // [-8,7] * howManyBits(0) = 1 * howManyBits(-1) = 1 // [-1,0] * howManyBits(0x80000000) = 32 * Legal ops: ! ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 90 * Rating: 4 */ int howManyBits(int x) { // 负数取反，统一处理 // x\u0026gt;\u0026gt;31 ? ~x:x = x\u0026gt;\u0026gt;31 \u0026amp; ~x | ~(x\u0026gt;\u0026gt;31) \u0026amp; x x = x\u0026gt;\u0026gt;31^x; // 位宽取决于最高位，问题转化为寻找最高位 // 90个操作符不足以遍历32个位，因此需要优化搜索算法，如二分。 // !!(x\u0026gt;\u0026gt;16) 判断x的高16位是否存在1 int b16 = !!(x\u0026gt;\u0026gt;16) \u0026lt;\u0026lt; 4; // 若存在，至少需要16位，因此b16赋值为16或0 x = x \u0026gt;\u0026gt; b16; // 通过移位实现二分搜索： // 若高位存在则舍弃低位，高位全0则判断低位 int b8 = !!(x\u0026gt;\u0026gt;8) \u0026lt;\u0026lt; 3; x = x \u0026gt;\u0026gt; b8; int b4 = !!(x\u0026gt;\u0026gt;4) \u0026lt;\u0026lt; 2; x = x \u0026gt;\u0026gt; b4; int b2 = !!(x\u0026gt;\u0026gt;2) \u0026lt;\u0026lt; 1; x = x \u0026gt;\u0026gt; b2; int b1 = !!(x\u0026gt;\u0026gt;1); x = x \u0026gt;\u0026gt; b1; return b16+b8+b4+b2+b1+x+1; } //float /* * floatScale2 - Return bit-level equivalent of expression 2*f for * floating point argument f. * Both the argument and result are passed as unsigned int\u0026#39;s, but * they are to be interpreted as the bit-level representation of * single-precision floating point values. * When argument is NaN, return argument * Legal ops: Any integer/unsigned operations incl. ||, \u0026amp;\u0026amp;. also if, while * Max ops: 30 * Rating: 4 */ unsigned floatScale2(unsigned uf) { unsigned s = uf \u0026amp; (1 \u0026lt;\u0026lt; 31); unsigned exp = (uf \u0026amp; 0x7f800000) \u0026gt;\u0026gt; 23; unsigned frac = uf \u0026amp; (~0xff800000); if (exp == 0) return frac \u0026lt;\u0026lt; 1 | s; // 非规格数乘2即可 if (exp == 255) return uf; // 特殊值直接返回 exp++; if (exp == 255) return 0x7f800000 | s; // 乘法不可能得到NaN，所以返回无穷 return s | (exp \u0026lt;\u0026lt; 23) | frac; } /* * floatFloat2Int - Return bit-level equivalent of expression (int) f * for floating point argument f. * Argument is passed as unsigned int, but * it is to be interpreted as the bit-level representation of a * single-precision floating point value. * Anything out of range (including NaN and infinity) should return * 0x80000000u. * Legal ops: Any integer/unsigned operations incl. ||, \u0026amp;\u0026amp;. also if, while * Max ops: 30 * Rating: 4 */ int floatFloat2Int(unsigned uf) { unsigned s = uf \u0026amp; (1 \u0026lt;\u0026lt; 31); unsigned exp = (uf \u0026amp; 0x7f800000) \u0026gt;\u0026gt; 23; unsigned frac = uf \u0026amp; (~0xff800000); int E = exp - 127; if (exp == 255 || E \u0026gt; 31) return 0x80000000; // 特殊值 if (E \u0026lt; 0) return 0; // 小数舍入为0 unsigned M = frac | (1 \u0026lt;\u0026lt; 23); // 1 + frac int V = (E \u0026gt; 23 ? M \u0026lt;\u0026lt; (E - 23) : M \u0026gt;\u0026gt; (23 - E)); // M已经被左移了23位 if (s) V *= -1; // 负数 return V; } /* * floatPower2 - Return bit-level equivalent of the expression 2.0^x * (2.0 raised to the power x) for any 32-bit integer x. * * The unsigned value that is returned should have the identical bit * representation as the single-precision floating-point number 2.0^x. * If the result is too small to be represented as a denorm, return * 0. If too large, return +INF. * * Legal ops: Any integer/unsigned operations incl. ||, \u0026amp;\u0026amp;. Also if, while * Max ops: 30 * Rating: 4 */ unsigned floatPower2(int x) { // V = (-1)^s * M * 2^E // E = e-127 E∈[-126,127] // s=0,f=0, x带入E即可得到 2^x // 为此，反演从E求e的过程 if (x \u0026gt;= 128) return 0x7f800000; // +INF if (x \u0026gt;= -126) return (x + 127) \u0026lt;\u0026lt; 23; // [-126,127]: 2^x为规格数, f=1.0, e=x+127 if (x \u0026gt;= -150) return 1 \u0026lt;\u0026lt; (x + 150); // [-150,-125]: 2^x为非规格数, f=2^(x+150), e=0 else return 0; // too small } 太史公曰：前面几个考察int的题目层层深入，从掩码思想到条件判断，每个新题目都可以用到前面题目的思路。只有howManyBits需要想到如何用移位构造迭代，有一定的难度。相比而言最后的浮点数题目由于放开了诸多限制，变成了一般的编程题，只需要熟练掌握浮点数规则即可作答。\n","date":"2020-01-21T00:00:03Z","permalink":"https://lonelyuan.github.io/p/csapp-datalab/","title":"CSAPP - Datalab"},{"content":"那个男孩不想玩人工智能呢？在玄学修bug之后，我终于跑通了jetbot自带的深度学习demo。\n怎样才能让ai程序发挥好的效果呢？众所周知，所谓人工智能，有多少人工就有多智能。\nAI的发展离不开三个要素：算力，算法和算材。根据摩尔定律，算力的发展是不会停滞的（虽然定律快失效了）；进几年来的AI热正是算法的突破，即深度学习相关算法的突飞猛进；而算材就是用来训练模型的数据，未来几年AI应用的进一步落地离不开算材的进一步开发（中国在AI方面的最大优势正在于此）。数据集的丰富程度和有效程度直接影响了AI应用的效果，我将在下文详细说明。\n在jetbot项目中，我们也能体验到用“人工”换“智能”的快乐。作为视觉识别类的AI应用，我们要在预设环境里创建数据集，并为其标注。有了数据集，jetbot搭载的NVIDIA牌GPU在方寸之间就能完成海量计算，仅用一颗摄像头就能实现自动避障，目标追踪，自动巡线等等炫酷功能！不要1999，也不要999，只要99！99刀NVIDIA计算卡带回家！（妮维雅打钱）\n给萌新理清几个概念：\n人工智能，机器学习，深度学习的关系：\n深度学习：一种实现机器学习的技术；机器学习：一种实现人工智能的方法 【包含关系图】 AI的发展路径：\n弱AI：单独领域工作效率超过人类→ 通用AI：可以广泛应用于大部分领域→ 强AI：有自主意识，即将灭绝人类（不是）→ 现在AI发展到什么地步了：弱AI，有生之年可能见到通用AI\n推荐一波汉化的很好的wiki，也有自己原创的内容：http://www.waveshare.net/wiki/JetBot_AI_Kit\n本篇详细介绍两个demo的代码和可能遇到的问题，最后附上神经网络的入门笔记。同样是初次接触，大佬请绕道。\ndemo1：自动避障 小车如何实现自动避障的呢？用通俗的不能再通俗的说法，AI程序通过学习你给他的数据集，知道了什么样的图像是死路，什么样的图像是通路。得到新图像时就能判断是死路的概率有多少，在程序里可以很简单的看出，当这个概率大于0.5的时候就触发小车转向。\n具体而言，你要在你的环境里拍至少200张照片，100张标记为通路（free），100张标记为死路（blocked）。这便是你的数据集（dataset）。构建数据集的时候尽量分散在环境的各个位置和各个方向，可以沿边界环绕一圈，走一段距离停下，转一圈，收集8-10张图片。反正你的数据越多，标记的越准确，模型效果越好。\n下一步就开始训练模型了，从代码里看出，这个demo使用AlexNet模型，用pytorch实现（废话）。第一次运行你会下载一个244M左右的大文件，在/home/jetbot/.torch/models目录下会看到这个.pth文件。这便是AlexNet了。\n继续运行程序，完整的输出结果有三十行，每行后面的小数代表当前模型的准确度（？），程序最后会从这30个模型中选取准确度最高的作为最终模型，也是一个pth文件：best_model.pth\n下载文件和训练模型都需要花挺长时间，看到kernel busy，也就是右上角的大黑点不要轻易打断。\n什么是模型呢？稍微解释一下机器学习的概念。\n模型就是函数，其要素为输入，输出，和变换关系。举例说明：\n模型 输入 输出 细菌向养分移动 外界环境的化学信号 催动鞭毛的电信号 学生参加高考 试卷反射的光信号 试卷上问题的答案 小车自动避障 摄像头传输图像信号 前方被堵塞的概率 实际上，知识的本质也是函数，生命延续的关键就在于该生命的模型是否适应环境。这里不深入解释了，觉得惊奇请参阅Yjango的频道https://space.bilibili.com/344849038他用机器学习的角度解释生物进化，非常颠覆三观。\n总之训练出来的模型就是这样一个函数。其输入为经过处理的摄像头的图形信号，输出一个0-1的数，越接近1越意味着模型认为小车要撞墙了。但是当他大于0.5的时候就会触发转向，也就实现了自动避障。\nAlexNet是2012年提出的一种卷积神经网络（即CNN）算法。首次实现gpu加速。\n主流深度学习框架：TensorFlow；PyTorch；Keras\n还挺好玩的😀\ndemo2：目标追踪 基于上一个demo，我们还要下载一个模型，coco数据集神经网络，可以检测90种不同的物体。按教程把.engine文件下载到指定位置，顺着跑就完事了。（引入模型也要花挺长时间）\n如果有数据集里的物品，从输出里能看到蓝框标出，小车会自动转向物体，同时还保留了自动避障的程序。\n遇到bug：程序仅能读取一张图像进行识别，摄像头更新的功能无法执行。\n修bug：摄像头问题 描述：摄像头只要调用了一次，后面就无法在其他地方调用。直接在jupyter上关闭输出并没有作用。而且只要在一个notebook里就能重复调用，换一个就不行。而且并没有报错信息，程序一直处在busy状态。\n找到源码，在jetbot/jetbot/camera.py，但是所有样例里面调用摄像头都是用的Camera.instance()方法，而这个instance是在traitlets库里的，于是找到trailets官方文档\nTraitlets是一个纯 python 库，支持：\n对 python 对象属性的强类型实施( 类型属性称为 \u0026ldquo;特征\u0026rdquo; ) ； 动态计算的默认值； 当尝试改变时，自动验证和强制特征属性； 当特征值改变时注册接收通知； 从文件或者 命令行 参数中读取值- 在traitlets上不同层，因这里可以在没有配置机器的情况下使用 traitlets。 Traitlets支持IPython和Jupyter的配置系统，以及IPython交互小部件的声明性 API。\nipython是一个 python 的交互式 shell，比默认的python shell 好用得多，支持变量自动补全，自动缩进，支持 bash shell 命令，内置了许多很有用的功能和函数。其中就包括traitlets库。\nhttps://traitlets.readthedocs.io/en/stable/config.html 在这里找到instance的功能：返回现有的类，如果没有就新建一个。\n下面是样例中调用摄像头的代码：\n1 2 3 4 5 6 7 8 import ipywidgets.widgets as widgets #图像模块 from IPython.display import display #ipy的显示模块 import traitlets from jetbot import Camera, bgr8_to_jpeg #摄像头驱动，图像格式转换 camera = Camera.instance(width=500, height=500)#初始化摄像头对象 image = widgets.Image(format=\u0026#39;jpeg\u0026#39;, width=400, height=400)#创建图像 camera_link = traitlets.dlink((camera, \u0026#39;value\u0026#39;), (image, \u0026#39;value\u0026#39;), transform=bgr8_to_jpeg) #连接摄像头到图像 display(image) #显示图像 尝试从camera.py里调用原始api。得到报错：Each object must be HasTraits, not \u0026lt;class 'NoneType'\u0026gt;，是说必须为对象指定类型。那么HasTraits这个类型是啥？文档说:任何具有trait属性的类都必须从 HasTraits 继承。\n再次梳理调用摄像头的流程：\n引入模型：model.load_state_dict(torch.load('best_model.pth')) 连接摄像头：见上文 模型执行： 1 2 3 4 def update(): ...#此处为模型执行函数，将输入图像预处理后，执行模型 update({\u0026#39;new\u0026#39;: camera.value}) #初始化该函数 camera.observe(update, names=\u0026#39;value\u0026#39;) #将update函数设为camera.value的observer 研究一下observe用法：当对象发生变化时调用函数。\nhttps://traitlets.readthedocs.io/en/stable/using_traitlets.html#validation\n执行如下代码：\n1 2 3 4 5 6 7 8 9 10 import ipywidgets.widgets as widgets #图像模块 from IPython.display import display #ipy的显示模块 import traitlets from jetbot import Camera, bgr8_to_jpeg #摄像头驱动，图像格式转换 camera = Camera.instance(width=500, height=500)#初始化摄像头对象 def update(change): x = change[\u0026#39;new\u0026#39;] display(x) #显示图像 update({\u0026#39;new\u0026#39;: camera.value}) camera.observe(update, names=\u0026#39;value\u0026#39;) 输出一大堆数组，说明camera.value是这一大堆像素。而且observe正常运行，数据一直冒出。\n1 2 3 4 5 6 7 8 9 10 11 12 array([[[122, 116, 130], [126, 113, 127], [125, 117, 129], ..., [ 84, 96, 107], [ 82, 96, 113], [ 93, 93, 113]], [[120, 119, 130], [122, 120, 119], [118, 123, 130], ..., 然而就是不实时更新数据，卒。\n👴佛了。\n","date":"2019-10-01T00:26:38Z","permalink":"https://lonelyuan.github.io/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8jetbot%E6%99%BA%E8%83%BD%E5%B0%8F%E8%BD%A6%E5%B0%9D%E9%B2%9C%E4%BA%8C/","title":"深度学习入门——jetbot智能小车尝鲜（二）"},{"content":"那个男孩不想玩树莓派呢？机缘巧合之下，我得到了一台价值上百美元的智能小车的使用权。\n小车的核心是NVIDIA家的jetson-nano开发板，这款19年三月才发布的微型AI计算机可谓是平民级核弹，四核A57的CPU，128核心Maxwell架构的GPU，4g内存，支持4k视频解码，而且这只五脏俱全的麻雀只需要5W的电源支持，任何一支充电宝都可以胜任。而它的定位是用它简单的搭建人工智能应用，非常的amazing。\n本文的目的,不完全是新手教程,还有自己学习过程的记录和分享.初次接触,多有疏漏,欢迎指教.\n【图片：主板证件照】\n给萌新理清几个概念：\n单片机：Single-Chip Microcomputer。\n树莓派：一款著名的微型电脑品牌（本文介绍的jetson-nano可以理解为是树莓派的竞品，相比树莓派，这款单片机价格更高，性能更好，主打AI应用）\njetbot：以jetson-nano为平台搭建的ai机器人应用，也就是所谓智能小车\n硬件组装:积木和电工 本人拿到的是零件状态的小车，所以首先讲一讲组装的问题。有关具体步骤，官网教程十分详细，贴个连接给懒人吧：https://www.ncnynl.com/archives/201904/2927.html\n这里只讲一讲我作为初学者的一些理解。首先，玩单片机和玩积木的区别就在于编程。当然，入门单片机还需要其他技能。比如，电工技能：你需要进行线材的简单加工，引脚的焊接，准备基本的工具就好，毕竟那个男孩没有一根热热的棒子呢（指电烙铁）。然后，各个部件的拼接固定需要一些做手工的技巧，这个也不用怕，赫鲁晓夫曾经说过：热熔胶可以让我们创造奇迹。\n在这个层面上，初学者会浪费许多耗材，这是必要的练习手段，所以初学者也可以从最简单的芯片入手。同时你还要学习诊断硬件方面的问题，万用表会很有帮助。关于更详细的工具和耗材的需要，请自行查阅单片机入门有关资料。\n在本项目中，焊接工作已经完成，剩下的连接都是可插拔式的。我们只需要两把螺丝刀即可完成组装。即便如此，本人还是花了一晚上才把小车点亮，原因是我得到的线材损坏近半，只得自己寻找和修理。\n下面分析一下小车的结构:\njetson-nano开发板:即本机的主板,可以看到有两层芯片,上层为核心层,包括cpu,gpu和内存可以像笔记本内存条一样拆卸;下层为主板,用于连接各种设备 intel无线网卡:将上层拆下即可安装.令连出两根天线,缠绕机身即可. PiOLED显示器和拓展版:连接在I2C主线上 相机模块:官方样例展示了只用一个摄像头通过深度学习进行自动避障的demo. 马达和其驱动板:下文重点讲解 开发板就可以运行一个完整的Ubuntu系统,其余设备是为其拓展功能的.\n硬件架构：驱动芯片和I2C主线 我在玩小车的过程中耽误最长时间的就是电机（即马达）驱动了，借此讲一讲系统架构的事。\n让轮子前进要靠马达，给马达供电不能直接让主板来做，要让主板给另一块小芯片发送指令，这块小芯片连接着独立的电源，收到指令才会给马达通电。这块小芯片即是电机驱动板。\n驱动芯片是从硬件走向软件的第一道桥梁，可以类比PC的IO设备来理解。和物理世界交互的各种功能，都需要有专门的驱动芯片。包括马达，摄像头，扬声器，机械臂等等，只不过有的可以集成在一起，如：小车上的摄像头，PiOLED显示器等；有的出于体积，安全性，模块化的考虑需要分开，如电机和驱动板。\n电机驱动板 官方给出的电机驱动板型号为:DC-Stepper-Motor PCA9685+TB6612.可以驱动两个步进电机或四个直流电机。（四轴飞行器gkd）本项目只用到了两个直流电机。\n各个引脚的讲解：https://learn.adafruit.com/adafruit-stepper-dc-motor-featherwing/pinouts\n电机驱动板上共连接有10根跳线。一对电源输入，两对为马达输出。还需四根母-母杜邦线来连接至主板的I2C总线,具体来说,是在LED屏旁边的拓展板。分别是：\n驱动板引脚 主板I2C引脚 功能 3V3 3V3 为驱动板供电,即电源正极 GND GND 接地,即电源负极 SDA 3 串行数据线，传输数据 SCL 5 串行时钟线，传输控制信号 【图片：驱动板引脚】\n接错了有可能烧坏板子哦\nI2C总线 所谓总线,可以理解为一条街道,每个设备就是街道两旁的房子,房内的住户出门走亲访友就是数据在不同设备间的传输。\nI2C总线是常用于嵌入式系统的一种简易串行总线.他有简洁的双线结构(SCL+SDA),每个设备都有一个地址码,以此实现多个设备相互通讯。设备有主从之分，主设备/主端必须是带有CPU的逻辑模块，在同一总线上同一时刻使能有一个主端，可以有多个从端，从端的数量受地址空间和总线的最大电容 400pF的限制。\n可以使用i2c-tools调试i2c总线:\n检测有几组i2c总线在系统上i2cdetect -l 检测挂载在i2c-1上的设备i2cdetect -r -y 1 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 a b c d e f 00: -- -- -- -- -- -- -- -- -- -- -- -- -- 10: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 20: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 30: -- -- -- -- -- -- -- -- -- -- -- -- 3c -- -- --（led） 40: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 50: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 60: 60 -- -- -- -- -- -- -- -- -- -- -- -- -- -- --（电机驱动） 70: 70 -- -- -- -- -- -- -- 查看设备(地址为0x20)上所有寄存器的值i2cdump -f -y 1 0x20\n对单个寄存器进行读写:\ni2cset -f -y 1 0x20 0x77 0x3f （设置i2c-1上0x20器件的0x77寄存器值为0x3f）\ni2cget -f -y 1 0x20 0x77 （读取i2c-1上0x20器件的0x77寄存器值）\njetson-nano开发板提供了6条I2C主线,以及其他丰富的接口。理解这些接口是拓展各种设备的前提。\n软件连接:ssh远程桌面 从头开始的话，我们还需要往sd卡里烧写系统镜像，不过我拿到的已经完成了这一步骤，故不再赘述。\n在官方教程中,需要hdmi线连接显示屏,usb连接鼠标键盘,来进入jetson-nano的Ubuntu系统.其目的在于首次连接一个无线网络(手机热点),之后只要电脑和nano在同一网络,即可用电脑访问nano的IP(8888端口),直接操纵jetbot.\n由于我并没有hdmi线,只有一根网线,反正都能插,插谁不一样?所以用网线把小车和笔记本连接起来组成局域网.用ssh的方式进入nano的系统.具体步骤如下:\nip发现:在插入网线前后执行两次:arp -a,比较不同,会发现多出一个地址,类型为动态,此即为小车的内网IP.小车的led屏也会自动显示其ip.如eth0:192.168.x.x\n(如此,我们可以直接从浏览器访问这个ip的8888端口,并能运行jupyter notebook了.但我们不能让小车拖着网线跑啊,所以还是要配置无线网络.)\n将笔记本的wifi连接设为对以太网可共享,这一步是为了让小车能通过笔记本联网\n端口扫描:nmap -sT 192.168.x.x发现22端口开放,故连接之:ssh jetbot@192.168.x.x,就用官方教程给的账户密码.\n连接成功后,就可以用命令行工具连接WiFi了,但还是安装一下远程桌面吧.\n配置远程桌面:执行以下命令:\n1 2 3 sudo apt-get install tightvncserver sudo apt-get install xrdp sudo apt-get install vnc4server tightvncserver 之后在你的主机win+R，输入mstsc,进入远程登录桌面，输入小车的ip地址，点击连接\n在xrdp的登陆界面输入用户名密码即可打开远程桌面\n(这里我用jetbot用户登陆遭遇闪退,用root就可以,不清楚原因)(另外开了远程桌面内存疯涨,就很离谱)\n连接上wifi后,你能在小车的led板上看到另一个ip:wlan0:192.168.x.x\n不管怎样,连接上wifi之后的操作就很简单了.跟着教程,跑一跑demo,还是很有成就感的.\n排查bug 然而demo并没有让我跑出来,且指向同一个错误:\n1 OSError: [Errno 121] Remote I/O error 沿着jupyter notebook的报错一直走,一直到了最底层,向设备写入数据报错,remote IO error.\n看起来像是硬件的问题。一步一步排查呗\n怀疑跳线错误\n更换跳线——无果 用万用表测量线两端的信号——正常，排除连接问题 时钟线保持3.3v每隔几秒跳到2.2v又回来，结合i2c的原理应该是正常现象？ 数据线同样保持3.3v，间断跳至2.3，2.0 软件方法检验设备连接性\n用i2ctools可以检测到设备，拔下4根接线，在0x60,0x70处的设备消失（一个是i2c线，一个是逻辑供电？） 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 a b c d e f 00: -- -- -- -- -- -- -- -- -- -- -- -- -- 10: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 20: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 30: -- -- -- -- -- -- -- -- -- -- -- -- 3c -- -- -- 40: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 50: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 60: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 70: -- -- -- -- -- -- -- -- 然而，在通电状态下，把连线拔下又插上之后，i2c又能检测到设备，然后示例代码就能运行了？？？\n迷惑。所以开机时机器并没能正确载入设备，反倒是重新连接后能识别了？？？本来我都要换驱动板了，orz。\n又或者是和驱动板上的reset按钮有关？等下次遇到问题再说吧。\n拾遗 linux内存占用 led屏会显示内存占用，然鹅时间长了总会到90%以上，可我并没有运行什么程序。\n经查阅此处显示的是实际占有的加上buffer和cached mem部分，可以理解为缓存的，随时清理，并不占用实际内存。\n可用top命令查看内存详情。\n供电问题 用充电宝供电方便，但是只要一断电系统就会重启，这对linux系统而言伤害很大。\n而在充电宝电量不满时，经常发生开不了机的问题，大概是因为电量不足导致电压不稳。\n关机命令： sudo shutdown -h now\n重启： shutdown -h now -r\n下一篇：操纵小车和AI初探\n参考链接 https://github.com/NVIDIA-AI-IOT/jetbot/wiki/Hardware-Setup\nhttps://robocarstore.cn/\nhttp://www.gpus.cn/gpus_list_page_techno_support_content?id=50\nhttps://www.jianshu.com/p/789944463fd7\n","date":"2019-09-20T00:25:55Z","permalink":"https://lonelyuan.github.io/p/%E5%8D%95%E7%89%87%E6%9C%BA%E5%85%A5%E9%97%A8jetbot%E6%99%BA%E8%83%BD%E5%B0%8F%E8%BD%A6%E5%B0%9D%E9%B2%9C%E4%B8%80/","title":"单片机入门——jetbot智能小车尝鲜(一)"}]
>>>>>>> c299a18a604c29ea9bc9290079d2cccbbd9506ef
