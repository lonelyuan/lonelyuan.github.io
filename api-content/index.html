{"posts":[{"title":"基于vivado的基于FPGA的一种基于MIPS的一种五级流水线CPU实现的注释","content":" 本文所述为计算机组成原理课拓展实验的相关记录，基于“龙芯体系结构与CPU设计教学实验系统” 项目官网： http://www.loongson.cn/business/general/teach/356.html； 相关资料代码：#TODO:: github仓库 PS：标题可简记为《基于基于的一种基于的一种实现》 吐槽时间 快考试了，👴发觉👴计组学了个🔨，👴去年也学了个🔨，但是去年可以归因于晦气的晦气，今年只能说自己晦气。难道还要重蹈去年的晦气吗？👴本应该回去背课本，刷考研题，但是👴一看ppt就想起我们敬爱的《计算机组成原理》课的任课老师，丐哥老师反复强调的至理名言：“听不懂的举手（无停顿）都没举手，都听懂了，非常好。”本人十分钦佩丐哥老师对幽默感的独特理解。 （但是特此声明：本人不了解、不认同其关于&quot;5G是个几把&quot;，&quot;高晓松很nb这个人&quot;，&quot;钱=浪漫&quot;等议题的看法） 而且👴这人很怪，课本上的重点，不好玩；选做的实验，好玩！哎就是玩，怪不得卷不过别人，你也配卷？滚去考研吧。 众所周知，计算机学生的本科生涯，如果能做到在自己设计的CPU上运行自己写的操作系统并用自己写的编译器跑代码，那就非常成功了。👴差不多，👴能在自己搜的代码上写自己的注释并用自己的电脑截图，都是三个&quot;自己&quot;。那么今天给大家爆个啥捏，流水线奥。 “用”计算机→“造”计算机 上回书说到（#TODO:: CSAPP大篇），汇编器(as)让我们得到了机器能看懂的比特流，最后一步只需要连接器(ld)将其和其他调用一起载入内存。这回答了程序如何在CPU这个平台上运行的问题，然而一个更基本的问题是，这个现有的平台是如何实现的？一个粗略的认识是，我们知道这些足以实现CPU的复杂的逻辑，其最小单元总对应到简单的诸如逻辑门上面，但是落实到真正的物理实现之上，如何使效率最高？功耗最小？这些问题所跨越的复杂度的量级依然是一片巨大的迷雾。照亮这片迷雾的知识，大概隶属于IC学科。 However，作为CS专业而不是IC专业，我们的目标仅在于理解所谓“组成原理”。在IC产业的复杂度规模数轴上，向下是专有芯片（又称嵌入式？），功能专用，规模较小；向上是通用芯片，即手机电脑等的核心，其难度不言而喻。位于中间的FPGA则既兼顾了自由度也考虑了速度，因此，这玩意能满足CS本科教学的需要（主要是便宜耐操）。 高贵的IC工程师都用啥轮子 Vivado是一个FPGA集成设计平台（也算一个EDA？），他主界面左侧的工作流窗口很好的概括了利用FPGA开发的基本流程。即 编写设计源码(Source)：使用Verilog语言编写逻辑或引入IP 设计仿真模拟(Simulation)：通过观察仿真波形图和编写testbench来对设计进行debug 综合(Systhesis)门级网表：从RTL级描述降维到门级网表 生成(Implementation)布局布线：根据管脚约束，将依然是虚拟的门级连线落实为实际的线路 进行硬件编程(program)：生成比特流并写入目标设备 名词解释： IC：集成电路 FPGA：现场可编程门阵列 Verilog：一种硬件描述语言，语法涵盖了自顶向下五个抽象层面：系统级、算法级、RTL级、门级、开关级。 RTL：寄存器传输级。一般使用最多的就是RTL级。 IP：Intellectual Property内核模块，可以理解为将代码封装为函数。分为，软IP内核(soft IP core)，固IP内核(firm IP core)和硬IP内核(hard IP core)3个层次，相当于集成电路的毛坯、半成品和成品。 SoC：片上系统，大概是芯片及其装载的第一层软件接口的集合，很宽泛的概念。 EDA：电子设计自动化。 由此，我们可以大致探清了这片迷雾，CPU的设计如何从高抽象层次的逻辑，梳理成最底层的逻辑门，再实现为小小的芯片。那么我们有了轮子，要造一个CPU，还要确定目标指令集。由于本项目由龙芯公司赞助，那必然要选MIPS了。 MIPS指令集格式 啥叫指令集呢，学过几种语言就不难理解。高级程序语言规定每个ascii码的组合所对应的含义，指令集规定0和1的组合所对应的寄存器，ALU的各种信号。MIPS指令集从属于RISC系列，最基本的指令有31条。 //讲到这里本应该打个表展示31条指令，但是👴懒得打了。 Vivado中，.coe文件用于初始化IP核，本实验给出的.coe文件中存放了几条指令，不过是16进制数字，写个小脚本打印成可读的形式。 # mips_dump.py with open(path,'r') as f: hex_list = f.read().split('\\n') bin_list = list(map(lambda x:bin(int(x,16)),hex_list)) # bin_code_list = [&quot;{:0&gt;32}&quot;.format(i[2:],'b') for i in bin_list] bin_code_list = [i[2:].zfill(32) for i in bin_list] IType_op_dict = { '001000':'addi', '001001':'addiu', '001100':'ori', '001101':'xori', '001111':'lui', '100011':'lw', '101011':'sw', '000100':'beq', '000101':'bne', '001010':'slti', '001011':'sltiu' } RType_func_dict = { '100000':'add', '100001':'addu', '100010':'sub', '100011':'subu', '100100':'and', '100101':'or', '100110':'xor', '100111':'nor', '101010':'slt', '101011':'sltu', '000000':'sll', '000010':'srl', '000011':'sra', '000100':'sllv', '000110':'srlv', '000111':'srav', '001000':'jr', } def f_hex(ori, width): # bin-&gt;hex return &quot;0x&quot;+hex(int(ori,2))[2:].zfill(width) def f_reg(ori): # print register num return &quot;$&quot;+str(int(ori,2)).zfill(2) def code_dump(type:str,inst:str,params:list): if type == 'R': s = inst.ljust(6) + &quot;, &quot;.join([f_reg(params[0]),f_reg(params[1]),f_reg(params[2]),f_hex(params[3],2)]) elif type == 'I': s = inst.ljust(6) + &quot;, &quot;.join([f_reg(params[0]),f_reg(params[1]),f_hex(params[2],8)]) else: s = inst.ljust(6) +'0x'+ hex(int(params[0],2))[2:].zfill(8) return s assembly_list = [] for _ in bin_code_list: op = _[:6] # public field try: if op == '000000': # R-Type rs = _[6:11] rt = _[11:16] rd = _[16:21] shamt = _[21:26] func = _[26:] assembly_list.append(code_dump('R',RType_func_dict[func],[rs,rt,rd,shamt])) elif op in ['000010', '000011']: # J-Type target = _[6:] assembly_list.append(code_dump('J','j',[target])) else: # I-Type rs = _[6:12] rt = _[12:18] imm = _[18:] assembly_list.append(code_dump('I',IType_op_dict[op],[rs, rt, imm])) except Exception as e: assembly_list.append(&quot;***** decode error! *****&quot;) head = &quot;+---hexdump----|--------- assembly ---------+&quot; print(head) addr = 0 for i in range(len(bin_code_list)): print(&quot;|&quot;+ f_hex(bin(addr),2) +&quot; &quot;+ hex_list[i] +&quot; | &quot;+ assembly_list[i].ljust(26) + &quot; |&quot;) addr += 4 tail = &quot;+&quot;+&quot;-&quot;*43+&quot;+&quot; print(tail) 打印出来👴傻了，怎么还有不在31条范围里的。 +---hexdump----|--------- assembly ---------+ |0x00 24010001 | addiu $00, $04, 0x00000001 | |0x04 00011100 | sll $00, $01, $02, 0x04 | |0x08 00411821 | addu $02, $01, $03, 0x00 | |0x0c 00022082 | srl $00, $02, $04, 0x02 | |0x10 28990005 | slti $09, $36, 0x00000005 | |0x14 07210010 | ***** decode error! ***** | |0x18 00642823 | subu $03, $04, $05, 0x00 | |0x1c AC050014 | sw $00, $20, 0x00000014 | |0x20 00A23027 | nor $05, $02, $06, 0x00 | |0x24 00C33825 | or $06, $03, $07, 0x00 | |0x28 00E64026 | xor $07, $06, $08, 0x00 | |0x2c AC08001C | sw $00, $32, 0x0000001c | |0x30 11030002 | beq $16, $12, 0x00000002 | |0x34 00C7482A | slt $06, $07, $09, 0x00 | |0x38 24010008 | addiu $00, $04, 0x00000008 | |0x3c 8C2A0014 | lw $02, $40, 0x00000014 | |0x40 15450004 | bne $20, $20, 0x00000004 | |0x44 00415824 | and $02, $01, $11, 0x00 | |0x48 AC2B001C | sw $02, $44, 0x0000001c | |0x4c AC240010 | sw $02, $16, 0x00000010 | |0x50 0C000019 | j 0x00000019 | |0x54 3C0C000C | lui $00, $48, 0x0000000c | |0x58 004CD007 | srav $02, $12, $26, 0x00 | |0x5c 003AD804 | sllv $01, $26, $27, 0x00 | |0x60 0360F809 | ***** decode error! ***** | |0x64 A07A0005 | ***** decode error! ***** | |0x68 0063682B | sltu $03, $03, $13, 0x00 | |0x6c 1DA00003 | ***** decode error! ***** | |0x70 00867004 | sllv $04, $06, $14, 0x00 | |0x74 000E7883 | sra $00, $14, $15, 0x02 | |0x78 002F8006 | srlv $01, $15, $16, 0x00 | |0x7c 1A000008 | ***** decode error! ***** | |0x80 002F8007 | srav $01, $15, $16, 0x00 | |0x84 240B008C | addiu $00, $44, 0x0000008c | |0x88 06000006 | ***** decode error! ***** | |0x8c 8D5C0003 | lw $21, $48, 0x00000003 | |0x90 179D0007 | bne $57, $52, 0x00000007 | |0x94 A0AF0008 | ***** decode error! ***** | |0x98 80B20008 | ***** decode error! ***** | |0x9c 90B30008 | ***** decode error! ***** | |0xa0 2DF8FFFF | sltiu $31, $35, 0x00003fff | |0xa4 0185E825 | or $12, $05, $29, 0x00 | |0xa8 01600008 | jr $11, $00, $00, 0x00 | |0xac 31F4FFFF | ori $31, $19, 0x00003fff | |0xb0 35F5FFFF | xori $31, $23, 0x00003fff | |0xb4 39F6FFFF | ***** decode error! ***** | |0xb8 08000000 | j 0x00000000 | +-------------------------------------------+ 总之，代码都给你了，下面给出一个vivado实验的完整流程，不全面，但是都是踩坑经验。 Vivado使用 本流程环境：Vivado 2020.2 开发板型号：LS-CPU-EXB-1 创建项目 下一步，下一步，下一步，，，确认。 这一步只需要注意选器件，一定要选对。否则有可能在Implementation遇到“端口电平不匹配”“端口数量不足”等硬件问题。当然，有可能型号相近的性能规格也差不多，这属于玄学问题了。实验书上选择的的型号应该是“xc7a200tfbg676-2”，但是👴用的是“xc7a200tfbv676-2”也能成功写入比特流。 编写代码并仿真 本实验的代码大多来自“2016-04-14”，那就是龙芯公司给的源代码。在该系列代码中有一处bug，位于“单周期CPU实验”的single_cycle_cpu.v中。214行，resetn应该为{4{resetn}}，写使能位宽应为为4。 下面讲解一下项目结构，所有实验都是类似的： 三个顶层文件夹分别对应Add Source里的三类源文件：添加设计，添加仿真，添加约束。如果不需要上板，只完成仿真，那么只需要添加设计（几个.v），添加仿真（testbench.v/tb.v）就足够了，xxx_display.v也是上板需要的故而可以忽略。（实际上，图中我用箭头标记的都用不到）。 编写tb，无非是给tb里声明为input的信号赋值，还可以使用#xx，让tb等待一段时间。 点击Run Simulation，等一会就能看到波形图。波形图有三种颜色： 绿色代表信号正常正常； 红色的X代表信号不确定； 蓝色的Z代表信号休眠。 一般遇到红X，都是未初始化问题。蓝Z大概是没有模块调用这些信号。Vivado波形图的操作极其难用，这里介绍一个相对好用的操作：左键从左向右水平划，会直接缩放到鼠标滑过的这一段。右键选择进制等操作略。 仿真需要注意的问题： 如果文件没问题，模块调用层次会被自动解析从而呈现成一棵树，而不是好几个顶层文件。 注意set as top，应该设为根部模块（调用其他模块的）和tb //如果设错了可能在Implementation会出现“端口未赋初值”的报错。 中文乱码是经典字符集问题，有可能在换行处导致语法错误。建议统一换成utf-8。 简单解决方法：从vscode里复制。 引入IP核 对于流水线CPU，data_ram和inst_rom需要同步写，自己实现比较复杂，故直接实例化封装好的内存块IP。如何引入？首先说明几种文件格式： .dcp 原意为checkpoints文件，是一种加密压缩文件。用于封装模块方便调用，但对版本要求极其敏感。 .xci/.xcix IP核配置文件，本质是一个xml。是Vivado在新版本提倡使用xci而不是dcp。 .xdc 管脚约束文件。在Implementation用到，此处按下不表。 这几种文件格式都是可以直接Add Source添加进来的。实验老师同时提供dcp和xci文件，添加dcp崩屎了，原因估计如上。添加xci之后，提示我将IP更新为core cointainer的形式 更新就完了。然后需要等一会，IP还要执行一步synth，这段时间里IP属于锁住的状态，不能修改配置。 注意更换器件后，IP核都会锁住。这表示IP的配置和当前环境不匹配。对所有IP锁住的问题，只需要点击菜单栏Reports→Reports IP Status，然后点upgrade即可解除锁定。 我直接上板 直接点生成比特流，会一步步的按工作流向下运行，等待几分钟就能愉快的收获你的报错了！ 在把上文提到的坑都踩过一遍之后，终于没有critical warning，泪目。 但是此时实验课已经结束了，👴偷溜到没人的实验室，并留下以下珍贵画面 然后👴发现data_ram写入失败。但是👴没时间搞了，👴还是滚去复习课本吧。 多周期流水线CPU原理 最后，继续复习计组。 ","link":"https://lonelyuan.github.io/post/mips_pipeline_cpu/"},{"title":"我和拖延症的战争","content":"//这是一篇永远不会完结的文章。 //先准备目录 0x01 | 拖延症的生理基础 习惯的重要性 习惯行为学 生理基础：多巴胺 演化论证据 0x02 | 对拖延症的方法论综述 可行的计划 积极的环境 正向的反馈 能战胜拖延症的，是爱 0x03 | 高级作战录像 拖延循环 拖延症不是你失败的唯一原因 此身不灭，壮志不渝 0x04 | 西西弗斯计划 模型比方法更重要 对话机制 提示机制 这场战争，我们还没输，但也只能说还没输 ","link":"https://lonelyuan.github.io/post/ProcrastinationWar/"},{"title":"深度学习入门——jetbot智能小车尝鲜（二）","content":"那个男孩不想玩人工智能呢？在玄学修bug之后，我终于跑通了jetbot自带的深度学习demo。 怎样才能让ai程序发挥好的效果呢？众所周知，所谓人工智能，有多少人工就有多智能。 AI的发展离不开三个要素：算力，算法和算材。根据摩尔定律，算力的发展是不会停滞的（虽然定律快失效了）；进几年来的AI热正是算法的突破，即深度学习相关算法的突飞猛进；而算材就是用来训练模型的数据，未来几年AI应用的进一步落地离不开算材的进一步开发（中国在AI方面的最大优势正在于此）。数据集的丰富程度和有效程度直接影响了AI应用的效果，我将在下文详细说明。 在jetbot项目中，我们也能体验到用“人工”换“智能”的快乐。作为视觉识别类的AI应用，我们要在预设环境里创建数据集，并为其标注。有了数据集，jetbot搭载的NVIDIA牌GPU在方寸之间就能完成海量计算，仅用一颗摄像头就能实现自动避障，目标追踪，自动巡线等等炫酷功能！不要1999，也不要999，只要99！99刀NVIDIA计算卡带回家！（妮维雅打钱） 给萌新理清几个概念： 人工智能，机器学习，深度学习的关系： 深度学习：一种实现机器学习的技术；机器学习：一种实现人工智能的方法 【包含关系图】 AI的发展路径： 弱AI：单独领域工作效率超过人类→ 通用AI：可以广泛应用于大部分领域→ 强AI：有自主意识，即将灭绝人类（不是）→ 现在AI发展到什么地步了：弱AI，有生之年可能见到通用AI 推荐一波汉化的很好的wiki，也有自己原创的内容：http://www.waveshare.net/wiki/JetBot_AI_Kit 本篇详细介绍两个demo的代码和可能遇到的问题，最后附上神经网络的入门笔记。同样是初次接触，大佬请绕道。 demo1：自动避障 小车如何实现自动避障的呢？用通俗的不能再通俗的说法，AI程序通过学习你给他的数据集，知道了什么样的图像是死路，什么样的图像是通路。得到新图像时就能判断是死路的概率有多少，在程序里可以很简单的看出，当这个概率大于0.5的时候就触发小车转向。 具体而言，你要在你的环境里拍至少200张照片，100张标记为通路（free），100张标记为死路（blocked）。这便是你的数据集（dataset）。构建数据集的时候尽量分散在环境的各个位置和各个方向，可以沿边界环绕一圈，走一段距离停下，转一圈，收集8-10张图片。反正你的数据越多，标记的越准确，模型效果越好。 下一步就开始训练模型了，从代码里看出，这个demo使用AlexNet模型，用pytorch实现（废话）。第一次运行你会下载一个244M左右的大文件，在/home/jetbot/.torch/models目录下会看到这个.pth文件。这便是AlexNet了。 继续运行程序，完整的输出结果有三十行，每行后面的小数代表当前模型的准确度（？），程序最后会从这30个模型中选取准确度最高的作为最终模型，也是一个pth文件：best_model.pth 下载文件和训练模型都需要花挺长时间，看到kernel busy，也就是右上角的大黑点不要轻易打断。 什么是模型呢？稍微解释一下机器学习的概念。 模型就是函数，其要素为输入，输出，和变换关系。举例说明： 模型 输入 输出 细菌向养分移动 外界环境的化学信号 催动鞭毛的电信号 学生参加高考 试卷反射的光信号 试卷上问题的答案 小车自动避障 摄像头传输图像信号 前方被堵塞的概率 实际上，知识的本质也是函数，生命延续的关键就在于该生命的模型是否适应环境。这里不深入解释了，觉得惊奇请参阅Yjango的频道https://space.bilibili.com/344849038他用机器学习的角度解释生物进化，非常颠覆三观。 总之训练出来的模型就是这样一个函数。其输入为经过处理的摄像头的图形信号，输出一个0-1的数，越接近1越意味着模型认为小车要撞墙了。但是当他大于0.5的时候就会触发转向，也就实现了自动避障。 AlexNet是2012年提出的一种卷积神经网络（即CNN）算法。首次实现gpu加速。 主流深度学习框架：TensorFlow；PyTorch；Keras 还挺好玩的😀 demo2：目标追踪 基于上一个demo，我们还要下载一个模型，coco数据集神经网络，可以检测90种不同的物体。按教程把.engine文件下载到指定位置，顺着跑就完事了。（引入模型也要花挺长时间） 如果有数据集里的物品，从输出里能看到蓝框标出，小车会自动转向物体，同时还保留了自动避障的程序。 遇到bug：程序仅能读取一张图像进行识别，摄像头更新的功能无法执行。 修bug：摄像头问题 描述：摄像头只要调用了一次，后面就无法在其他地方调用。直接在jupyter上关闭输出并没有作用。而且只要在一个notebook里就能重复调用，换一个就不行。而且并没有报错信息，程序一直处在busy状态。 找到源码，在jetbot/jetbot/camera.py，但是所有样例里面调用摄像头都是用的Camera.instance()方法，而这个instance是在traitlets库里的，于是找到trailets官方文档 Traitlets是一个纯 python 库，支持： 对 python 对象属性的强类型实施( 类型属性称为 &quot;特征&quot; ) ； 动态计算的默认值； 当尝试改变时，自动验证和强制特征属性； 当特征值改变时注册接收通知； 从文件或者 命令行 参数中读取值- 在traitlets上不同层，因这里可以在没有配置机器的情况下使用 traitlets。 Traitlets支持IPython和Jupyter的配置系统，以及IPython交互小部件的声明性 API。 ipython是一个 python 的交互式 shell，比默认的python shell 好用得多，支持变量自动补全，自动缩进，支持 bash shell 命令，内置了许多很有用的功能和函数。其中就包括traitlets库。 https://traitlets.readthedocs.io/en/stable/config.html 在这里找到instance的功能：返回现有的类，如果没有就新建一个。 下面是样例中调用摄像头的代码： import ipywidgets.widgets as widgets #图像模块 from IPython.display import display #ipy的显示模块 import traitlets from jetbot import Camera, bgr8_to_jpeg #摄像头驱动，图像格式转换 camera = Camera.instance(width=500, height=500)#初始化摄像头对象 image = widgets.Image(format='jpeg', width=400, height=400)#创建图像 camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg) #连接摄像头到图像 display(image) #显示图像 尝试从camera.py里调用原始api。得到报错：Each object must be HasTraits, not &lt;class 'NoneType'&gt;，是说必须为对象指定类型。那么HasTraits这个类型是啥？文档说:任何具有trait属性的类都必须从 HasTraits 继承。 再次梳理调用摄像头的流程： 引入模型：model.load_state_dict(torch.load('best_model.pth')) 连接摄像头：见上文 模型执行： def update(): ...#此处为模型执行函数，将输入图像预处理后，执行模型 update({'new': camera.value}) #初始化该函数 camera.observe(update, names='value') #将update函数设为camera.value的observer 研究一下observe用法：当对象发生变化时调用函数。 https://traitlets.readthedocs.io/en/stable/using_traitlets.html#validation 执行如下代码： import ipywidgets.widgets as widgets #图像模块 from IPython.display import display #ipy的显示模块 import traitlets from jetbot import Camera, bgr8_to_jpeg #摄像头驱动，图像格式转换 camera = Camera.instance(width=500, height=500)#初始化摄像头对象 def update(change): x = change['new'] display(x) #显示图像 update({'new': camera.value}) camera.observe(update, names='value') 输出一大堆数组，说明camera.value是这一大堆像素。而且observe正常运行，数据一直冒出。 array([[[122, 116, 130], [126, 113, 127], [125, 117, 129], ..., [ 84, 96, 107], [ 82, 96, 113], [ 93, 93, 113]], [[120, 119, 130], [122, 120, 119], [118, 123, 130], ..., 然而就是不实时更新数据，卒。 👴佛了。 神经网络笔记 AlexNet——CNN 2012年由Hinton学生Alex提出，是Lenet加宽版。其采用了一系列的新技术：成功的引用了relu、dropout和lrn等trick，首次采用gpu加速。其包含65万神经元，5个卷积层，三个后面带有池化层，最后用了三个全链接。 ","link":"https://lonelyuan.github.io/post/jetbot-2/"},{"title":"单片机入门——jetbot智能小车尝鲜(一)","content":"那个男孩不想玩树莓派呢？机缘巧合之下，我得到了一台价值上百美元的智能小车的使用权。 小车的核心是NVIDIA家的jetson-nano开发板，这款19年三月才发布的微型AI计算机可谓是平民级核弹，四核A57的CPU，128核心Maxwell架构的GPU，4g内存，支持4k视频解码，而且这只五脏俱全的麻雀只需要5W的电源支持，任何一支充电宝都可以胜任。而它的定位是用它简单的搭建人工智能应用，非常的amazing。 本文的目的,不完全是新手教程,还有自己学习过程的记录和分享.初次接触,多有疏漏,欢迎指教. 【图片：主板证件照】 给萌新理清几个概念： 单片机：Single-Chip Microcomputer。 树莓派：一款著名的微型电脑品牌（本文介绍的jetson-nano可以理解为是树莓派的竞品，相比树莓派，这款单片机价格更高，性能更好，主打AI应用） jetbot：以jetson-nano为平台搭建的ai机器人应用，也就是所谓智能小车 硬件组装:积木和电工 本人拿到的是零件状态的小车，所以首先讲一讲组装的问题。有关具体步骤，官网教程十分详细，贴个连接给懒人吧：https://www.ncnynl.com/archives/201904/2927.html 这里只讲一讲我作为初学者的一些理解。首先，玩单片机和玩积木的区别就在于编程。当然，入门单片机还需要其他技能。比如，电工技能：你需要进行线材的简单加工，引脚的焊接，准备基本的工具就好，毕竟那个男孩没有一根热热的棒子呢（指电烙铁）。然后，各个部件的拼接固定需要一些做手工的技巧，这个也不用怕，赫鲁晓夫曾经说过：热熔胶可以让我们创造奇迹。 在这个层面上，初学者会浪费许多耗材，这是必要的练习手段，所以初学者也可以从最简单的芯片入手。同时你还要学习诊断硬件方面的问题，万用表会很有帮助。关于更详细的工具和耗材的需要，请自行查阅单片机入门有关资料。 在本项目中，焊接工作已经完成，剩下的连接都是可插拔式的。我们只需要两把螺丝刀即可完成组装。即便如此，本人还是花了一晚上才把小车点亮，原因是我得到的线材损坏近半，只得自己寻找和修理。 下面分析一下小车的结构: jetson-nano开发板:即本机的主板,可以看到有两层芯片,上层为核心层,包括cpu,gpu和内存可以像笔记本内存条一样拆卸;下层为主板,用于连接各种设备 intel无线网卡:将上层拆下即可安装.令连出两根天线,缠绕机身即可. PiOLED显示器和拓展版:连接在I2C主线上 相机模块:官方样例展示了只用一个摄像头通过深度学习进行自动避障的demo. 马达和其驱动板:下文重点讲解 开发板就可以运行一个完整的Ubuntu系统,其余设备是为其拓展功能的. 硬件架构：驱动芯片和I2C主线 我在玩小车的过程中耽误最长时间的就是电机（即马达）驱动了，借此讲一讲系统架构的事。 让轮子前进要靠马达，给马达供电不能直接让主板来做，要让主板给另一块小芯片发送指令，这块小芯片连接着独立的电源，收到指令才会给马达通电。这块小芯片即是电机驱动板。 驱动芯片是从硬件走向软件的第一道桥梁，可以类比PC的IO设备来理解。和物理世界交互的各种功能，都需要有专门的驱动芯片。包括马达，摄像头，扬声器，机械臂等等，只不过有的可以集成在一起，如：小车上的摄像头，PiOLED显示器等；有的出于体积，安全性，模块化的考虑需要分开，如电机和驱动板。 电机驱动板 官方给出的电机驱动板型号为:DC-Stepper-Motor PCA9685+TB6612.可以驱动两个步进电机或四个直流电机。（四轴飞行器gkd）本项目只用到了两个直流电机。 各个引脚的讲解：https://learn.adafruit.com/adafruit-stepper-dc-motor-featherwing/pinouts 电机驱动板上共连接有10根跳线。一对电源输入，两对为马达输出。还需四根母-母杜邦线来连接至主板的I2C总线,具体来说,是在LED屏旁边的拓展板。分别是： 驱动板引脚 主板I2C引脚 功能 3V3 3V3 为驱动板供电,即电源正极 GND GND 接地,即电源负极 SDA 3 串行数据线，传输数据 SCL 5 串行时钟线，传输控制信号 【图片：驱动板引脚】 接错了有可能烧坏板子哦 I2C总线 所谓总线,可以理解为一条街道,每个设备就是街道两旁的房子,房内的住户出门走亲访友就是数据在不同设备间的传输。 I2C总线是常用于嵌入式系统的一种简易串行总线.他有简洁的双线结构(SCL+SDA),每个设备都有一个地址码,以此实现多个设备相互通讯。设备有主从之分，主设备/主端必须是带有CPU的逻辑模块，在同一总线上同一时刻使能有一个主端，可以有多个从端，从端的数量受地址空间和总线的最大电容 400pF的限制。 可以使用i2c-tools调试i2c总线: 检测有几组i2c总线在系统上i2cdetect -l 检测挂载在i2c-1上的设备i2cdetect -r -y 1 0 1 2 3 4 5 6 7 8 9 a b c d e f 00: -- -- -- -- -- -- -- -- -- -- -- -- -- 10: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 20: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 30: -- -- -- -- -- -- -- -- -- -- -- -- 3c -- -- --（led） 40: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 50: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 60: 60 -- -- -- -- -- -- -- -- -- -- -- -- -- -- --（电机驱动） 70: 70 -- -- -- -- -- -- -- 查看设备(地址为0x20)上所有寄存器的值i2cdump -f -y 1 0x20 对单个寄存器进行读写: i2cset -f -y 1 0x20 0x77 0x3f（设置i2c-1上0x20器件的0x77寄存器值为0x3f） i2cget -f -y 1 0x20 0x77 （读取i2c-1上0x20器件的0x77寄存器值） jetson-nano开发板提供了6条I2C主线,以及其他丰富的接口。理解这些接口是拓展各种设备的前提。 软件连接:ssh远程桌面 从头开始的话，我们还需要往sd卡里烧写系统镜像，不过我拿到的已经完成了这一步骤，故不再赘述。 在官方教程中,需要hdmi线连接显示屏,usb连接鼠标键盘,来进入jetson-nano的Ubuntu系统.其目的在于首次连接一个无线网络(手机热点),之后只要电脑和nano在同一网络,即可用电脑访问nano的IP(8888端口),直接操纵jetbot. 由于我并没有hdmi线,只有一根网线,反正都能插,插谁不一样?所以用网线把小车和笔记本连接起来组成局域网.用ssh的方式进入nano的系统.具体步骤如下: ip发现:在插入网线前后执行两次:arp -a,比较不同,会发现多出一个地址,类型为动态,此即为小车的内网IP.小车的led屏也会自动显示其ip.如eth0:192.168.x.x (如此,我们可以直接从浏览器访问这个ip的8888端口,并能运行jupyter notebook了.但我们不能让小车拖着网线跑啊,所以还是要配置无线网络.) 将笔记本的wifi连接设为对以太网可共享,这一步是为了让小车能通过笔记本联网 端口扫描:nmap -sT 192.168.x.x发现22端口开放,故连接之:ssh jetbot@192.168.x.x,就用官方教程给的账户密码. 连接成功后,就可以用命令行工具连接WiFi了,但还是安装一下远程桌面吧. 配置远程桌面:执行以下命令: sudo apt-get install tightvncserver sudo apt-get install xrdp sudo apt-get install vnc4server tightvncserver 之后在你的主机win+R，输入mstsc,进入远程登录桌面，输入小车的ip地址，点击连接 在xrdp的登陆界面输入用户名密码即可打开远程桌面 (这里我用jetbot用户登陆遭遇闪退,用root就可以,不清楚原因)(另外开了远程桌面内存疯涨,就很离谱) 连接上wifi后,你能在小车的led板上看到另一个ip:wlan0:192.168.x.x 不管怎样,连接上wifi之后的操作就很简单了.跟着教程,跑一跑demo,还是很有成就感的. 排查bug 然而demo并没有让我跑出来,且指向同一个错误: OSError: [Errno 121] Remote I/O error 沿着jupyter notebook的报错一直走,一直到了最底层,向设备写入数据报错,remote IO error. 看起来像是硬件的问题。一步一步排查呗 怀疑跳线错误 更换跳线——无果 用万用表测量线两端的信号——正常，排除连接问题 时钟线保持3.3v每隔几秒跳到2.2v又回来，结合i2c的原理应该是正常现象？ 数据线同样保持3.3v，间断跳至2.3，2.0 软件方法检验设备连接性 用i2ctools可以检测到设备，拔下4根接线，在0x60,0x70处的设备消失（一个是i2c线，一个是逻辑供电？） 0 1 2 3 4 5 6 7 8 9 a b c d e f 00: -- -- -- -- -- -- -- -- -- -- -- -- -- 10: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 20: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 30: -- -- -- -- -- -- -- -- -- -- -- -- 3c -- -- -- 40: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 50: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 60: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 70: -- -- -- -- -- -- -- -- 然而，在通电状态下，把连线拔下又插上之后，i2c又能检测到设备，然后示例代码就能运行了？？？ 迷惑。所以开机时机器并没能正确载入设备，反倒是重新连接后能识别了？？？本来我都要换驱动板了，orz。 又或者是和驱动板上的reset按钮有关？等下次遇到问题再说吧。 拾遗 linux内存占用 led屏会显示内存占用，然鹅时间长了总会到90%以上，可我并没有运行什么程序。 经查阅此处显示的是实际占有的加上buffer和cached mem部分，可以理解为缓存的，随时清理，并不占用实际内存。 可用top命令查看内存详情。 供电问题 用充电宝供电方便，但是只要一断电系统就会重启，这对linux系统而言伤害很大。 而在充电宝电量不满时，经常发生开不了机的问题，大概是因为电量不足导致电压不稳。 关机命令： sudo shutdown -h now 重启： shutdown -h now -r 下一篇：操纵小车和AI初探 参考链接 https://github.com/NVIDIA-AI-IOT/jetbot/wiki/Hardware-Setup https://robocarstore.cn/ http://www.gpus.cn/gpus_list_page_techno_support_content?id=50 https://www.jianshu.com/p/789944463fd7 ","link":"https://lonelyuan.github.io/post/jetbot-1/"},{"title":"About Me","content":" Do not go gentle into that good night, Old age should burn and rave at close of day; Rage, rage against the dying of the light. 🐭我是谁 存在主义者。 性别男，爱好女。 本阶段人生目标：想理解计算机的一切。 目前还是Web狗一条。 🍌本博客宗旨 尽量不制造垃圾。 争取周更。 🤺同好检测器 Masterpiece //排名按时间顺序 文： 大刘 王小波 《GEB》 《量子窃贼》三部曲 剧： Re:0 JOJO 爱死机 Rick&Morty 黑镜 第九艺术： Minecraft Bioshock: Infinity Celeste 戴森球计划 🌌三观 world view | 放眼寰宇 资本主义秩序下的世界无可避免地走到周期的末尾，而第四次工业革命依然前途渺茫，所谓百年未有之大变革，人类文明正走向混沌的路口。 outlook on life and value | 聚焦个人： 当赛博朋克悄然成为现实，当手机成为不可或缺的器官，当消费主义暴打了理想、蒙骗了爱情，当记录了你的喜怒哀乐的数据比你更值钱； 作为信息时代原住民的我们，作为被资本主义异化、被互联网原子化了的个体，作为在内卷或被内卷中焦虑挣扎的普通人—— 是否有勇气走出舒适区，向无处不在的信息茧房说不？ 是否愿意审视自我的成见，尝试理解他人？ 是否敢于走出自闭，建立真实深刻的社会关系？ 是否相信人类意志的成长性，不断逼近生理和心理的极限？ 是否敢于自我解构，而不放弃探求生活的真相？ 是否接受人生的无意义，并选择继续热爱这一切？ ","link":"https://lonelyuan.github.io/post/about/"}]}